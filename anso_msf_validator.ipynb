{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e28d72-803b-489e-b659-86b7add042b3",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1871a9-98db-4b6f-ba3f-bb80a2644d97",
   "metadata": {},
   "source": [
    "#### - Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57cc96-7134-4522-b957-75692b690cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Import libraries for HTTP requests, authentication, and URL handling\n",
    "import requests                           # -- For making HTTP requests to the DHIS2 API\n",
    "from requests.auth import HTTPBasicAuth   # -- For handling basic authentication in HTTP requests\n",
    "from urllib.parse import quote            # -- For URL encoding special characters\n",
    "from getpass import getpass               # -- For securely collecting the passkey (hidden input)\n",
    "import dataframe_image as dfi\n",
    "import textwrap\n",
    "import socket                             # -- For handling DNS resolution errors\n",
    "from urllib3.exceptions import NameResolutionError\n",
    "from requests.exceptions import HTTPError, RequestException  # -- For handling HTTP and request-related exceptions\n",
    "import time                               # -- For using time.sleep in retry logic\n",
    "\n",
    "# -- Import data manipulation and numerical libraries\n",
    "import pandas as pd                       # -- For data manipulation and creating dfs\n",
    "import numpy as np                        # -- For data manipulation and numerical operations\n",
    "\n",
    "# -- Import Jupyter Notebook display and interactive utilities\n",
    "from IPython.display import clear_output  # -- For clearing screen display in Jupyter \n",
    "from IPython.display import display, HTML       # -- For displaying dfs in Jupyter Notebooks\n",
    "import ipywidgets as widgets              # -- For creating interactive buttons and widgets\n",
    "from functools import partial             # -- For cleaner argument binding in function calls\n",
    "\n",
    "# -- Import file, system, and regular expression utilities\n",
    "import os                                 # -- For operating system interactions (e.g., file paths)\n",
    "import sys                                # -- For system-specific parameters and functions\n",
    "import re                                 # -- For working with regular expressions\n",
    "\n",
    "# -- Import Excel file manipulation and styling tools\n",
    "from openpyxl import load_workbook        # -- For working with Excel files\n",
    "from openpyxl.styles import Font, Alignment  # -- For styling and aligning Excel cells\n",
    "\n",
    "# -- Import document and image processing libraries\n",
    "from docx import Document                # -- For creating and editing Word documents\n",
    "from docx.shared import Pt, RGBColor, Inches  # -- For Word document styling (e.g., font size, color, dimensions)\n",
    "from PIL import Image                    # -- For image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fa0c0f-00b3-4dbe-b484-004c5b19d80c",
   "metadata": {},
   "source": [
    "#### - IHVN DHIS2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594e9f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to fetch and process DHIS2 data\n",
    "def fetch_and_process_DHIS2_data(username, password, start_period, end_period, named_urls=None):\n",
    "    \"\"\"\n",
    "    Fetch and process DHIS2 data from named URLs with a user-specified period range, returning a dictionary of processed dfs.\n",
    "    \n",
    "    Args:\n",
    "        username (str): DHIS2 username for authentication\n",
    "        password (str): DHIS2 password for authentication\n",
    "        start_period (str): Start period in YYYYMM format (e.g., '202501')\n",
    "        end_period (str): End period in YYYYMM format (e.g., '202503')\n",
    "        named_urls (dict, optional): Dictionary where keys are names (e.g., Report Rate Facility) and values are DHIS2 API URLs.\n",
    "                                    If None, a default set of URLs is used.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary where keys are URL names and values are processed dfs\n",
    "    \"\"\"\n",
    "\n",
    "    # -- Step 4: Define separator line\n",
    "    separator_line = '-' * 43                                                  # -- Create a separator line of 43 dashes\n",
    "\n",
    "    # -- Step 1: Define default DHIS2 URLs if none are provided\n",
    "    if named_urls is None:                                                    # -- Check if named_urls is not provided\n",
    "        named_urls = {\n",
    "            \"Report Rate Facility\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=pe%3A202501&dimension=ou%3AKH62ia35VIZ%3Bum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&dimension=dx%3AZ7E9RxXmwxG.REPORTING_RATE%3BVmGwLcfPS2N.REPORTING_RATE%3BYFnIy7lATQL.REPORTING_RATE%3BNkuV7xoThHV.REPORTING_RATE%3BHwfLR3npibF.REPORTING_RATE%3BvN9rk5ChByM.REPORTING_RATE%3BoxUN7AXSF8r.REPORTING_RATE&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false\",\n",
    "            \"Report Rate LGA\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=pe%3A202501&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-lmSTo2yxNsA&dimension=dx%3AZ7E9RxXmwxG.REPORTING_RATE%3BVmGwLcfPS2N.REPORTING_RATE%3BYFnIy7lATQL.REPORTING_RATE%3BNkuV7xoThHV.REPORTING_RATE%3BHwfLR3npibF.REPORTING_RATE%3BvN9rk5ChByM.REPORTING_RATE%3BoxUN7AXSF8r.REPORTING_RATE&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"AGYW MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AQ1KKjeS4seJ%3BzhvcKIWKvEX%3BpgsZWQLbTvw%3BdPefeXOI0MT%3Bb62rwfvBP13%3Bechn4uCHBhF%3BeoSKe92wBYa%3BIYJciZgP6Yt%3BbbSqZH1OAxk%3By5mYZFQbMe6%3BSSa2P2O1keL%3BrtjZkt3ImND%3BDhw4lcmA8i5%3BAMs19im8mm7%3BTNTPcRPC3jV%3BWWaSbjutZof%3BcspEoTIBnOB%3BQ1ntMoY7ZrP%3BjQ51vKvy1SN&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"ART MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AEVJnWv5UQ2I%3BaDFx7U0OSNp%3BuTAVBA24Qgg%3BVNvZaoEcS8M%3BdJpKA2CL66w%3BwUlUHsYzh80%3BmaTBR3htwav%3BN4skK4jJVnm%3BcMpe2pMLJed%3BmJ3Af4Qg0wV%3BxFsrvhyu0Wx%3BCVIR5mDSrr0%3BqO3FSAwqg15%3BE8J56tfMIEa%3BBiqkhMdFIwy%3BfVpRSB8jy9Q%3BudXxeZhT8Fd%3BE20mRpvl5jK%3Bgcg9I4dagWN%3BfBJzc5QIP1b%3BgDuNCzc5liq%3BngCJ4UZOCme%3BEtg6BPVX548%3BiTJ2VvKOWHG%3BrJB5XXrF5zx%3BFRMmrIYSRfz%3BPhUxFwPj2US%3BKtMzH6OTxXL%3Bu0W1SpovSd3%3Bxz9C4uZwMuB%3BLqdahCtUzSX%3Bqb3YzC5X9Lo%3BOU60086uSKx%3Bs2d4Hk231P9%3BmnbibCKaDNb%3BlEdQdPdK5KL&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"ART MSF_tb screening\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AaDFx7U0OSNp&dimension=sbKiaUuaHpX%3AmyDWsEb0XMg%3BnsnGDTrtxbw&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"HTS MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AsxXB2RokZrt%3BhxYcq0LyXh6%3Bi3I5wU8vm0U%3BwSLnU5ihgb3%3BVz0ZjXCnFtX%3BK7Bkwdae7X1%3BRBxwgKGZYpv%3BjNodLWC4U4d%3Bq6bey1tg06I%3BAZSZngrMzj6%3BpS0Cjik4WEH%3BBrVqJd9MHSA%3BXKu24OQK64R%3BpgiqhOhD95N%3BYL87jqnIzQA%3BmN5TqnUQRgq%3BEvB0bzvxMq0%3BgWVJbVYOT1A%3Bd8lMQuQpLPe%3BT6f8BA7M9Q0%3BSVpx1fVD3bh%3BpJH2bCApdTe%3BuGUbRjQvCeN%3BE3bZgIIG5qQ%3Bd8pnVkpyGlU%3BDn4PJOJJASf%3BQV3wq0WsLXe%3Bs9ksVidbnRG%3BOFj0H56KbKp%3Bh9SMVFhNbBN%3BrJD9ER08iT4%3BJLOnLNuLOva%3BZztEVzPBwwl%3BX6wyczqYmJN%3Bvhhrj8rTq83%3ByR5JEOs2t7q%3BCnSrjlY5Siw%3BUMPLBlGYjWM%3BiE5kXuUJoMC%3BuMqKjodBP76%3Bu9gp0VFbnHh%3BzJuaAQbUlq8%3BQXNyy0dbIpd%3BomaL0XteWO8%3BKtzvesDYABJ%3BHdTQzlvMtjU%3Bqznyc2H90Ay%3Bdtri8UEwZFV%3BFB1EZfVSmYi%3BXzghRlcLMqB%3BOk6fJzfTk75%3BomujB6405jI%3BenPRkAVrHKi%3BE6wddhqJVIN%3BjWajcYCyiDE%3BLSQuUgoTH7o%3Bilp3JWW1qt5%3BURgQ4d3y8WF%3Bxc40kwzTBVG%3BmCD2Qhbd6CY%3BnQtTVOdEMqV%3BKQAEkHXQe7N%3BxBr9Sgyk4cO%3BlI7YzdC7wEd%3BegRRIwWxnJs%3BPPxR0HhCKQR%3BkmBNFDE8duJ%3BGTUzO3HGLWA%3Bh8HFl5EeHHl%3BuXwAyGT9eqW%3BDahOUj6bRk0%3BT8G2KNNZ4eI%3BD7ygy6yCHFs%3BuSQJcqAEvHg%3BU74jSwLCoA1%3BZheiLjTrqRZ%3BjlFslOk3bkU%3BOxBKckVqp29%3BJWHc7D4J132%3Bq1XlBEcB1PE%3BNb95zNUKf29%3BevlfYhoKrjI%3BU8xSE6OneYl%3BF2JEmiJt3Yl%3BPZWrrb7VyCj%3BXxpFcHK1S89%3BsICfdv3or5G%3Bg5HvgkCKSSU%3Bh7XmbTNyTUi%3BUi7DiLwSgqm%3BHIHQHXPOGKl%3Bl3aXhanFimZ%3BSl6d3hqzq2C%3BpIsmPa1GjFs%3BOwrvPMKq0pQ%3BV7hcDYvuPMY%3BDWb8URoPRym%3BL7l30ySaQDy%3BnYrdLtwDlV0%3BifE9LKaLqUm%3BuMkZMIHVVjV%3BcCLFgRUkIww%3BHUWYU2ruloN%3BoXsckqTpzhN%3Bm4CzDuc50Jn%3BLPyxdv2eBEj%3BZLARI5LYBOL%3BPYL5GdQGPfI%3BmQZ4z94jzak%3BRkwT0w0mPNj%3BEC5iN37lZ61%3BS0QI1IcESjq%3BnR3ZklnEuBy%3BgxZKoTwyLnn%3BIp75Jb7o8Au%3BVPMZR303TWP%3BjqP0tN3v5hJ%3BuoBeVy413Mj%3BPn1GooQL0I4%3BEh4GHGcZV1U%3BJr0gixBBrvT&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"HTS MSF_hivst approach\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AT8G2KNNZ4eI&dimension=tBdRxXi3Dxr%3AALL_ITEMS&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"NSP MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AxesSKTdzhPF%3BuIx4sChOeMC%3BkJSLUKrBKez%3BJylie7CPg63%3BTV5DhhOgF7s%3BL0X8cbiEfrC%3BoSDqDrfRpb3%3BIQYpNyC6lF2%3BlOVVI8B4Ag6%3BRxQv56EIuWs%3BqyV24hEIgM5%3BObJbRGQ3QPI%3BptgY5CK3GUc%3BC16TIH6Zxju%3BKY2gb90cvTu%3BO3g2Lq9fpUU%3Bkk3hEztWa48%3BxvfqoSSOIOL%3BcLSlAzBug6Y%3BayTk1t8sjFN%3BjY2SLdSlMug%3Bv3sfwf9O1R9%3BxrHzg7SORIt&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"PMTCT MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ABWLsXE490Yw%3BAtzuY8wFIaP%3BmjoPYWLowE6%3BhWkEco9hG0R%3BgybVHn9Y3SQ%3BkNEHSaIxOja%3BSWsoIgeQBKd%3Bym1WjkXu8ol%3BHDVcSJrN68V%3BIY3zDXL1t0b%3BCrv4RYmAJot%3Bn1MZAkrNWlM%3BGDFB54Uuepj%3BPaXizDbvXcE%3BhnqKzrB2hX0%3BZv0Go6hoDxZ%3BZOzgBnzWLOK%3Bbj8jc0HujI2%3BVlhKdJD8Mav%3BqO3KHhkVM38%3BkSHVwcO9iYZ%3BWnEhg2SiMjF%3BFR9ibOgyNKg%3BbyiZy4Xo7Rx%3BvpEeS23uOzB%3BzoSht7Xk3OI%3BUMFtzIDX9nE%3BxkQqd3C5vd8%3BCAO8uuth3q6%3BRATzsmd7JfL%3BDPFGLfkzZTF%3BZZEXn1RzLwL%3BuMATgKm1ZEV%3ByShXhGc00TY%3Bdc0p7yc1jPy%3BJsyAmKQMqK1%3BlIJwQ20CgPE%3BbxeHOqH0s2V%3BOum5ofYWexC%3BadqiOXDSRbU%3BHFq8NihMhgw%3BcibdW4TLOJ5%3BMJHhWCCOy1q%3BPQHBZmMVWE3%3Bw9NSJbXp5Ub%3BCyrYJsUOe7Q%3BER9cFdvluIM%3BUP3mRp6Zr69%3Bgl5kyYu85zX%3BrIY8zpZJxtv%3BaPtwtDwhOeL%3BuQEZL5j8ZHS%3BSpuoRhODIuZ%3Bvu5TP1CuesM%3BeZ4kUaPlQWC%3BSVDAcLT6IKS%3BFLt9JLhBWlK%3Bt9NJ4JhsXVl%3BnOpah0JpIzI%3BDuFJekp1ymh%3BTJ5BREHjZnu%3BWzAmqotjxV7%3BwRRoicp2S4Y%3Bzq6Tvgk5GFl%3BLMrI0jXhjP4%3BTDLVNVgHUvf%3BakVDx9ew0y8%3ByDAbvAlPR69%3Bi6rCuewXarq%3BzKYuhIKhMKM%3BGQ4kUNGMf7i%3Bv2e5LaziiBr%3BsLWmlnDQzgt%3BrKzvhBgkpe5%3BpyUW87YFbY5%3BssvxYtnGXpp%3BlY6wzD8718l%3BeLZuFwiv4rQ%3BDRFLRwv7f8F%3BLgbHzzQILZY%3BWt8jhQxqq9L%3BTdqRbqoS3Uj%3BcfUpkarx8og%3BWbRBSkKaTE8%3BEvZz6jNSRMX%3BYGZr2K5Y0Yq%3BJGj4bfhtzCk%3BkKSgWbeTAL1%3Bo9zPtZI4c9T%3BcmkwuM6ZOaN%3BcGPBuUrZ5Oi%3BN4WysYNBRFk%3Bd0izXgJhn2P%3BxUYwPZH7ulJ%3BykZcKOVoJeH%3Bj3ycCFq6vzR%3BK2lEmtE4xjz%3Bw4jlyeHkVTD%3BDbj5r3zevDF%3BZYmUM2TtV80%3BYfvO0pN0SVl%3BwbplLMxCVSo%3BEJ31P0DyQaY&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"KP Prev MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ArJFps9PGgYI%3BpFrm4E6yE0i%3Bwld8ChYjUUS%3Bhnqs8zD2RBz%3BFdogfvZ9Es5%3BUWnjd2hDMpZ%3BmM3TZYEkMaF%3BK93mvkTXpbl%3BtIZvjax5TD5%3BN05zqacXFsD%3BcVHdvMKuwse%3BBFSM6D4KWg4%3ByHBgGkS0dPr%3BEw3ZRxdYY7g%3BihRnS748lOC%3BlIu2vmR2zHU%3BfbxvYGgVsrK%3BTdATue0b5th%3BFBBKTzFqBVR%3BF27CfSgCmSk%3BdecdNlpZy4B%3BRVuw3Ny3ysw%3BhN5ZT3zziqA%3BKngVqiOqAdp%3Bdfznt6rhrYg%3BbxK7Uh32HMK%3BduzVXts1QUh%3BXpDOj1a7ZdC%3BogXBJLCw1Qe%3BAKQTKPoUHt6%3BrClFr1FdYVY%3BdTWbSB6HZg6%3BGZo5a5CwzV7%3BdIElcrfEgSB%3BP8oCCg2mUcG%3BZc7dmnNEQwj%3BmWQsKiSyv7J%3BQVOL72RTOZR%3Bri9iXOK3wxX%3Bpqp8Tyvsdc1%3BNat3LtmEWXD%3BPm78aQ5UVh8%3BWaI8nE16Ab0%3BfHlNG1CMqYX%3BGwxEq7jrcSc%3BiqqfsLcdWiK%3BeF7Yi0cLTXP%3BVnDrAREzUE2%3BSSxprjJB8vd%3BL5pAPbPCrNF%3BPrdKtyHsOE8%3BLNQtCiSCfnC%3Bb3JIlAZUjNJ%3BeK3YlBsHGkB%3BTz9WrAjxVY9%3BMkl91koS5cn%3BdAQlguHfLF8%3BBdgtqOw1P33%3BhZzpfxOQo4b%3BJBoik13RWdP%3BhAVQ3sTq3nJ%3BGKiJWrIeEJu%3BqqFvQly7I9h%3BJtOlLSk4yTF%3BUfMiT3LdXYc%3BdLj7PgakBi5%3BUaOdcjrcI59%3BssQZNWweFrL%3BhHkzZLsAqmI%3BkYAhnVk8fYp%3BkTIGrSkqbrG%3Bl4ZD3aaxH7j%3BWAZm2HXm3xI%3BSECmJH5Lfer%3BKHnHX7Rb29d%3BVE0Z777wXB2%3Bzgqte2mbKxT%3BDbavrmvoWPG%3BJgDiY0dv2RX%3BS8WFXWTFvai%3BBBwzjs2JQ1Z%3BxRJrWUdpAxm%3BYS8QAyBakNp%3BJfPSsLKaeDV%3BkmsvoBtZ4oa&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"PMTCT MSF_sdp\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AN4WysYNBRFk&dimension=brKpOJgkKa0%3AOLcx26MiJia%3BQ9RcEpV6443%3BEGHRBByvqFu&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"PMTCT MSF_sdp_pos\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AykZcKOVoJeH&dimension=brKpOJgkKa0%3AOLcx26MiJia%3BQ9RcEpV6443%3BEGHRBByvqFu&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"PMTCT MSF_sd<72_in-outside\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3Av2e5LaziiBr&dimension=FtBUOVZVrC6%3AE8fr3yVA0mn%3BS0QLh0UvPbm&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "            \"PMTCT MSF_sd>72_in-outside\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AGQ4kUNGMf7i&dimension=FtBUOVZVrC6%3AE8fr3yVA0mn%3BS0QLh0UvPbm&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\"\n",
    "        }                                                                    # -- Initialize dictionary for URLs\n",
    "\n",
    "    # -- Step 2: Extract dx IDs from named_urls\n",
    "    all_dx_ids = set()                                                        # -- Initialize empty set to store unique dx IDs\n",
    "    for url in named_urls.values():                                           # -- Iterate over each URL in named_urls\n",
    "        dx_matches = re.findall(r'dx%3A([^&]+)', url)                         # -- Extract dx parameter from URL using regex\n",
    "        for match in dx_matches:                                              # -- Process each dx match found\n",
    "            ids = [id.split('.')[0] for id in match.split('%3B')]             # -- Split by %3B and remove .REPORTING_RATE suffixes\n",
    "            all_dx_ids.update(ids)                                            # -- Add cleaned IDs to the set\n",
    "\n",
    "    # -- Step 3: Fetch only relevant data element descriptions\n",
    "    base_url = 'https://ihvn.dhistance.com/api/dataElements'                  # -- Set base URL for data elements endpoint\n",
    "    dx_filter = f\"id:in:[{','.join(all_dx_ids)}]\"                             # -- Create filter string for specific dx IDs\n",
    "    params = {                                                                # -- Define query parameters for the API request\n",
    "        'fields': 'id,name,description',                                      # -- Request id, name, and description fields\n",
    "        'filter': dx_filter,                                                  # -- Apply filter for specific IDs\n",
    "        'paging': 'false'                                                     # -- Disable pagination to get all results\n",
    "    }\n",
    "    # Retry parameters\n",
    "    max_retries = 3                                                           # -- Set maximum retry attempts\n",
    "    retry_delay = 5                                                           # -- Set delay between retries in seconds\n",
    "    dataelement_to_description = {}                                           # -- Initialize dictionary for data element descriptions\n",
    "    for attempt in range(1, max_retries + 1):                                 # -- Loop through retry attempts\n",
    "        try:\n",
    "            socket.create_connection((\"8.8.8.8\", 53), timeout=5)              # -- Test DNS resolution with Google's DNS\n",
    "            response = requests.get(\n",
    "                base_url,\n",
    "                auth=HTTPBasicAuth(username, password),\n",
    "                params=params,\n",
    "                timeout=30                                                    # -- Add timeout to prevent hanging\n",
    "            )\n",
    "            response.raise_for_status()                                       # -- Raise exception for HTTP errors\n",
    "            data_elements = response.json().get('dataElements', [])           # -- Extract data elements from response\n",
    "            print(f\"Fetched {len(data_elements)} data elements\")              # -- Log number of fetched data elements\n",
    "            dataelement_to_description = {\n",
    "                de['id']: de.get('description', de['name']) for de in data_elements\n",
    "            }                                                                 # -- Map data element IDs to descriptions or names\n",
    "            break                                                             # -- Exit retry loop on success\n",
    "        except HTTPError as e:                                                # -- Handle HTTP errors\n",
    "            if response.status_code == 401:                                   # -- Check for unauthorized error\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                print(\"⦸ Error: Invalid IHVN DHIS2 login credentials\")        # -- Notify user of invalid credentials\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                return {}                                                     # -- Return empty dict to halt execution\n",
    "            else:\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                print(f\"⦸ HTTP Error (Attempt {attempt}/{max_retries}): HTTP status code {response.status_code} - {response.reason}\")\n",
    "                                                                              # -- Log HTTP error with status and reason\n",
    "            if attempt == max_retries:                                        # -- Check if max retries reached\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                print(\"⦸ Error: Max retries reached. Unable to fetch data elements.\")  # -- Notify user of failure\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                return {}                                                     # -- Return empty dict\n",
    "            time.sleep(retry_delay)                                           # -- Wait before retrying\n",
    "        except (ConnectionError, NameResolutionError) as e:                   # -- Handle network/DNS errors\n",
    "            print(separator_line)                                             # -- Print separator line\n",
    "            print(f\"⦸ Network Error (Attempt {attempt}/{max_retries}): Unable to resolve 'ihvn.dhistance.com'. Check domain or network connection.\") # -- Notify user of network/DNS issue\n",
    "            print(separator_line)                                             # -- Print separator line\n",
    "            if attempt == max_retries:                                        # -- Check if max retries reached\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                print(\"⦸ Error: Max retries reached. Please verify the domain name or check your internet connection.\") # -- Suggest checking domain/network\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                return {}                                                     # -- Return empty dict\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")                    # -- Log retry attempt\n",
    "            time.sleep(retry_delay)                                           # -- Wait before retrying\n",
    "        except RequestException as e:                                         # -- Handle other request errors\n",
    "            print(separator_line)                                             # -- Print separator line\n",
    "            print(f\"⦸ Request Error (Attempt {attempt}/{max_retries}): A general error occurred while trying to fetch data elements.\") # -- Log general request error\n",
    "            if attempt == max_retries:                                        # -- Check if max retries reached\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                print(\"⦸ Error: Max retries reached. Unable to fetch data elements.\") # -- Notify user of failure\n",
    "                print(separator_line)                                         # -- Print separator line\n",
    "                return {}                                                     # -- Return empty dict\n",
    "            time.sleep(retry_delay)                                           # -- Wait before retrying\n",
    "\n",
    "    # -- Step 5: Validate and parse the start and end periods\n",
    "    # -- Step 5.1: Validate start and end periods\n",
    "    for period in [start_period, end_period]:                                 # -- Check both start and end periods\n",
    "        if not (isinstance(period, str) and len(period) == 6 and period.isdigit() and 1 <= int(period[4:]) <= 12): # -- Validate format and month range\n",
    "            print(separator_line)                                             # -- Print separator line\n",
    "            print(\"⦸ Error: Invalid period date format\")                     # -- Print error message\n",
    "            print(separator_line)                                             # -- Print separator line\n",
    "            return {}                                                         # -- Return empty dict to halt execution\n",
    "\n",
    "    # -- Step 5.2: Parse the start and end periods\n",
    "    start_year = int(start_period[:4])                                        # -- Extract year from start period\n",
    "    start_month = int(start_period[4:])                                       # -- Extract month from start period\n",
    "    end_year = int(end_period[:4])                                            # -- Extract year from end period\n",
    "    end_month = int(end_period[4:])                                           # -- Extract month from end period\n",
    "\n",
    "    # -- Step 6: Format the period range for display\n",
    "    month_names = {                                                           # -- Define month names for display\n",
    "        1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
    "        7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "    }\n",
    "    start_display = f\"{month_names[start_month]}{str(start_year)[-2:]}\"       # -- Format start period (e.g., Jan-25)\n",
    "    end_display = f\"{month_names[end_month]}{str(end_year)[-2:]}\"             # -- Format end period (e.g., Mar-25)\n",
    "\n",
    "    # -- Step 7: Print separator line to highlight successful setup\n",
    "    print('Data processed and stored as:')                                    # -- Print processing start message\n",
    "    print(separator_line)                                                     # -- Print separator line\n",
    "\n",
    "    # -- Step 8: Generate a list of periods between start and end\n",
    "    periods = []                                                              # -- Initialize empty list for periods\n",
    "    current_year, current_month = start_year, start_month                     # -- Set starting point for period generation\n",
    "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month): # -- Loop until end period is reached\n",
    "        periods.append(f\"{current_year}{current_month:02d}\")                  # -- Add period in YYYYMM format\n",
    "        current_month += 1                                                    # -- Increment month\n",
    "        if current_month > 12:                                                # -- If month exceeds 12\n",
    "            current_month = 1                                                 # -- Reset to January\n",
    "            current_year += 1                                                 # -- Increment year\n",
    "\n",
    "    # -- Step 9: Encode the periods for URL use\n",
    "    period_string = \"%3B\".join(periods)                                       # -- Join periods with URL-encoded semicolon\n",
    "    period_param = f\"dimension=pe%3A{period_string}\"                          # -- Format period parameter for API URL\n",
    "\n",
    "    # -- Step 10: Initialize data storage and counters\n",
    "    processed_data = {}                                                       # -- Initialize dict to store processed DataFrames\n",
    "    success_count = 0                                                         # -- Counter for successful URL processes\n",
    "    total_urls = len(named_urls)                                              # -- Total number of URLs to process\n",
    "\n",
    "    # -- Step 11: Define cluster mapping for LGAs\n",
    "    cluster = {                                                               # -- Define mapping of LGAs to clusters\n",
    "        # -- Cluster: Aguata\n",
    "        \"an Aguata\": \"Aguata\",\n",
    "        \"an Anaocha\": \"Aguata\",\n",
    "        \"an Orumba North\": \"Aguata\",\n",
    "        \"an Orumba South\": \"Aguata\",\n",
    "        # -- Cluster: Awka\n",
    "        \"an Awka North\": \"Awka\",\n",
    "        \"an Awka South\": \"Awka\",\n",
    "        \"an Dunukofia\": \"Awka\",\n",
    "        \"an Idemili North\": \"Awka\",\n",
    "        \"an Idemili South\": \"Awka\",\n",
    "        \"an Njikoka\": \"Awka\",\n",
    "        # -- Cluster: Nnewi\n",
    "        \"an Ekwusigo\": \"Nnewi\",\n",
    "        \"an Ihiala\": \"Nnewi\",\n",
    "        \"an Nnewi North\": \"Nnewi\",\n",
    "        \"an Nnewi South\": \"Nnewi\",\n",
    "        # -- Cluster: Omambala\n",
    "        \"an Anambra East\": \"Omambala\",\n",
    "        \"an Anambra West\": \"Omambala\",\n",
    "        \"an Ayamelum\": \"Omambala\",\n",
    "        \"an Oyi\": \"Omambala\",\n",
    "        # -- Cluster: Onitsha\n",
    "        \"an Ogbaru\": \"Onitsha\",\n",
    "        \"an Onitsha North\": \"Onitsha\",\n",
    "        \"an Onitsha South\": \"Onitsha\"\n",
    "    }\n",
    "\n",
    "    # -- Step 12: Process each named URL\n",
    "    for url_name, url in named_urls.items():                                  # -- Iterate over each name-URL pair\n",
    "        # -- Step 12.1: Update URL with new period range\n",
    "        if \"dimension=pe%3A\" in url:                                          # -- Check if URL has a period dimension\n",
    "            start_idx = url.find(\"dimension=pe%3A\")                           # -- Find start of period parameter\n",
    "            end_idx = url.find(\"&\", start_idx) if url.find(\"&\", start_idx) != -1 else len(url) # -- Find end of period parameter\n",
    "            url = url[:start_idx] + period_param + url[end_idx:]              # -- Replace old period with new one\n",
    "        else:                                                                 # -- If no period dimension exists\n",
    "            url = url + \"&\" + period_param if \"?\" in url else url + \"?\" + period_param # -- Append period parameter\n",
    "\n",
    "        # -- Step 12.2: Fetch data from DHIS2 API\n",
    "        try:\n",
    "            response = requests.get(url, auth=HTTPBasicAuth(username, password)) # -- Send GET request with authentication\n",
    "            response.raise_for_status()                                       # -- Raise exception if request fails\n",
    "            data = response.json()                                            # -- Parse response into JSON\n",
    "        except RequestException as e:                                         # -- Catch request-related exceptions\n",
    "            print(f\"⦸ Error: No signal to get '{url_name}' data\")            # -- Print error message\n",
    "            continue                                                          # -- Skip to next URL\n",
    "\n",
    "        # -- Step 12.3: Extract table structure from JSON\n",
    "        headers = [header['name'] for header in data.get('headers', [])]      # -- Get column names from headers\n",
    "        df = pd.DataFrame(data.get('rows', []), columns=headers)              # -- Create DataFrame from rows\n",
    "        df = df.rename(columns={'dx': 'dataElement', 'ou': 'orgUnit', 'pe': 'period'}) # -- Standardize column names\n",
    "\n",
    "        # -- Step 12.4: Extract metadata from the JSON response\n",
    "        meta = data.get('metaData', {})                                       # -- Get metadata section\n",
    "        ou_hierarchy = meta.get('ouHierarchy', {})                            # -- Get organizational unit hierarchy\n",
    "        items = meta.get('items', {})                                         # -- Get item mappings (IDs to names)\n",
    "\n",
    "        # -- Ensure dimension names are available for special URLs\n",
    "        if url_name == 'ART MSF_tb screening':                                # -- Check for ART MSF_tb screening URL\n",
    "            dimension_id = 'sbKiaUuaHpX'                                      # -- Set dimension ID\n",
    "        elif url_name == 'HTS MSF_hivst approach':                            # -- Check for HTS MSF_hivst approach URL\n",
    "            dimension_id = 'tBdRxXi3Dxr'                                      # -- Set dimension ID\n",
    "        elif url_name == 'PMTCT MSF_sdp':                                     # -- Check for PMTCT MSF_sdp URL\n",
    "            dimension_id = 'brKpOJgkKa0'                                      # -- Set dimension ID\n",
    "        elif url_name == 'PMTCT MSF_sdp_pos':                                 # -- Check for PMTCT MSF_sdp_pos URL\n",
    "            dimension_id = 'brKpOJgkKa0'                                      # -- Set dimension ID \n",
    "        elif url_name == 'PMTCT MSF_sd<72_in-outside':                        # -- Check for PMTCT MSF_sd<72_in-outside URL\n",
    "            dimension_id = 'FtBUOVZVrC6'                                      # -- Set dimension ID\n",
    "        elif url_name == 'PMTCT MSF_sd>72_in-outside':                        # -- Check for PMTCT MSF_sd>72_in-outside URL\n",
    "            dimension_id = 'FtBUOVZVrC6'                                      # -- Set dimension ID  \n",
    "        else:\n",
    "            dimension_id = None                                               # -- No dimension ID for other URLs\n",
    "\n",
    "        if dimension_id:                                                      # -- If dimension ID is set\n",
    "            dimension_values = set(df[dimension_id].unique())                 # -- Get unique dimension values\n",
    "            missing_dimensions = [dv for dv in dimension_values if dv not in items] # -- Find missing dimension values\n",
    "            if missing_dimensions:                                            # -- If there are missing dimensions\n",
    "                dimension_url = 'https://ihvn.dhistance.com/api/categoryOptions'   # -- Set URL for category options\n",
    "                dimension_filter = f\"id:in:[{','.join(missing_dimensions)}]\"   # -- Create filter for missing dimensions\n",
    "                dimension_params = {\n",
    "                    'fields': 'id,name',\n",
    "                    'filter': dimension_filter,\n",
    "                    'paging': 'false'\n",
    "                }                                                             # -- Define query parameters\n",
    "                try:\n",
    "                    dimension_response = requests.get(\n",
    "                        dimension_url,\n",
    "                        auth=HTTPBasicAuth(username, password),\n",
    "                        params=dimension_params\n",
    "                    )                                                         # -- Fetch dimension names\n",
    "                    dimension_response.raise_for_status()                     # -- Raise exception for HTTP errors\n",
    "                    dimensions = dimension_response.json().get('categoryOptions', [])  # -- Extract category options\n",
    "                    for dim in dimensions:\n",
    "                        items[dim['id']] = {'name': dim['name']}              # -- Add to items\n",
    "                except RequestException as e:                                 # -- Handle request errors\n",
    "                    print(f\"⦸ Warning: Failed to fetch dimension names for {url_name}: {e}\") # -- Log warning\n",
    "\n",
    "        # -- Step 12.5: Create organizational unit mappings based on URL name\n",
    "        if url_name == \"Report Rate LGA\":                                     # -- Special case for Report Rate LGA\n",
    "            orgunit_to_level = {ou: ou for ou in df['orgUnit'].unique()}      # -- Map orgUnit to itself\n",
    "        else:                                                                 # -- For other URLs\n",
    "            orgunit_to_level = {\n",
    "                ou: ou_hierarchy.get(ou, '').split('/')[1] if '/' in ou_hierarchy.get(ou, '') else ou\n",
    "                for ou in df['orgUnit'].unique()\n",
    "            }                                                                 # -- Extract second level from hierarchy\n",
    "\n",
    "        # -- Step 12.6: Create name mappings for organizational units and data elements\n",
    "        level_to_name = {\n",
    "            org_id: items[org_id]['name']\n",
    "            for org_id in set(orgunit_to_level.values()) if org_id in items\n",
    "        }                                                                 # -- Map orgUnit level IDs to names\n",
    "        orgunit_to_name = {\n",
    "            ou: items[ou]['name']\n",
    "            for ou in df['orgUnit'].unique() if ou in items\n",
    "        }                                                                 # -- Map orgUnit IDs to names\n",
    "        dataelement_to_name = {\n",
    "            de: items[de]['name']\n",
    "            for de in df['dataElement'].unique() if de in items\n",
    "        }                                                                 # -- Map dataElement IDs to names\n",
    "        if url_name in ['ART MSF_tb screening', 'HTS MSF_hivst approach', 'PMTCT MSF_sdp', \n",
    "                        'PMTCT MSF_sdp_pos', 'PMTCT MSF_sd<72_in-outside', 'PMTCT MSF_sd>72_in-outside']:  # -- Check for special URLs\n",
    "            column_map = {\n",
    "                'ART MSF_tb screening': 'sbKiaUuaHpX',\n",
    "                'HTS MSF_hivst approach': 'tBdRxXi3Dxr',\n",
    "                'PMTCT MSF_sdp': 'brKpOJgkKa0',\n",
    "                'PMTCT MSF_sdp_pos': 'brKpOJgkKa0',\n",
    "                'PMTCT MSF_sd<72_in-outside': 'FtBUOVZVrC6',\n",
    "                'PMTCT MSF_sd>72_in-outside': 'FtBUOVZVrC6'\n",
    "            }                                                               # -- Define column mapping for URL names\n",
    "            dimension_values = df[column_map[url_name]].unique()            # -- Get unique dimension values from selected column\n",
    "\n",
    "        # -- Step 12.7: Pivot the df to reshape the data\n",
    "        if url_name == 'HTS MSF_hivst approach':                              # -- Check for HTS MSF_hivst approach\n",
    "            if 'tBdRxXi3Dxr' not in df.columns:                               # -- Verify dimension column exists\n",
    "                print(f\"⦸ Warning: Dimension tBdRxXi3Dxr missing for {url_name}\") # -- Log warning\n",
    "                continue                                                      # -- Skip to next URL\n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='tBdRxXi3Dxr',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        elif url_name == 'ART MSF_tb screening':                              # -- Check for ART MSF_tb screening\n",
    "            if 'sbKiaUuaHpX' not in df.columns:                              # -- Verify dimension column exists\n",
    "                print(f\"⦸ Warning: Dimension sbKiaUuaHpX missing for {url_name}\") # -- Log warning\n",
    "                continue                                                      # -- Skip to next URL\n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='sbKiaUuaHpX',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        elif url_name == 'PMTCT MSF_sdp':                                     # -- Check for PMTCT MSF_sdp\n",
    "            if 'brKpOJgkKa0' not in df.columns:                              # -- Verify dimension column exists\n",
    "                print(f\"⦸ Warning: Dimension brKpOJgkKa0 missing for {url_name}\") # -- Log warning\n",
    "                continue                                                      # -- Skip to next URL \n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='brKpOJgkKa0',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        elif url_name == 'PMTCT MSF_sdp_pos':                                     # -- Check for PMTCT MSF_sdp\n",
    "            if 'brKpOJgkKa0' not in df.columns:                              # -- Verify dimension column exists\n",
    "                print(f\"⦸ Warning: Dimension brKpOJgkKa0 missing for {url_name}\") # -- Log warning\n",
    "                continue                                                      # -- Skip to next URL \n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='brKpOJgkKa0',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        elif url_name == 'PMTCT MSF_sd<72_in-outside':                        # -- Check for PMTCT MSF_sd<72_in-outside\n",
    "            if 'FtBUOVZVrC6' not in df.columns:                              # -- Verify dimension column exists\n",
    "                print(f\"⦸ Warning: Dimension FtBUOVZVrC6 missing for {url_name}\") # -- Log warning\n",
    "                continue                                                      # -- Skip to next URL \n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],        \n",
    "                columns='FtBUOVZVrC6',\n",
    "                values='value'  \n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        elif url_name == 'PMTCT MSF_sd>72_in-outside':                        # -- Check for PMTCT MSF_sd>72_in-outside\n",
    "            if 'FtBUOVZVrC6' not in df.columns:                              # -- Verify dimension column exists    \n",
    "                print(f\"⦸ Warning: Dimension FtBUOVZVrC6 missing for {url_name}\")   \n",
    "                continue                                                      # -- Skip to next URL\n",
    "            pivoted_df = df.pivot(  \n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='FtBUOVZVrC6',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        else:\n",
    "            pivoted_df = df.pivot(\n",
    "                index=['period', 'orgUnit'],\n",
    "                columns='dataElement',\n",
    "                values='value'\n",
    "            ).reset_index()                                                   # -- Pivot DataFrame\n",
    "        pivoted_df.columns.name = None                                        # -- Clear column index name\n",
    "\n",
    "        # -- Step 12.8: Format the 'period' column to 'Mon-YY' (e.g., Jan-24)\n",
    "        pivoted_df['period'] = pd.to_datetime(pivoted_df['period'], format='%Y%m').dt.strftime('%b-%y') # -- Convert YYYYMM to Mon-YY\n",
    "\n",
    "        # -- Step 12.9: Add organizational hierarchy information to the pivoted df\n",
    "        pivoted_df['orgunitlevel'] = pivoted_df['orgUnit'].map(orgunit_to_level) # -- Add orgUnit level\n",
    "        pivoted_df['LGA'] = pivoted_df['orgunitlevel'].map(level_to_name)     # -- Add LGA name\n",
    "        pivoted_df['orgUnit'] = pivoted_df['orgUnit'].map(orgunit_to_name)    # -- Replace orgUnit ID with name\n",
    "        pivoted_df['Cluster'] = pivoted_df['LGA'].map(cluster)                # -- Add cluster mapping\n",
    "\n",
    "        # -- Step 12.10: Rename columns with dimension or data element names\n",
    "        if url_name in [\"Report Rate Facility\", 'Report_Rate_LGA']:           # -- Check if URL is a report rate type\n",
    "            rename_dict = {\n",
    "                **{col: dataelement_to_name.get(col, col) for col in pivoted_df.columns if col in dataelement_to_name},\n",
    "                'period': 'ReportPeriod',\n",
    "                'orgUnit': 'FacilityName'\n",
    "            }                                                                 # -- Create renaming dictionary\n",
    "        elif url_name in ['ART MSF_tb screening', 'HTS MSF_hivst approach', 'PMTCT MSF_sdp', \n",
    "                          'PMTCT MSF_sdp_pos', 'PMTCT MSF_sd<72_in-outside', 'PMTCT MSF_sd>72_in-outside']:  # -- Check for special URLs\n",
    "            rename_dict = {\n",
    "                **{col: items.get(col, {}).get('name', col) for col in pivoted_df.columns if col in items},\n",
    "                'period': 'ReportPeriod',\n",
    "                'orgUnit': 'FacilityName'\n",
    "            }                                                                 # -- Use items for dimension names\n",
    "        else:\n",
    "            rename_dict = {\n",
    "                **{col: dataelement_to_description.get(col, col) for col in pivoted_df.columns if col in dataelement_to_description},\n",
    "                'period': 'ReportPeriod',\n",
    "                'orgUnit': 'FacilityName'\n",
    "            }                                                                 # -- Use descriptions for data elements\n",
    "        pivoted_df.rename(columns=rename_dict, inplace=True)                  # -- Apply renaming\n",
    "\n",
    "        # -- Step 12.11: Shorten FacilityName\n",
    "        pivoted_df['FacilityName'] = pivoted_df['FacilityName'].apply(\n",
    "            lambda x: x[:34] + '...' if isinstance(x, str) and len(x) > 33 else x\n",
    "        )                                                            # -- Truncate FacilityName to 34 chars if >33\n",
    "\n",
    "        # -- Step 12.12: Handle NaN values\n",
    "        if url_name in [\"Report Rate Facility\", 'Report_Rate_LGA']:           # -- Check if URL is a report rate type\n",
    "            pivoted_df.fillna('', inplace=True)                               # -- Replace NaN with empty string\n",
    "        else:                                                                 # -- For other URLs\n",
    "            pivoted_df.fillna(0, inplace=True)                                # -- Replace NaN with 0\n",
    "\n",
    "        # -- Step 12.13: Finalize DataFrame\n",
    "        pivoted_df = pivoted_df.reset_index(drop=True)                        # -- Reset index and drop it\n",
    "        processed_data[url_name] = pivoted_df                                 # -- Store processed DataFrame\n",
    "        success_count += 1                                                    # -- Increment success counter\n",
    "        print(f\"- {url_name}\")                                                # -- Print URL name as processed\n",
    "\n",
    "    # -- Step 13: Display processing summary\n",
    "    global report_period_display                                              # -- Declare global variable\n",
    "    report_period_display = (\n",
    "        f\"✔️ Data fetched successfully!\\nReport extracts: ({success_count}/{total_urls})\\n\"\n",
    "        f\"Extraction period: {start_display} - {end_display}\\nWorkbook variables & functions loaded\"\n",
    "    )                                                                     # -- Format summary message\n",
    "    if processed_data:                                                    # -- Check if any data was processed\n",
    "        print(separator_line)                                             # -- Print separator line\n",
    "        print(report_period_display)                                      # -- Print success message\n",
    "        print(separator_line)                                             # -- Print separator line\n",
    "    else:                                                                 # -- If no data was processed\n",
    "        print(separator_line)                                             # -- Print separator line\n",
    "        print(f\"⦸ Failed:\\nReport extracts: (0/{total_urls})\\nIHVN DHIS2 login credentials invalid\") # -- Print failure message\n",
    "        print(separator_line)                                             # -- Print separator line\n",
    "\n",
    "    # -- Step 14: Return processed data\n",
    "    return processed_data                                                 # -- Return dictionary of processed DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572cb49-2d9f-49df-bcf4-f1f51e14f424",
   "metadata": {},
   "source": [
    "#### - Function: Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d146cdc-5e76-4cca-886e-da0d5a9da049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Global variable to store DHIS2_data\n",
    "def fetch_dhis2_data_interactive_jupyter_mode():\n",
    "    \"\"\"\n",
    "    Interactive function to collect user inputs and fetch/process DHIS2 data in a Jupyter notebook.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        dict: DHIS2_data fetched from the DHIS2 server (accessible globally after submission)\n",
    "    \"\"\"\n",
    "    global DHIS2_data, load_variables, load_functions  # -- Declare global varible and function to modify it within handlers\n",
    "    \n",
    "    # -- Step 1: Define constants\n",
    "    separator_line = '-' * 43  # -- Define a static separator line of 43 dashes for formatting\n",
    "    output = widgets.Output()  # -- Output area for displaying results\n",
    "\n",
    "    # -- Step 2: Create widgets for collecting credentials\n",
    "    username_input = widgets.Text(description=\"Username:\", placeholder=\"Enter IHVN DHIS2 username\")\n",
    "    password_input = widgets.Password(description=\"Passkey:\", placeholder=\"Enter IHVN DHIS2 password\")\n",
    "    submit_credentials = widgets.Button(description=\"Submit\")\n",
    "    credentials_box = widgets.VBox([username_input, password_input, submit_credentials])\n",
    "\n",
    "    # -- Step 3: Create widgets for collecting periods\n",
    "    start_period_input = widgets.Text(description=\"Start Period:\", placeholder=\"Enter report period (YYYYMM, e.g., 202501)\")\n",
    "    end_period_input = widgets.Text(description=\"End Period:\", placeholder=\"Enter report period (YYYYMM, e.g., 202512)\")\n",
    "    submit_periods = widgets.Button(description=\"Submit\")\n",
    "    periods_box = widgets.VBox([start_period_input, end_period_input, submit_periods])\n",
    "\n",
    "    # -- Step 4: Store collected inputs\n",
    "    credentials = [None, None]  # -- To store username and password\n",
    "    periods = [None, None]      # -- To store start_period and end_period\n",
    "\n",
    "    # -- Step 5: Define formatting functions\n",
    "    def format_credentials(username, password):\n",
    "        \"\"\"Format login credentials for display with masked password.\"\"\"\n",
    "        username_line = f\"{'Username: ':<{43 - len(username)}}{username}\"\n",
    "        password_line = f\"{'Passkey: ':<{43 - len(password)}}{'*' * len(password)}\"\n",
    "        return f\"{username_line}\\n{password_line}\"\n",
    "\n",
    "    def format_report_period(start_period, end_period):\n",
    "        \"\"\"Format report period dates for display.\"\"\"\n",
    "        start_period_line = f\"{'Period Start Date: ':<{43 - len(start_period)}}{start_period}\"\n",
    "        end_period_line = f\"{'Period End Date: ':<{43 - len(end_period)}}{end_period}\"\n",
    "        return f\"{start_period_line}\\n{end_period_line}\"\n",
    "\n",
    "    def display_information(credentials_display, report_display):\n",
    "        \"\"\"Display all collected information in a formatted way.\"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"Enter IHVN DHIS2 login credentials:\")\n",
    "            print(separator_line)\n",
    "            print(credentials_display)\n",
    "            print(separator_line)\n",
    "            print()\n",
    "            print('Enter report period (YYYYMM, e.g., 202501):')\n",
    "            print(separator_line)\n",
    "            print(report_display)\n",
    "            print(separator_line)\n",
    "            print()\n",
    "\n",
    "    # -- Step 6: Define button handlers\n",
    "    def on_submit_credentials(b):\n",
    "        \"\"\"Handle submission of credentials.\"\"\"\n",
    "        credentials[0] = username_input.value\n",
    "        credentials[1] = password_input.value\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"Enter IHVN DHIS2 login credentials:\")\n",
    "            print(separator_line)\n",
    "            print(format_credentials(credentials[0], credentials[1]))\n",
    "            print(separator_line)\n",
    "            print()\n",
    "            print('Enter report period (YYYYMM, e.g., 202501):')\n",
    "            print(separator_line)\n",
    "            display(periods_box)\n",
    "\n",
    "    def on_submit_periods(b):\n",
    "        \"\"\"Handle submission of periods and fetch data.\"\"\"\n",
    "        global DHIS2_data\n",
    "        periods[0] = start_period_input.value\n",
    "        periods[1] = end_period_input.value\n",
    "\n",
    "        # Display formatted info\n",
    "        credentials_display = format_credentials(credentials[0], credentials[1])\n",
    "        report_display = format_report_period(periods[0], periods[1])\n",
    "        display_information(credentials_display, report_display)\n",
    "\n",
    "        # -- Fetch and process DHIS2 data (placeholder)\n",
    "        with output:\n",
    "            DHIS2_data = fetch_and_process_DHIS2_data(credentials[0], credentials[1], periods[0], periods[1])\n",
    "            if DHIS2_data:\n",
    "                load_variables()\n",
    "                load_functions()\n",
    "\n",
    "            # -- Optional LGA Filter Widget Setup\n",
    "            if \"Report Rate LGA\" in DHIS2_data and \"LGA\" in DHIS2_data[\"Report Rate LGA\"].columns:\n",
    "                available_lgas = sorted(DHIS2_data[\"Report Rate LGA\"][\"LGA\"].dropna().unique())\n",
    "\n",
    "                lga_filter_widget = widgets.SelectMultiple(\n",
    "                    options=available_lgas,\n",
    "                    description=\"Select LGA:\",\n",
    "                    #layout=widgets.Layout(width='300px', height='150px'),\n",
    "                    rows=6\n",
    "                )\n",
    "\n",
    "                apply_filter_button = widgets.Button(description=\"Apply report level\")\n",
    "\n",
    "                def on_apply_filter_clicked(b):\n",
    "                    selected_lgas = list(lga_filter_widget.value)\n",
    "                    with output:\n",
    "                        if not selected_lgas:\n",
    "                            print(\"✔️ State level data ready\")\n",
    "                        else:\n",
    "                            for key, df in DHIS2_data.items():\n",
    "                                if isinstance(df, pd.DataFrame) and \"LGA\" in df.columns:\n",
    "                                    DHIS2_data[key] = df[df[\"LGA\"].isin(selected_lgas)].copy()\n",
    "                            print(f\"✔️ LGA level data ready for {selected_lgas}\")\n",
    "\n",
    "                apply_filter_button.on_click(on_apply_filter_clicked)\n",
    "\n",
    "                print(f\"\\nOptional: Select report level - LGA\")\n",
    "                print(separator_line)\n",
    "                display(widgets.VBox([\n",
    "                    lga_filter_widget,\n",
    "                    apply_filter_button\n",
    "                ]))\n",
    "                print(separator_line)\n",
    "                \n",
    "    # -- Step 7: Link buttons to handlers\n",
    "    submit_credentials.on_click(on_submit_credentials)\n",
    "    submit_periods.on_click(on_submit_periods)\n",
    "\n",
    "    # -- Step 8: Display the initial interface\n",
    "    with output:\n",
    "        print(\"Enter IHVN DHIS2 login credentials:\")\n",
    "        print(separator_line)\n",
    "        display(credentials_box)\n",
    "    display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71fc325-811f-4993-adb7-be36a0a6f304",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Functions: Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fec3f2-1ea8-4bc6-824f-4eac8c914cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_variables():\n",
    "    \"\"\"\n",
    "    Defines variables for the notebook and assigns them as global.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Declare all variables as global\n",
    "    global file_path, report_name, report_name_rate, report_name_outlier, report_name_period\n",
    "    global report_name_period_name, report_period_name_folder, sub_folder_image_file, sub_folder_doc_file\n",
    "    global sub_folder2_image_file_report_rate, sub_folder2_image_file_msf_outlier\n",
    "    global doc_file_report_rate_xlsx, doc_file_msf_outlier_docx, doc_file_msf_outlier_xlsx\n",
    "    global highlight_red_list, MSF_hierarchy, MSF_report_rate_columns    \n",
    "\n",
    "    try:\n",
    "        # -- Step 1: Define main report export path\n",
    "        try:\n",
    "            file_path = r'C:\\Users\\HP\\Desktop\\ANSO\\CQI\\python\\report\\dhis2\\msf\\ihvn'\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining file_path: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 2: Create report name, dynamic period, and joined report period name\n",
    "        try:\n",
    "            report_name = \"anso msf report\"\n",
    "            report_name_rate = \"anso msf report rate\"\n",
    "            report_name_outlier = \"anso msf outlier\"\n",
    "            report_name_period = DHIS2_data[\"Report Rate Facility\"].ReportPeriod.iloc[0]\n",
    "            report_name_period_name = f\"{report_name_period} {report_name}\"\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining report names or accessing DHIS2_data: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 3: Create report period folder\n",
    "        try:\n",
    "            report_period_name_folder = os.path.join(file_path, f\"{report_name_period_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error creating report_period_name_folder: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 4: Define folders for storing reports\n",
    "        try:\n",
    "            sub_folder_image_file = os.path.join(report_period_name_folder, \"image file\")\n",
    "            sub_folder_doc_file = os.path.join(report_period_name_folder, \"document file\")\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining sub_folder_image_file or sub_folder_doc_file: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 4.1: Add subfolders for specific report types\n",
    "        try:\n",
    "            sub_folder2_image_file_report_rate = os.path.join(sub_folder_image_file, f\"{report_name_rate}\")\n",
    "            sub_folder2_image_file_msf_outlier = os.path.join(sub_folder_image_file, f\"{report_name_outlier}\")\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining sub_folder2_image_file_report_rate or sub_folder2_image_file_msf_outlier: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 5: Create folders if they do not exist\n",
    "        try:\n",
    "            os.makedirs(sub_folder_image_file, exist_ok=True)\n",
    "            os.makedirs(sub_folder_doc_file, exist_ok=True)\n",
    "            os.makedirs(sub_folder2_image_file_report_rate, exist_ok=True)\n",
    "            os.makedirs(sub_folder2_image_file_msf_outlier, exist_ok=True)\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error creating directories: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 6: Define report document file paths\n",
    "        try:\n",
    "            doc_file_report_rate_xlsx = os.path.join(sub_folder_doc_file, f\"{report_name_period} {report_name_rate}.xlsx\")\n",
    "            doc_file_msf_outlier_docx = os.path.join(sub_folder_doc_file, f\"{report_name_period_name}.docx\")\n",
    "            doc_file_msf_outlier_xlsx = os.path.join(sub_folder_doc_file, f\"{report_name_period_name}.xlsx\")\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining document file paths: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 7: Define list of words and phrases to keep after HTML cleaning\n",
    "        try:\n",
    "            highlight_red_list = [\n",
    "                'Community', 'Walk-In', 'Community & Walk-In', 'subset of 4',\n",
    "                'Self, Spouse, Sexual Partner, Children, Social Network, Others',\n",
    "                'FSW, MSM, PWID, TG, Others', 'Testing frequency', 'Outreach',\n",
    "                'Outreach-Pregnant', 'Outreach-Others', 'Excluding community testing',\n",
    "                'Excluding previously known', 'IPV', 'ANC', 'L&D', '<72hrs PP',\n",
    "                '<72 hrs', '>72 hrs - < 6 months', '>6 - 12 months',\n",
    "                'ANC, L&D, <72hrs Post Partum', 'Facility', 'Outside Facility',\n",
    "                'Within and outside the facility', 'within 72 hrs of birth',\n",
    "                'between >72 hrs - <2 months of birth', 'All regimens', 'Regimen Lines',\n",
    "                'MMD', 'DSD', 'excludes ART transfer-in', 'ART Addendum-2'\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining highlight_red_list: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "        # -- Step 8: Define MSF hierarchy\n",
    "        try:\n",
    "            MSF_hierarchy = ['ReportPeriod', 'Cluster', 'LGA', 'FacilityName']\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining MSF_hierarchy: {str(e)}\")\n",
    "            raise  # Re-raise to trigger top-level except\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⦸ Error loading variables: {str(e)}\")\n",
    "        # Optionally assign fallback values to globals, but here we just return\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdbaef-657c-45ca-af3a-67757f53d82e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Function: Validations & Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d564859-98d8-48d0-83a5-90f204120531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_functions():\n",
    "    \"\"\"\n",
    "    Defines and assigns global functions for styling dfs and exporting them to image, Excel, and Word formats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Declare global functions and variables\n",
    "        global outlier_red_report_rate, outlier_green_report_rate, outlier_red, outlier_yellow, outlier_red_LT0, outlier_yellow_LT0, outlier_red_GT0, outlier_yellow_GT0\n",
    "        global export_df_to_doc_image_excel, filter_gap_and_check_empty_df, prepare_and_convert_df, wrap_column_headers, wrap_column_headers2, widget_display_df\n",
    "        global Pre_HTS_MSF_positive, Pre_MSF_positives_all\n",
    "\n",
    "        def wrap_column_headers(df, max_width=20):                       # -- Wrap DataFrame column headers\n",
    "            \"\"\"\n",
    "            Wraps DataFrame column headers exceeding max_width characters for better display.\n",
    "\n",
    "            Args:\n",
    "                df (pd.DataFrame): Input DataFrame.\n",
    "                max_width (int): Maximum character width before wrapping. Defaults to 26.\n",
    "\n",
    "            Returns:\n",
    "                pd.DataFrame: DataFrame with wrapped column headers.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                wrapped_columns = []                                     # -- Initialize list for wrapped column names\n",
    "                for col in df.columns:                                   # -- Iterate over column names\n",
    "                    if len(str(col)) > max_width:                        # -- Check if column name exceeds max width\n",
    "                        wrapped = '\\n'.join(textwrap.wrap(col, max_width, break_long_words=True)) # -- Wrap long column name\n",
    "                        wrapped_columns.append(wrapped)                  # -- Add wrapped name to list\n",
    "                    else:\n",
    "                        wrapped_columns.append(col)                      # -- Keep short column name as is\n",
    "                df.columns = wrapped_columns                             # -- Update DataFrame columns\n",
    "                return df                                                # -- Return modified DataFrame\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error in wrap_column_headers: {str(e)}\")      # -- Print error message\n",
    "                return df                                                # -- Return original DataFrame on error\n",
    "\n",
    "        # -- Function: Wrap list of column names\n",
    "        def wrap_column_headers2(columns, max_width=20):                 # -- Wrap list of column names\n",
    "            \"\"\"\n",
    "            Wraps a list of column names exceeding max_width characters.\n",
    "\n",
    "            Args:\n",
    "                columns (list): List of column names.\n",
    "                max_width (int): Maximum character width before wrapping. Defaults to 26.\n",
    "\n",
    "            Returns:\n",
    "                list: List of wrapped column names.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                wrapped_columns = []                                     # -- Initialize list for wrapped column names\n",
    "                for col in columns:                                      # -- Iterate over column names\n",
    "                    if len(str(col)) > max_width:                        # -- Check if column name exceeds max width\n",
    "                        wrapped = '\\n'.join(textwrap.wrap(col, max_width, break_long_words=True))\n",
    "                                                                # -- Wrap long column name\n",
    "                        wrapped_columns.append(wrapped)                  # -- Add wrapped name to list\n",
    "                    else:\n",
    "                        wrapped_columns.append(col)                      # -- Keep short column name as is\n",
    "                return wrapped_columns                                   # -- Return wrapped column names\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error in wrap_column_headers2: {str(e)}\")     # -- Print error message\n",
    "                return columns                                           # -- Return original columns on error\n",
    "\n",
    "        # -- Step 2: Define outlier_red_report_rate function\n",
    "        # -- Function: Style cells with light coral for values less than 100\n",
    "        def outlier_red_report_rate(val):                                 # -- Define function to style cells red\n",
    "            \"\"\"\n",
    "            Styles cells with a light coral background and bold font for values less than 100.\n",
    "            Applies a border for consistent formatting.\n",
    "    \n",
    "            Args:\n",
    "                val: Value to evaluate (int, float, or string).\n",
    "    \n",
    "            Returns:\n",
    "                str: CSS style string if condition met.\n",
    "            \"\"\"\n",
    "            try:                                                        # -- Begin try block for error handling\n",
    "                # -- Step 2.1: Define conditions for styling\n",
    "                condition = (                                           # -- Combine all conditions for red styling\n",
    "                ((isinstance(val, (int, float)) and val < 100) or       # -- Check if numeric and less than 100\n",
    "                 (isinstance(val, object) and val != '100' and val != ''))  # -- Check if string, not '100', and not empty\n",
    "                or                                                      # -- OR condition for additional cases\n",
    "                (not (isinstance(val, (int, float)) and val < 100) and  # -- Check if not numeric less than 100\n",
    "                 (isinstance(val, (int, float)) and val != 0))          # -- AND numeric not equal to 0\n",
    "            )  # -- Check if numeric and less than 100\n",
    "                # -- Step 2.2: Apply styling if condition is met\n",
    "                if condition:                                           # -- Evaluate combined condition\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'  # -- Return red styling for matching values\n",
    "                return None                                             # -- Return None if no styling applies\n",
    "            except Exception as e:                                      # -- Catch exceptions in outlier_red_report_rate definition\n",
    "                print(f\"⦸ Error defining outlier_red_report_rate: {str(e)}\")        # -- Print error message\n",
    "                return None                                             # -- Return None on error\n",
    "        \n",
    "        # -- Step 3: Define outlier_green_report_rate function\n",
    "        # -- Function: Style cells with light green for values equal to 100\n",
    "        try:\n",
    "            def outlier_green_report_rate(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light green background and bold font for values equal to 100.\n",
    "                Applies a border for consistent formatting.\n",
    "                \n",
    "                Args:\n",
    "                    val: Value to evaluate (int, float, or string).\n",
    "                \n",
    "                Returns:\n",
    "                    str: CSS style string if condition met, None otherwise.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val == 100) or (isinstance(val, object) and val == '100' and val != ''):\n",
    "                    return 'background-color: lightgreen; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_green_report_rate: {str(e)}\") # -- Print error message for outlier_green_report_rate\n",
    "            return None                                                     # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light red for values equal is not 0\n",
    "        try:\n",
    "            def outlier_red(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light red background and bold font for values is not 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val != 0):\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_red: {str(e)}\")               # -- Print error message for outlier_red\n",
    "            return None                                                     # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light yellow for values is not 0\n",
    "        try:\n",
    "            def outlier_yellow(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light yellow background and bold font for values is not 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val != 0):\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_yellow: {str(e)}\")               # -- Print error message for outlier_yellow\n",
    "            return None                                                        # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light red for values is less than 0\n",
    "        try:\n",
    "            def outlier_red_LT0(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light red background and bold font for values less than 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val < 0):\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_red_LT0: {str(e)}\")               # -- Print error message for outlier_red_LT0\n",
    "            return None                                                         # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light yellow for values is less than 0\n",
    "        try:\n",
    "            def outlier_yellow_LT0(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light yellow background and bold font for values less than 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val < 0):\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_yellow_LT0: {str(e)}\")               # -- Print error message for outlier_yellow_LT0\n",
    "            return None                                                            # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light red for values is greater than 0\n",
    "        try:\n",
    "            def outlier_red_GT0(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light red background and bold font for values greater than 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val > 0):\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_red_GT0: {str(e)}\")               # -- Print error message for outlier_red_GT0\n",
    "            return None                                                         # -- Fallback to a no-op function\n",
    "        \n",
    "        # -- Function: Style cells with light yellow for values is greater than 0\n",
    "        try:\n",
    "            def outlier_yellow_GT0(val):\n",
    "                \"\"\"\n",
    "                Styles cells with a light yellow background and bold font for values gretar than 0. Applies a border for consistent formatting.\n",
    "                \"\"\"\n",
    "                if (isinstance(val, (int, float)) and val > 0):\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining outlier_yellow_GT0: {str(e)}\")               # -- Print error message for outlier_yellow_GT0\n",
    "            return None                                                            # -- Fallback to a no-op function\n",
    "\n",
    "        # -- Step 4: Define export_df_to_doc_image_excel function\n",
    "        try:\n",
    "            def export_df_to_doc_image_excel(\n",
    "                report_name=None,\n",
    "                df_style=None,\n",
    "                img_file_name=None,\n",
    "                img_file_path=None,\n",
    "                doc_description=None,\n",
    "                doc_indicators_to_italicize=None,\n",
    "                doc_indicators_to_underline=None,\n",
    "                doc_file_path=doc_file_msf_outlier_docx,\n",
    "                xlm_file_path=None,\n",
    "                xlm_sheet_name=None,\n",
    "                highlight_red_list=highlight_red_list\n",
    "            ):\n",
    "                \"\"\"\n",
    "                Exports a df to an image, Excel file, and Word document with optional description for the document.\n",
    "                (Docstring truncated for brevity; see original for full details.)\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    # -- Step 4.1: Process image export\n",
    "                    if all([df_style is not None, img_file_name is not None, img_file_path is not None]):  # -- Check if all image params are provided\n",
    "                        # Apply basic styling that Matplotlib can interpret\n",
    "                        styled_df = df_style.set_properties(**{\n",
    "                            'text-align': 'right',\n",
    "                            'font-size': '12pt',  \n",
    "                            #'border': '1px solid black'\n",
    "                        })\n",
    "                        image_path = os.path.join(img_file_path, img_file_name)\n",
    "                        \n",
    "                        dfi.export(\n",
    "                            styled_df, \n",
    "                            image_path, \n",
    "                            table_conversion='matplotlib',  # -- Use matplotlib for rendering\n",
    "                            max_rows=-1,                    # -- Render all rows (no truncation)\n",
    "                            max_cols=-1,                    # -- Render all columns\n",
    "                            fontsize=12,                    # -- Reduce font size to fit more rows\n",
    "                            dpi=300                         # -- Increase DPI for better quality\n",
    "                        )\n",
    "\n",
    "                    # -- Step 4.2: Process Excel export\n",
    "                    if all([df_style is not None, xlm_file_path is not None, xlm_sheet_name is not None]):  # -- Check if all Excel params are provided\n",
    "                        xlm_sheet_name = xlm_sheet_name[:31]            # -- Truncate sheet name to 31 characters\n",
    "                        mode = 'a' if os.path.exists(xlm_file_path) else 'w'  # -- Set mode: append if file exists, write if not\n",
    "                        with pd.ExcelWriter(xlm_file_path, engine='openpyxl', mode=mode, if_sheet_exists='replace' if mode == 'a' else None) as writer:  # -- Open Excel writer\n",
    "                            df_style.to_excel(writer, sheet_name=xlm_sheet_name, index=False)  # -- Write styled DataFrame to Excel\n",
    "\n",
    "                        wb = load_workbook(xlm_file_path)               # -- Load workbook for further formatting\n",
    "                        ws = wb[xlm_sheet_name]                         # -- Select worksheet by truncated name\n",
    "\n",
    "                        for cell in ws[1]:                              # -- Process header row for formatting\n",
    "                            if cell.value and isinstance(cell.value, str):  # -- Check if cell has string value\n",
    "                                protected_map = {}                      # -- Initialize map for protected phrases\n",
    "                                for phrase in highlight_red_list or []: # -- Iterate over phrases to highlight\n",
    "                                    token = f\"@@PROTECT_{abs(hash(phrase))}@@\"  # -- Create unique token\n",
    "                                    protected_map[token] = phrase       # -- Map token to phrase\n",
    "                                    cell.value = cell.value.replace(phrase, token)  # -- Replace phrase with token\n",
    "                                cell.value = re.sub(r\"<.*?>\", \"\", cell.value)  # -- Remove HTML tags\n",
    "                                for token, phrase in protected_map.items():  # -- Restore protected phrases\n",
    "                                    cell.value = cell.value.replace(token, phrase)  # -- Replace token with phrase\n",
    "                                cell.value = cell.value.strip()         # -- Strip whitespace\n",
    "\n",
    "                        font_style = Font(name='Calibri', size=8)       # -- Define font style for cells\n",
    "                        header_font = Font(name='Calibri', size=8, bold=True)  # -- Define font style for headers\n",
    "                        header_alignment = Alignment(horizontal=\"left\", vertical=\"bottom\", wrap_text=True)  # -- Define header alignment\n",
    "\n",
    "                        for row in ws.iter_rows():                      # -- Apply font style to all cells\n",
    "                            for cell in row:\n",
    "                                cell.font = font_style\n",
    "\n",
    "                        for cell in ws[1]:                              # -- Apply header formatting\n",
    "                            cell.alignment = header_alignment\n",
    "                            cell.font = header_font\n",
    "\n",
    "                        for col in ws.iter_cols(min_col=1, max_col=4):  # -- Adjust column widths\n",
    "                            max_length = max((len(str(cell.value)) if cell.value else 0) for cell in col)  # -- Find max length\n",
    "                            ws.column_dimensions[col[0].column_letter].width = max_length  # -- Set column width\n",
    "\n",
    "                        ws.auto_filter.ref = ws.dimensions              # -- Enable auto-filter for sheet\n",
    "                        wb.save(xlm_file_path)                          # -- Save workbook\n",
    "\n",
    "                    # -- Step 4.3: Create or append to Word document\n",
    "                    if all([doc_file_path is not None, image_path is not None, doc_indicators_to_italicize is not None, doc_indicators_to_underline is not None]):  # -- Check if all doc params are provided\n",
    "                        if os.path.exists(doc_file_path):               # -- Check if document exists\n",
    "                            doc = Document(doc_file_path)               # -- Load existing document\n",
    "                        else:\n",
    "                            doc = Document()                            # -- Create new document\n",
    "\n",
    "                        style = doc.styles['Normal']                    # -- Set default style\n",
    "                        style.font.name = 'Calibri'                     # -- Set font to Calibri\n",
    "                        style.font.size = Pt(9.5)                       # -- Set font size\n",
    "\n",
    "                        for section in doc.sections:                    # -- Configure section margins\n",
    "                            section.left_margin = Inches(0.5)\n",
    "                            section.right_margin = Inches(0.5)\n",
    "                            section.top_margin = Inches(1)\n",
    "                            section.bottom_margin = Inches(1)\n",
    "\n",
    "                        if doc_description:                             # -- Add description if provided\n",
    "                            title_paragraph = doc.add_heading(report_name, level=2)  # -- Add report name as heading\n",
    "                            title_run = title_paragraph.runs[0]         # -- Get title run\n",
    "                            title_run.font.size = Pt(10)                # -- Set title font size\n",
    "                            title_run.font.color.rgb = RGBColor(0, 0, 0)  # -- Set title color\n",
    "\n",
    "                            paragraph = doc.add_paragraph()             # -- Add paragraph for description\n",
    "                            paragraph.paragraph_format.space_after = Pt(0)  # -- Remove space after paragraph\n",
    "\n",
    "                            phrases_to_bold = [                         # -- Define phrases to bold\n",
    "                                \"REPORT ONLY 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY HEI ARVs FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY EID SAMPLE COLLECTION FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY EID PCR RESULTS FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"Report Name:\", \"should not be greater than\",\n",
    "                                \"should not be lesser than\", \"should not be equal to\",\n",
    "                                \"should be greater than\", \"should be lesser than\",\n",
    "                                \"should be equal to\", \"plus\", \"Note\", \"OR\"\n",
    "                            ]\n",
    "                            all_phrases = phrases_to_bold + (doc_indicators_to_italicize or []) + (doc_indicators_to_underline or [])  # -- Combine all phrases\n",
    "                            pattern = r'|'.join(re.escape(phrase) for phrase in all_phrases)  # -- Create regex pattern\n",
    "                            matches = list(re.finditer(pattern, doc_description))  # -- Find matches in description\n",
    "\n",
    "                            last_index = 0                              # -- Track last processed index\n",
    "                            for match in matches:                       # -- Process each match\n",
    "                                start, end = match.start(), match.end() # -- Get match boundaries\n",
    "                                paragraph.add_run(doc_description[last_index:start])  # -- Add text before match\n",
    "                                run = paragraph.add_run(doc_description[start:end])  # -- Add matched text\n",
    "                                if match.group(0) in phrases_to_bold:   # -- Apply bold if in bold list\n",
    "                                    run.bold = True\n",
    "                                if match.group(0) in doc_indicators_to_italicize:  # -- Apply italic if in italicize list\n",
    "                                    run.italic = True\n",
    "                                if match.group(0) in doc_indicators_to_underline:  # -- Apply underline if in underline list\n",
    "                                    run.underline = True\n",
    "                                last_index = end                            # -- Update last index\n",
    "\n",
    "                            paragraph.add_run(doc_description[last_index:])  # -- Add remaining text\n",
    "\n",
    "                        doc.add_picture(image_path, width=Inches(7))    # -- Add image to document\n",
    "\n",
    "                        section = doc.sections[-1]                      # -- Get last section for footer\n",
    "                        footer = section.footer.paragraphs[0]           # -- Access footer paragraph\n",
    "                        footer.text = \"This is an auto-generated report. Ensure all data is reviewed before any update is made.\"  # -- Set footer text\n",
    "                        footer.runs[0].font.size = Pt(7.5)             # -- Set footer font size\n",
    "                        footer.runs[0].font.color.rgb = RGBColor(100, 100, 100)  # -- Set footer color\n",
    "\n",
    "                        doc.save(doc_file_path)                         # -- Save document\n",
    "\n",
    "                    # -- Step 4.4: Generate and print success messages\n",
    "                    if all([report_name, img_file_name, img_file_path, xlm_file_path, xlm_sheet_name]):  # -- Check if all params for success message are provided\n",
    "                        img_file_path_name = os.path.basename(img_file_path)  # -- Get base image path name\n",
    "                        xlm_file_path_name = os.path.basename(xlm_file_path)  # -- Get base Excel path name\n",
    "                        image_success_print = rf\"IMG: '{img_file_name}' in {img_file_path_name}\"  # -- Format image success message\n",
    "                        excel_success_print = rf\"XLS: '{xlm_sheet_name}' in {xlm_file_path_name}\"  # -- Format Excel success message\n",
    "                        \n",
    "                        messages = [image_success_print, excel_success_print]  # -- Initialize success messages list\n",
    "                        if doc_description:                             # -- Check if document description exists\n",
    "                            doc_file_path_name = os.path.basename(doc_file_path)  # -- Get base document path name\n",
    "                            doc_success_print = rf\"DOC: '{report_name}' in {doc_file_path_name}\"  # -- Format document success message\n",
    "                            messages.append(doc_success_print)          # -- Add document message to list\n",
    "\n",
    "                        separator_line = '-' * max(len(msg) for msg in messages)  # -- Create separator line based on longest message\n",
    "\n",
    "                        print(f\"✔️ {report_name}\")                      # -- Print report name with checkmark\n",
    "                        print(separator_line)                           # -- Print separator line\n",
    "                        print('\\n'.join(messages))                      # -- Print success messages\n",
    "                        print(separator_line)                           # -- Print separator line\n",
    "\n",
    "                    return image_path                                   # -- Return image path\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⦸ Error in export_df_to_doc_image_excel: {str(e)}\")  # -- Print error message\n",
    "                    return None                                         # -- Return None on error\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining export_df_to_doc_image_excel: {str(e)}\")  # -- Print error message for function definition\n",
    "            export_df_to_doc_image_excel = lambda *args, **kwargs: None  # -- Fallback to a no-op function\n",
    "\n",
    "        # -- Step 5: Define prepare_and_convert_df function\n",
    "        def prepare_and_convert_df(DHIS2_data_key=None, hierarchy_columns=None, data_columns=None):\n",
    "            \"\"\"\n",
    "            Prepare and convert a DataFrame from DHIS2_data with available columns, applying sorting,\n",
    "            default values for missing data columns, and type conversions.\n",
    "\n",
    "            Args:\n",
    "                DHIS2_data_key (str): The key to look up the DHIS2 dataset.\n",
    "                hierarchy_columns (List[str] or None): List of hierarchy columns to include.\n",
    "                data_columns (List[str]): List of desired data columns.\n",
    "\n",
    "            Returns:\n",
    "                Optional[pd.DataFrame]: Prepared DataFrame or None if error occurs.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                if DHIS2_data_key not in DHIS2_data:\n",
    "                    print(f\"⦸ Error: '{DHIS2_data_key}' not found in DHIS2_data. Report not processed.\")\n",
    "                    return None\n",
    "\n",
    "                df_raw = DHIS2_data[DHIS2_data_key]\n",
    "\n",
    "                if hierarchy_columns is None:\n",
    "                    hierarchy_columns = []\n",
    "\n",
    "                # Find available and missing columns\n",
    "                available_columns = [col for col in data_columns if col in df_raw.columns]\n",
    "                missing_columns = [col for col in data_columns if col not in df_raw.columns]\n",
    "\n",
    "                # Print warning for each missing column\n",
    "                for col in missing_columns:\n",
    "                    print(f\"✋🏿 Warning: Column '{col}' not found in '{DHIS2_data_key}'.\")\n",
    "\n",
    "                # Print summary warning if no columns are found\n",
    "                if not available_columns:\n",
    "                    print(f\"✋🏿 Warning: None of the requested columns found in '{DHIS2_data_key}'. Missing columns: {missing_columns}\")\n",
    "\n",
    "                # Proceed with available columns and hierarchy\n",
    "                df = df_raw[hierarchy_columns + available_columns].copy()\n",
    "                df.sort_values(by=hierarchy_columns, inplace=True, ignore_index=True)\n",
    "\n",
    "                # Convert available columns to numeric\n",
    "                for col in available_columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "                # Add missing columns with default value 0\n",
    "                for col in data_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = 0\n",
    "\n",
    "                # Reorder columns to match input order\n",
    "                df = df[hierarchy_columns + data_columns]\n",
    "\n",
    "                return df\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error preparing and converting df for '{DHIS2_data_key}': {str(e)}\")\n",
    "                return None\n",
    "        \n",
    "        # -- Step 6: Define filter_gap_and_check_empty_df function\n",
    "        # -- Function: Filter gap and check empty df\n",
    "        try:\n",
    "            def filter_gap_and_check_empty_df(\n",
    "                df=None, \n",
    "                msg=None, \n",
    "                opNonZero=None, \n",
    "                opNeg=None, \n",
    "                opPos=None, \n",
    "                opNonPos=None, \n",
    "                opNonNeg=None, \n",
    "                opZero=None, \n",
    "                opLT100=None):\n",
    "                \"\"\"\n",
    "                Filters a df based on column-specific conditions and handles empty results.\n",
    "                (Docstring truncated for brevity; see original for full details.)\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    if df is None or df.empty:                          # -- Check if input DataFrame is invalid\n",
    "                        raise ValueError(\"Input DataFrame is None or empty\")   # -- Raise error if None or empty\n",
    "                    if not msg:                                         # -- Check if message is provided\n",
    "                        raise ValueError(\"No gap message provided for empty result\")  # -- Raise error if missing\n",
    "\n",
    "                    operator_map = {                                    # -- Define operator mapping for conditions\n",
    "                        'opNonZero': lambda x: x != 0,                  # -- Non-zero condition\n",
    "                        'opNeg': lambda x: x < 0,                       # -- Negative condition\n",
    "                        'opPos': lambda x: x > 0,                       # -- Positive condition\n",
    "                        'opZero': lambda x: x == 0,                     # -- Zero condition\n",
    "                        'opLT100': lambda x: x < 100                    # -- Less than 100 condition\n",
    "                    }\n",
    "\n",
    "                    conditions = []                                     # -- Initialize conditions list\n",
    "                    for arg, cols in {                                  # -- Iterate over operator arguments\n",
    "                        'opNonZero': opNonZero, 'opNeg': opNeg, 'opPos': opPos, \n",
    "                        'opNonPos': opNonPos, 'opNonNeg': opNonNeg, 'opZero': opZero, 'opLT100': opLT100\n",
    "                    }.items():\n",
    "                        if cols:                                        # -- Check if columns are provided for operator\n",
    "                            for col in cols:                            # -- Iterate over columns\n",
    "                                if col not in df.columns:               # -- Check if column exists\n",
    "                                    raise ValueError(f\"Column '{col}' not found in {df}\")  # -- Raise error if missing\n",
    "                                numeric_series = pd.to_numeric(df[col], errors='coerce').fillna(0)  # -- Convert to numeric\n",
    "                                conditions.append(operator_map[arg](numeric_series))  # -- Apply operator condition\n",
    "\n",
    "                    if not conditions:                                  # -- Check if any conditions were added\n",
    "                        print(\"No filtering conditions provided\")       # -- Print warning\n",
    "                        return df                                       # -- Return original DataFrame\n",
    "\n",
    "                    combined_condition = pd.DataFrame(conditions).T.any(axis=1)  # -- Combine conditions with OR logic\n",
    "                    df_filtered = df[combined_condition]            # -- Filter DataFrame\n",
    "\n",
    "                    if df_filtered.empty:                           # -- Check if filtered DataFrame is empty\n",
    "                        print(\"✋🏿Checked:\")                        # -- Print check message\n",
    "                        print(\"-\" * len(msg))                       # -- Print separator line\n",
    "                        print(msg)                                  # -- Print empty result message\n",
    "                        print(\"-\" * len(msg))                       # -- Print separator line\n",
    "                        return None                                 # -- Return None for empty result\n",
    "\n",
    "                    return df_filtered                              # -- Return filtered DataFrame\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"⦸ Error filtering gaps and checking empty df: {str(e)}\")  # -- Print error message\n",
    "                    return None                                     # -- Return None on error\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error defining filter_gap_and_check_empty_df: {str(e)}\")  # -- Print error message for function definition\n",
    "            filter_gap_and_check_empty_df = lambda *args, **kwargs: None  # -- Fallback to a no-op function\n",
    "\n",
    "         # -- Step 7: Constants Initialization for Positive Data Processing\n",
    "        # -- Define column lists for HTS, AGYW, PMTCT, and KP datasets\n",
    "        HTS_cols = {\n",
    "            \"positive\": [\n",
    "                \"Number of people who tested HIV positive and received results (Inpatient)\",  # -- Inpatient positive results\n",
    "                \"Number of people who tested HIV positive and received results (Outpatient)\", # -- Outpatient positive results\n",
    "                \"Number of people who tested HIV positive and received results (Standalone)\", # -- Standalone positive results\n",
    "                \"Number of people who tested HIV positive and received results (Community)\"   # -- Community positive results\n",
    "            ],\n",
    "            \"known_positive\": [\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Inpatient)\",  # -- Known positive inpatient\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Outpatient)\", # -- Known positive outpatient\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Standalone)\", # -- Known positive standalone\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\"   # -- Known positive community\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        AGYW_cols = [\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",  # -- AGYW community positive\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\"     # -- AGYW walk-in positive\n",
    "        ]\n",
    "\n",
    "        PMTCT_col = [\"Number of pregnant women tested HIV positive\"]  # -- PMTCT positive results\n",
    "\n",
    "        KP_cols = [\n",
    "            \"HTS-3a Number of MSM that have received an HIV test during the reporting period in KP-specific programs and received HIV Positive results\",                             # -- MSM positive results\n",
    "            \"HTS-3b Number of TG that have received an HIV test during the reporting period in KP-specific programs and HIV positive results\",                                       # -- TG positive results\n",
    "            \"HTS-3c Number of sex workers that have received an HIV test during the reporting period in KP-specific programs and received HIV-positive results\",                     # -- Sex workers positive\n",
    "            \"HTS-3d Number of people who inject drugs (PWID) that have received an HIV test during the reporting period in KP-specific programs and received HIV positive results\",  # -- PWID positive\n",
    "            \"HTS-3e Number of other vulnerable populations (OVP) that have received an HIV test during the reporting period and received HIV-positive results\",                      # -- OVP positive\n",
    "            \"HTS-3f Number of people in prisons and other closed settings that have received an HIV test during the reporting period and received HIV-positive results\"              # -- Prison positive\n",
    "        ]\n",
    "\n",
    "        # -- Step 8: Prepare and process HTS data\n",
    "        Pre_HTS_MSF_positive = prepare_and_convert_df(\"HTS MSF\", MSF_hierarchy, HTS_cols[\"positive\"] + HTS_cols[\"known_positive\"])           # -- Prepare HTS DataFrame\n",
    "        Pre_HTS_MSF_positive[\"HTS total tested - positive\"] = Pre_HTS_MSF_positive[HTS_cols[\"positive\"]].sum(axis=1)                         # -- Calculate total positive\n",
    "        Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"] = Pre_HTS_MSF_positive[HTS_cols[\"known_positive\"]].sum(axis=1)  # -- Calculate known positive\n",
    "        Pre_HTS_MSF_positive[\"HTS total tested - new positive (excluding previously known)\"] = np.where(\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"] > 0,                                                        # -- Check if known positive exists\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - positive\"] - Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"],      # -- Calculate new positive\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - positive\"]                                                                              # -- If not, keep total positive\n",
    "        )\n",
    "\n",
    "        # -- Step 9: Prepare AGYW data\n",
    "        Pre_AGYW_MSF_positive = prepare_and_convert_df(\"AGYW MSF\", MSF_hierarchy, AGYW_cols)                      # -- Prepare AGYW DataFrame\n",
    "        Pre_AGYW_MSF_positive[\"AGYW total tested - new positive\"] = Pre_AGYW_MSF_positive[AGYW_cols].sum(axis=1)  # -- Calculate total AGYW positive\n",
    "\n",
    "        # -- Step 10: Prepare PMTCT data\n",
    "        Pre_PMTCT_MSF_positive = prepare_and_convert_df(\"PMTCT MSF\", MSF_hierarchy, PMTCT_col)                    # -- Prepare PMTCT DataFrame\n",
    "        Pre_PMTCT_MSF_positive.rename(columns={PMTCT_col[0]: \"PMTCT total tested - new positive\"}, inplace=True)  # -- Rename PMTCT column\n",
    "\n",
    "        # -- Step 11: Prepare KP data\n",
    "        Pre_KP_MSF_positive = prepare_and_convert_df(\"KP Prev MSF\", MSF_hierarchy, KP_cols)                    # -- Prepare KP DataFrame\n",
    "        Pre_KP_MSF_positive[\"KP_Prev total tested - new positive\"] = Pre_KP_MSF_positive[KP_cols].sum(axis=1)  # -- Calculate total KP positive\n",
    "\n",
    "        # -- Step 12: Merge all DataFrames sequentially\n",
    "        base_cols = [\"ReportPeriod\", \"Cluster\", \"LGA\", \"FacilityName\"]                                           # -- Define base columns for merging\n",
    "        Pre_MSF_positives_all = DHIS2_data[\"Report Rate Facility\"][base_cols].merge(\n",
    "            Pre_HTS_MSF_positive[base_cols + [\"HTS total tested - new positive (excluding previously known)\"]],  # -- Merge HTS data\n",
    "            on=base_cols, how=\"left\"\n",
    "        ).merge(\n",
    "            Pre_AGYW_MSF_positive[base_cols + [\"AGYW total tested - new positive\"]],    # -- Merge AGYW data\n",
    "            on=base_cols, how=\"left\"\n",
    "        ).merge(\n",
    "            Pre_PMTCT_MSF_positive[base_cols + [\"PMTCT total tested - new positive\"]],  # -- Merge PMTCT data\n",
    "            on=base_cols, how=\"left\"\n",
    "        ).merge(\n",
    "            Pre_KP_MSF_positive[base_cols + [\"KP_Prev total tested - new positive\"]],   # -- Merge KP data\n",
    "            on=base_cols, how=\"left\"\n",
    "        )\n",
    "\n",
    "        # -- Step 13: Ensure numeric types & fill NaNs\n",
    "        for col in [\n",
    "            \"HTS total tested - new positive (excluding previously known)\",  # -- HTS new positive column\n",
    "            \"AGYW total tested - new positive\",                             # -- AGYW new positive column\n",
    "            \"PMTCT total tested - new positive\",                            # -- PMTCT new positive column\n",
    "            \"KP_Prev total tested - new positive\"                           # -- KP new positive column\n",
    "        ]:\n",
    "            Pre_MSF_positives_all[col] = pd.to_numeric(Pre_MSF_positives_all[col], errors='coerce').fillna(0).astype(int)  # -- Convert to int, fill NaNs with 0\n",
    "            Pre_MSF_positives_all[\"Total new positive\"] = Pre_MSF_positives_all[[  # -- Sum total new positive\n",
    "                \"HTS total tested - new positive (excluding previously known)\",\n",
    "                \"AGYW total tested - new positive\",\n",
    "                \"PMTCT total tested - new positive\",\n",
    "                \"KP_Prev total tested - new positive\"\n",
    "            ]].sum(axis=1)\n",
    "\n",
    "            \n",
    "        def widget_display_df(styler, widget=None):\n",
    "            \"\"\"\n",
    "            Apply table styles to a Pandas DataFrame Styler object and display it in an Output widget.\n",
    "            \n",
    "            Args:\n",
    "                styler (pandas.io.formats.style.Styler): The Styler object to apply styles to.\n",
    "                widget (ipywidgets.Output, optional): An existing Output widget to use. If None, a new one is created.\n",
    "            \n",
    "            Returns:\n",
    "                ipywidgets.Output: The widget containing the styled DataFrame.\n",
    "            \"\"\"\n",
    "            # Apply table styles\n",
    "            styled_styler = styler.set_table_styles([\n",
    "                # Table styling\n",
    "                {'selector': 'table', \n",
    "                'props': [('background-color', 'white'), \n",
    "                        ('border-collapse', 'collapse')]},\n",
    "                # Header styling\n",
    "                {'selector': 'th', \n",
    "                'props': [('background-color', '#f0f0f0'), \n",
    "                        ('text-align', 'right'), \n",
    "                        ('padding', '5px')]},\n",
    "                # Cell styling\n",
    "                {'selector': 'td', \n",
    "                'props': [('text-align', 'right'), \n",
    "                        ('padding', '5px')]},\n",
    "                # Hover effect for rows (background color)\n",
    "                {'selector': 'tr:hover', \n",
    "                'props': [('background-color', '#e0f7fa')]},\n",
    "                # Bold text for cells in hovered rows\n",
    "                {'selector': 'tr:hover td', \n",
    "                'props': [('font-weight', 'bold')]}\n",
    "            ])\n",
    "            \n",
    "            # Create or use an Output widget\n",
    "            if widget is None:\n",
    "                widget = widgets.Output()\n",
    "            \n",
    "            # Display the styled DataFrame in the widget\n",
    "            with widget:\n",
    "                display(HTML(styled_styler.to_html()))\n",
    "            \n",
    "            # Display the widget\n",
    "            display(widget)\n",
    "            \n",
    "            return widget \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⦸ Error in load_functions: {str(e)}\")                    # -- Print error message for load_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e50f1-1bbf-40c8-926b-44cf8d40c9af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MSF reporting rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d790c3c4-0e96-42b1-8805-cdfa10a3c9d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Reporting rate: LGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa7fd8-3a51-4d37-afaa-22dc1f21a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process LGA report rate gap\n",
    "def process_lga_report_rate_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process LGA report rate gap, exporting results as image and Excel files.\n",
    "    Caches the styled df and df shape for faster display in subsequent calls.\n",
    "    Reprocesses if the df shape changes.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the styled df for LGAs with gap.\n",
    "            Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        MSF_report_rate_columns = [                           # -- Define list of MSF report rate columns\n",
    "            'AGYW Monthly Summary Form - Reporting rate',\n",
    "            'ART MSF - Reporting rate',\n",
    "            'Care & Support MSF - Reporting rate',\n",
    "            'HTS Summary Form - Reporting rate',\n",
    "            'NSP Summary Form - Reporting rate',\n",
    "            'PMTCT MSF - Reporting rate',\n",
    "            'Prevention Summary Form - Reporting rate'\n",
    "        ]\n",
    "        MSF_report_rate_msg = \"No ANSO report rate gap found\"  # -- Define message for no gaps\n",
    "        report_name = \"ANSO MSF report rate\"                  # -- Define report name\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        global df_Report_Rate_LGA\n",
    "        df_Report_Rate_LGA = prepare_and_convert_df(          # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key='Report_Rate_LGA',                 # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=MSF_report_rate_columns              # -- Include specified report rate columns\n",
    "        )\n",
    "        if df_Report_Rate_LGA is None:                        # -- Check if data preparation failed or DataFrame is empty\n",
    "            return                                            # -- Exit function if no data\n",
    "        \n",
    "        # Drop the 'FacilityName' column if it exists\n",
    "        df_Report_Rate_LGA = df_Report_Rate_LGA.drop(columns='FacilityName')  # -- Drop the column\n",
    "        \n",
    "        wrap_column_headers(df_Report_Rate_LGA)\n",
    "        MSF_report_rate_columns2 = wrap_column_headers2(MSF_report_rate_columns)\n",
    "\n",
    "        # -- Step 3: Set export variables\n",
    "        report_month = df_Report_Rate_LGA['ReportPeriod'].iloc[0]  # -- Extract report month from DataFrame\n",
    "        report_sheet_name = \"All LGAs\"                        # -- Define Excel sheet name\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_lga_report_rate_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_Report_Rate_LGA.shape      # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:             # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(\"-\" * len(cached_display_name))     # -- Print separator line\n",
    "                    print(cached_display_name)                # -- Print display message\n",
    "                    print(\"-\" * len(cached_display_name))     # -- Print separator line\n",
    "                    display(process_lga_report_rate_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                    # -- Exit function\n",
    "\n",
    "        # -- Step 5: Filter for gaps\n",
    "        df_Report_Rate_LGA_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_Report_Rate_LGA,                            # -- Input DataFrame\n",
    "            msg=MSF_report_rate_msg,                          # -- Message for empty result\n",
    "            opNonZero=MSF_report_rate_columns2,                                   # -- No non-zero filter\n",
    "            opNeg=None,                                       # -- No negative filter\n",
    "            opPos=None,                                       # -- No positive filter\n",
    "            opZero=None,                                      # -- No zero filter\n",
    "            opLT100=MSF_report_rate_columns2                  # -- Filter for values less than 100\n",
    "        )\n",
    "        if df_Report_Rate_LGA_gap is None:                    # -- Check if no gaps found\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_lga_report_rate_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_lga_report_rate_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                            # -- Exit function\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_Report_Rate_LGA_style = (                          # -- Apply styling to filtered DataFrame\n",
    "            df_Report_Rate_LGA_gap.style                      # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                               # -- Hide index column\n",
    "            .map(outlier_red_report_rate, subset=MSF_report_rate_columns2)  # -- Highlight outliers in red for report rate columns\n",
    "            .map(outlier_green_report_rate)                                # -- Apply green outlier styling (assumed general application)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_lga_report_rate_gap.cached_style = df_Report_Rate_LGA_style  # -- Cache styled DataFrame\n",
    "        process_lga_report_rate_gap.cached_shape = df_Report_Rate_LGA.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8: Export results\n",
    "        export_df_to_doc_image_excel(                         # -- Export DataFrame to image and Excel formats\n",
    "            report_name=report_name,                          # -- Pass report name\n",
    "            df_style=df_Report_Rate_LGA_style,                # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                  # -- Pass image file name\n",
    "            img_file_path=sub_folder2_image_file_report_rate, # -- Pass image file path\n",
    "            doc_description=None,                             # -- No document description (not used)\n",
    "            doc_indicators_to_italicize=None,                 # -- No indicators to italicize (not used)\n",
    "            doc_indicators_to_underline=None,                 # -- No indicators to underline (not used)\n",
    "            xlm_file_path=doc_file_report_rate_xlsx,          # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                  # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 9: Optionally display styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            widget_display_df(df_Report_Rate_LGA_style)                 # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                    # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing LGA report rate gap: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_lga_report_rate_gap.cached_style      # -- Clear cached style\n",
    "        if hasattr(process_lga_report_rate_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_lga_report_rate_gap.cached_shape      # -- Clear cached shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f7db6c-270a-4af9-bf08-a0d12778cdfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - Reporting rate: Facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a3fbc-065c-46b1-8158-17d660f1b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process facility report rate gap\n",
    "def process_facility_report_rate_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process facility report rate gaps for each LGA, exporting results as images and Excel files.\n",
    "    Caches styled dfs for each LGA and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the styled df images for each LGA with gaps.\n",
    "            Defaults to None (will treat as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        MSF_report_rate_columns = [                           # -- Define list of MSF report rate columns\n",
    "            'AGYW Monthly Summary Form - Reporting rate',\n",
    "            'ART MSF - Reporting rate',\n",
    "            'Care & Support MSF - Reporting rate',\n",
    "            'HTS Summary Form - Reporting rate',\n",
    "            'NSP Summary Form - Reporting rate',\n",
    "            'PMTCT MSF - Reporting rate',\n",
    "            'Prevention Summary Form - Reporting rate'\n",
    "        ]\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_Report_Rate_Facility = prepare_and_convert_df(     # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"Report Rate Facility\",            # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=MSF_report_rate_columns              # -- Include specified report rate columns\n",
    "        )\n",
    "        if df_Report_Rate_Facility is None:                   # -- Check if data preparation failed or DataFrame is empty\n",
    "            return                                            # -- Exit function if no data\n",
    "        \n",
    "        wrap_column_headers(df_Report_Rate_Facility)\n",
    "        MSF_report_rate_columns2 = wrap_column_headers2(MSF_report_rate_columns)\n",
    "\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrames\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            if hasattr(process_facility_report_rate_gap, 'cached_styles'):  # -- Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_facility_report_rate_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_Report_Rate_Facility.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:             # -- Compare shapes\n",
    "                    for lga, style in process_facility_report_rate_gap.cached_styles.items():  # -- Iterate over cached styles\n",
    "                        cached_display_name = f\"✔️ Displaying {lga} facility report rate gap \"  # -- Define display message for LGA\n",
    "                        print(\"-\" * len(cached_display_name)) # -- Print separator line\n",
    "                        print(cached_display_name)            # -- Print display message\n",
    "                        print(\"-\" * len(cached_display_name)) # -- Print separator line\n",
    "                        display(style)                        # -- Display cached styled DataFrame for LGA\n",
    "                    return                                    # -- Exit function\n",
    "\n",
    "        # -- Step 4: Initialize cache\n",
    "        if not hasattr(process_facility_report_rate_gap, 'cached_styles'):  # -- Check if cache attribute exists\n",
    "            process_facility_report_rate_gap.cached_styles = {}  # -- Initialize dictionary to store styled DataFrames per LGA\n",
    "\n",
    "        # -- Step 5: Identify unique LGAs\n",
    "        lga_list = pd.Series(df_Report_Rate_Facility['LGA'].unique())  # -- Extract unique LGA names as a Series\n",
    "\n",
    "        # -- Step 6: Process each LGA for report rate gaps\n",
    "        for current_lga in lga_list:                          # -- Iterate over each unique LGA\n",
    "            # -- Step 6.1: Filter DataFrame for current LGA\n",
    "            global lga_filtered, lga_filtered_style\n",
    "            lga_filtered = df_Report_Rate_Facility[df_Report_Rate_Facility['LGA'] == current_lga]  # -- Filter DataFrame to current LGA\n",
    "\n",
    "            MSF_report_rate_msg = f\"No {current_lga} report rate gap found\"  # -- Define message for no gaps\n",
    "\n",
    "            # -- Step 6.2: Apply filtering for gaps\n",
    "            lga_filtered_gap = filter_gap_and_check_empty_df(  # -- Filter LGA-specific subset for gaps\n",
    "                df=lga_filtered,                              # -- Input LGA-filtered DataFrame\n",
    "                msg=MSF_report_rate_msg,                      # -- Message for empty result\n",
    "                opNonZero=MSF_report_rate_columns2,                               # -- No non-zero filter\n",
    "                opNeg=None,                                   # -- No negative filter\n",
    "                opPos=None,                                   # -- No positive filter\n",
    "                opZero=None,                                  # -- No zero filter\n",
    "                opLT100=MSF_report_rate_columns2               # -- Filter for values less than 100\n",
    "            )\n",
    "\n",
    "            if lga_filtered_gap is None:                      # -- Check if no gaps found for this LGA\n",
    "                if current_lga in process_facility_report_rate_gap.cached_styles:  # -- Check if LGA is in cache\n",
    "                    del process_facility_report_rate_gap.cached_styles[current_lga]  # -- Remove LGA from cache\n",
    "                continue                                      # -- Skip to next LGA\n",
    "\n",
    "            # -- Step 6.3: Style the DataFrame\n",
    "            lga_filtered_style = (                            # -- Apply styling to filtered LGA DataFrame\n",
    "                lga_filtered_gap.style                        # -- Start with DataFrame style object\n",
    "                .hide(axis='index')                           # -- Hide index column\n",
    "                .map(outlier_red_report_rate, subset=MSF_report_rate_columns2)  # -- Highlight outliers in red for report rate columns\n",
    "                .map(outlier_green_report_rate)                           # -- Apply green outlier styling (assumed general application)\n",
    "            )\n",
    "\n",
    "            # -- Step 6.4: Cache the styled DataFrame for this LGA\n",
    "            process_facility_report_rate_gap.cached_styles[current_lga] = lga_filtered_style  # -- Store styled DataFrame in cache\n",
    "\n",
    "            # -- Step 6.5: Define export variables\n",
    "            report_name = f\"{current_lga} Facility Report Rate Gap\"  # -- Define report name for current LGA\n",
    "            report_image_name = f\"{current_lga}.png\"          # -- Define image file name for current LGA\n",
    "            report_sheet_name = f\"{current_lga}\"              # -- Define Excel sheet name for current LGA\n",
    "\n",
    "            # -- Step 6.6: Export results\n",
    "            export_df_to_doc_image_excel(                     # -- Export LGA-specific DataFrame to image and Excel\n",
    "                report_name=report_name,                      # -- Pass report name\n",
    "                #df_shape=lga_filtered_gap,                     # -- Pass filtered LGA DataFrame\n",
    "                df_style=lga_filtered_style,                  # -- Pass styled LGA DataFrame\n",
    "                img_file_name=report_image_name,              # -- Pass image file name\n",
    "                img_file_path=sub_folder2_image_file_report_rate,  # -- Pass image file path\n",
    "                doc_description=None,                         # -- No document description (not used)\n",
    "                doc_indicators_to_italicize=None,             # -- No indicators to italicize (not used)\n",
    "                doc_indicators_to_underline=None,             # -- No indicators to underline (not used)\n",
    "                xlm_file_path=doc_file_report_rate_xlsx,      # -- Pass Excel file path\n",
    "                xlm_sheet_name=report_sheet_name              # -- Pass Excel sheet name\n",
    "            )\n",
    "\n",
    "            # -- Step 6.7: Optionally display styled DataFrame\n",
    "            if display_output:                                # -- Check if display is requested\n",
    "                widget_display_df(lga_filtered_style)                   # -- Display styled DataFrame for current LGA\n",
    "            \n",
    "            break\n",
    "\n",
    "        # -- Step 7: Cache overall unfiltered DataFrame shape\n",
    "        process_facility_report_rate_gap.cached_shape = df_Report_Rate_Facility.shape  # -- Cache unfiltered DataFrame shape after processing\n",
    "\n",
    "    except Exception as e:                                    # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing facility report rate gaps: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_facility_report_rate_gap, 'cached_styles'):  # -- Check if cache exists\n",
    "            process_facility_report_rate_gap.cached_styles.clear()  # -- Clear cached styles dictionary\n",
    "        if hasattr(process_facility_report_rate_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_facility_report_rate_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                            # -- Exit function on error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499ec5d3-cc22-4a74-bffd-8c472e3971cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AGYW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf8e4f-4088-4095-a705-da039306b6ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - AGYW HTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba86dda-e3c6-4225-948d-1fac9573f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process AGYW HTS gap\n",
    "def process_AGYW_HTS_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW HTS gap for each LGA, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for LGAs with gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_HTS_columns = [                                  # -- Define list of AGYW HTS columns in desired order\n",
    "            \"Number of AGYW reached with HIV Prevention Program - defined package of service during the reporting period (Community)\",\n",
    "            \"Number of AGYW reached with HIV Prevention Program - defined package of service during the reporting (Walk-In)\",\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Community)\",\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Walk-In)\"\n",
    "        ]\n",
    "        name = \"AGYW HTS gap\"                                 # -- Define general name\n",
    "        AGYW_HTS_gap_columns = ['AGYW HTS gap']               # -- Define gap column name\n",
    "        AGYW_HTS_msg = f\"No {name}\"                           # -- Define message for no gaps\n",
    "        report_name = f\"{name}1\"                              # -- Define report name\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_HTS = prepare_and_convert_df(                 # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key='AGYW MSF',                        # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=AGYW_HTS_columns                     # -- Include specified AGYW HTS columns\n",
    "        )\n",
    "        if df_AGYW_HTS is None:                               # -- Check if data preparation failed\n",
    "            return                                            # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_HTS)\n",
    "        AGYW_HTS_columns2 = wrap_column_headers2(AGYW_HTS_columns)\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_style'): # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_HTS_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_AGYW_HTS.shape             # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:             # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    print(cached_display_name)                # -- Print display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    display(process_AGYW_HTS_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                    # -- Exit function\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Total AGYW reached with HIV Prevention\n",
    "        df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"] = (  # -- Calculate total reached\n",
    "            df_AGYW_HTS[AGYW_HTS_columns2[0]] + df_AGYW_HTS[AGYW_HTS_columns2[1]]  # -- Sum Community and Walk-In\n",
    "        )\n",
    "        # -- Step 4.2: Total AGYW received HIV test & know status\n",
    "        df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] = (  # -- Calculate total tested\n",
    "            df_AGYW_HTS[AGYW_HTS_columns2[2]] + df_AGYW_HTS[AGYW_HTS_columns2[3]]  # -- Sum Community and Walk-In\n",
    "        )\n",
    "        # -- Step 4.3: AGYW HTS gap\n",
    "        df_AGYW_HTS[AGYW_HTS_gap_columns[0]] = np.where(      # -- Calculate gap\n",
    "            df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] > df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"],  # -- Condition for gap\n",
    "            df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] - df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"],  # -- Positive gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_HTS)                                    # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_wrap = wrap_column_headers2(AGYW_HTS_columns)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_HTS_gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_AGYW_HTS_gap = filter_gap_and_check_empty_df(      # -- Filter DataFrame for gaps\n",
    "            df=df_AGYW_HTS,                                   # -- Input DataFrame\n",
    "            msg=AGYW_HTS_msg,                                 # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                   # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                       # -- No negative filter\n",
    "            opPos=None,                                       # -- No positive filter\n",
    "            opZero=None,                                      # -- No zero filter\n",
    "            opLT100=None                                      # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_AGYW_HTS_gap is None:                           # -- Check if no gaps found\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_style'): # -- Check if cache exists\n",
    "                del process_AGYW_HTS_gap.cached_style         # -- Clear cached style\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_shape'): # -- Check if cached shape exists\n",
    "                del process_AGYW_HTS_gap.cached_shape         # -- Clear cached shape\n",
    "            return                                            # -- Exit function\n",
    "        \n",
    "        if df_AGYW_HTS_gap is None:                               # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_AGYW_HTS_gap_style = (                             # -- Apply styling to filtered DataFrame\n",
    "            df_AGYW_HTS_gap.style                             # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                               # -- Hide index column\n",
    "            .map(outlier_red, subset=gap_columns_wrap)    # -- Highlight outliers in gap column\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_AGYW_HTS_gap.cached_style = df_AGYW_HTS_gap_style  # -- Cache styled DataFrame\n",
    "        process_AGYW_HTS_gap.cached_shape = df_AGYW_HTS.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_AGYW_HTS['ReportPeriod'].iloc[0]    # -- Extract report month from DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                       # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create description for Word document\n",
    "        if (df_AGYW_HTS[AGYW_HTS_gap_columns[0]] != 0).any():  # -- Check if any gaps exist\n",
    "            report_description = (                                # -- Define report description\n",
    "                f\"Report Name: {gap_columns_wrap[0]}\"\n",
    "                f\"\\n{AGYW_HTS_columns[2]}\\nplus {AGYW_HTS_columns[3]}\"\n",
    "                f\"\\nshould not be greater than\"\n",
    "                f\"\\n{AGYW_HTS_columns[0]}\\nplus {AGYW_HTS_columns[1]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                         # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                          # -- Pass report name\n",
    "            df_style=df_AGYW_HTS_gap_style,                   # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                  # -- Pass image file name\n",
    "            img_file_path=report_image_path,                  # -- Pass image file path\n",
    "            doc_file_path=doc_file_msf_outlier_docx,          # -- Pass Word document path\n",
    "            doc_description=report_description,               # -- Pass description\n",
    "            doc_indicators_to_italicize=AGYW_HTS_columns,     # -- Italicize AGYW HTS columns\n",
    "            doc_indicators_to_underline=AGYW_HTS_gap_columns, # -- Underline gap column\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,          # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                  # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            widget_display_df(df_AGYW_HTS_gap_style)                    # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                    # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_AGYW_HTS_gap, 'cached_style'):     # -- Check if cache exists\n",
    "            del process_AGYW_HTS_gap.cached_style             # -- Clear cached style\n",
    "        if hasattr(process_AGYW_HTS_gap, 'cached_shape'):     # -- Check if cached shape exists\n",
    "            del process_AGYW_HTS_gap.cached_shape             # -- Clear cached shape\n",
    "        return                                                # -- Exit function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7675d4d-9704-44fe-ad84-c5eaaf9bcb92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - AGYW Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0836337-b8df-43b4-8e3b-0051aa35cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process AGYW Positive gap\n",
    "def process_AGYW_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_Positive_columns = [                             # -- Define list of AGYW Positive columns in desired order\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Community)\",\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Walk-In)\",\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\"\n",
    "        ]\n",
    "        name = \"AGYW Positive gap\"                            # -- Define general name\n",
    "        AGYW_Positive_gap_columns = [\"AGYW tested Positive gap\"]  # -- Define gap column name\n",
    "        AGYW_Positive_msg = f\"No {name}\"                      # -- Define message for no gaps\n",
    "        report_name = f\"{name}2\"                              # -- Define report name\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_Positive = prepare_and_convert_df(            # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key='AGYW MSF',                        # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=AGYW_Positive_columns                # -- Include specified AGYW Positive columns\n",
    "        )\n",
    "        if df_AGYW_Positive is None:                          # -- Check if data preparation failed\n",
    "            return                                            # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_Positive)\n",
    "        AGYW_Positive_columns2 = wrap_column_headers2(AGYW_Positive_columns)\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_Positive_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_AGYW_Positive.shape        # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:             # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    print(cached_display_name)                # -- Print display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    display(process_AGYW_Positive_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                    # -- Exit function\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Total AGYW tested\n",
    "        df_AGYW_Positive[\"Total AGYW tested\"] = (             # -- Calculate total tested\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[0]] +      # -- Add Community tested\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[1]]        # -- Add Walk-In tested\n",
    "        )\n",
    "        # -- Step 4.2: Total AGYW tested positive\n",
    "        df_AGYW_Positive[\"Total AGYW tested positive\"] = (    # -- Calculate total tested positive\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[2]] +      # -- Add Community positive\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[3]]        # -- Add Walk-In positive\n",
    "        )\n",
    "        # -- Step 4.3: AGYW tested Positive gap\n",
    "        df_AGYW_Positive[AGYW_Positive_gap_columns[0]] = np.where(  # -- Calculate gap\n",
    "            df_AGYW_Positive[\"Total AGYW tested positive\"] > df_AGYW_Positive[\"Total AGYW tested\"],  # -- Condition for gap\n",
    "            df_AGYW_Positive[\"Total AGYW tested positive\"] - df_AGYW_Positive[\"Total AGYW tested\"],  # -- Positive gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_Positive)                # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_wrap = wrap_column_headers2(AGYW_Positive_columns)  # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_Positive_gap_columns)  # -- Wrap gap column names\n",
    "        \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_AGYW_Positive_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_AGYW_Positive,                              # -- Input DataFrame\n",
    "            msg=AGYW_Positive_msg,                            # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,              # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                       # -- No negative filter\n",
    "            opPos=None,                                       # -- No positive filter\n",
    "            opZero=None,                                      # -- No zero filter\n",
    "            opLT100=None                                      # -- No less-than-100 filter\n",
    "        )\n",
    "        \n",
    "        if df_AGYW_Positive_gap is None:                      # -- Check if no gaps found\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_AGYW_Positive_gap.cached_style    # -- Clear cached style\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_AGYW_Positive_gap.cached_shape    # -- Clear cached shape\n",
    "            return                                            # -- Exit function\n",
    "        \n",
    "        if df_AGYW_Positive_gap is None:                          # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_AGYW_Positive_gap_style = (                        # -- Apply styling to filtered DataFrame\n",
    "            df_AGYW_Positive_gap.style                        # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                               # -- Hide index column\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # -- Highlight outliers in gap column\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_AGYW_Positive_gap.cached_style = df_AGYW_Positive_gap_style  # -- Cache styled DataFrame\n",
    "        process_AGYW_Positive_gap.cached_shape = df_AGYW_Positive.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_AGYW_Positive_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                       # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create description for Word document\n",
    "        if (df_AGYW_Positive_gap[gap_columns_wrap[0]] != 0).any():  # -- Check if any gaps exist\n",
    "            report_description = (                            # -- Define report description if gaps present\n",
    "                f\"Report Name: {gap_columns_wrap[0]}\"\n",
    "                f\"\\n{AGYW_Positive_columns[2]}\\nplus {AGYW_Positive_columns[3]}\"\n",
    "                f\"\\nshould not be greater than\"\n",
    "                f\"\\n{AGYW_Positive_columns[0]}\\nplus {AGYW_Positive_columns[1]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                         # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                          # -- Pass report name\n",
    "            df_style=df_AGYW_Positive_gap_style,              # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                  # -- Pass image file name\n",
    "            img_file_path=report_image_path,                  # -- Pass image file path\n",
    "            doc_file_path=doc_file_msf_outlier_docx,          # -- Pass Word document path\n",
    "            doc_description=report_description,               # -- Pass description\n",
    "            doc_indicators_to_italicize=AGYW_Positive_columns,  # -- Italicize AGYW Positive columns\n",
    "            doc_indicators_to_underline=AGYW_Positive_gap_columns,  # -- Underline gap column\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,          # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                  # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            widget_display_df(df_AGYW_Positive_gap_style)               # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                    # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_AGYW_Positive_gap.cached_style        # -- Clear cached style\n",
    "        if hasattr(process_AGYW_Positive_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_AGYW_Positive_gap.cached_shape        # -- Clear cached shape\n",
    "        return                                            # -- Exit function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f5aa2-9b2f-4bf2-aa58-a31cbdee5e1b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - AGYW Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719e7182-a5b1-4ac8-b24b-7e4f5169faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process AGYW Positive Linkage gap\n",
    "def process_AGYW_Positive_Linkage_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_Positive_Linkage_columns = [                     # -- Define list of AGYW Positive Linkage columns in desired order\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\",\n",
    "            \"Total number of AGYW who tested HIV Positive and are successfully linked to treatment during the reporting period (Community & Walk-In)\",\n",
    "            \"Linked/Referred for treatment to GF supported site (subset of 4)\",\n",
    "            \"Linked/Referred for treatment to non-GF supported site (subset of 4)\",\n",
    "            \"Number of AGYW newly started on ART during the reporting period\"\n",
    "        ] \n",
    "        name = \"AGYW Positive Linkage gap\"                    # -- Define general name\n",
    "        AGYW_Positive_Linkage_gap_columns = [                 # -- Define list of gap column names\n",
    "            \"AGYW positive linked to treatment gap\",\n",
    "            \"AGYW positive linkage to GF/non-GF supported site gap\",\n",
    "            \"AGYW newly started on ART gap\"\n",
    "        ]\n",
    "        AGYW_Positive_Linkage_msg = f\"No {name}\"              # -- Define message for no gaps\n",
    "        report_name = f\"{name}3\"                              # -- Define report name\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_Positive_Linkage = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key='AGYW MSF',                        # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=AGYW_Positive_Linkage_columns        # -- Include specified AGYW Positive Linkage columns\n",
    "        )\n",
    "        if df_AGYW_Positive_Linkage is None:                  # -- Check if data preparation failed\n",
    "            return                                            # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_Positive_Linkage)\n",
    "        AGYW_Positive_Linkage_columns2 = wrap_column_headers2(AGYW_Positive_Linkage_columns)\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Total AGYW Tested Positive\n",
    "        df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] = (  # -- Calculate total tested positive\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[0]] +  # -- Add Community positive\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[1]]    # -- Add Walk-In positive\n",
    "        )\n",
    "        # -- Step 4.2: AGYW positive linked to treatment gap\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[0]] = np.where(  # -- Calculate linkage gap\n",
    "            df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # -- Condition for gap\n",
    "            df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # -- Gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "        # -- Step 4.3: AGYW positive linkage to GF/non-GF supported site gap\n",
    "        total_linked_to_sites = (                             # -- Precompute total linked to sites\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[3]] +  # -- Add GF supported site\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[4]]    # -- Add non-GF supported site\n",
    "        )\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[1]] = np.where(  # -- Calculate site linkage gap\n",
    "            total_linked_to_sites != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # -- Condition for gap\n",
    "            total_linked_to_sites - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # -- Gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "        # -- Step 4.4: AGYW newly started on ART gap\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[2]] = np.where(  # -- Calculate ART gap\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]] != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[5]],  # -- Condition for gap\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]] - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[5]],  # -- Gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_Positive_Linkage_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_AGYW_Positive_Linkage.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:             # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    print(cached_display_name)                # -- Print display message\n",
    "                    print(f\"-\" * len(cached_display_name))    # -- Print separator line\n",
    "                    display(process_AGYW_Positive_Linkage_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                    # -- Exit function\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_Positive_Linkage)        # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_wrap = wrap_column_headers2(AGYW_Positive_Linkage_columns)  # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_Positive_Linkage_gap_columns)  # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_AGYW_Positive_Linkage_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_AGYW_Positive_Linkage,                      # -- Input DataFrame\n",
    "            msg=AGYW_Positive_Linkage_msg,                    # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,      # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                       # -- No negative filter\n",
    "            opPos=None,                                       # -- No positive filter\n",
    "            opZero=None,                                      # -- No zero filter\n",
    "            opLT100=None                                      # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_AGYW_Positive_Linkage_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_AGYW_Positive_Linkage_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_AGYW_Positive_Linkage_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                            # -- Exit function\n",
    "        \n",
    "        if df_AGYW_Positive_Linkage_gap is None:                          # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_AGYW_Positive_Linkage_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_AGYW_Positive_Linkage_gap.style                # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                               # -- Hide index column\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # -- Highlight outliers in gap columns\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_AGYW_Positive_Linkage_gap.cached_style = df_AGYW_Positive_Linkage_gap_style  # -- Cache styled DataFrame\n",
    "        process_AGYW_Positive_Linkage_gap.cached_shape = df_AGYW_Positive_Linkage.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_AGYW_Positive_Linkage_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                       # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        report_description = []                               # -- Initialize list to collect descriptions\n",
    "        # -- Step 9.1: Add description for AGYW Positive Linkage gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[0]] != 0).any():  # -- Check if linkage gap exists\n",
    "            report_description.append(                           # -- Add description for linkage gap\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[0]}\"\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[0]}\\nplus {AGYW_Positive_Linkage_columns[1]}\"\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns2[2]}\"\n",
    "                f\"\\nNote: Where this AGYW linkage gap is true, please ignore the outlier.\"\n",
    "            )\n",
    "        # -- Step 9.2: Add description for AGYW Positive Linkage to GF/non-GF supported site gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[1]] != 0).any():  # -- Check if site linkage gap exists\n",
    "            report_description.append(                        # -- Add description for site linkage gap\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[1]}\"\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[3]}\\nplus {AGYW_Positive_Linkage_columns[4]}\"\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns2[2]}\"\n",
    "            )\n",
    "        # -- Step 9.3: Add description for AGYW newly started on ART gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[2]] != 0).any():  # -- Check if ART gap exists\n",
    "            report_description.append(                        # -- Add description for ART gap\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[2]}\"\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[5]}\"\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns[2]}\"\n",
    "            )\n",
    "        # -- Step 9.4: Join all descriptions\n",
    "        report_description = \"\\n\\n\".join(report_description)\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                         # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                          # -- Pass report name\n",
    "            df_style=df_AGYW_Positive_Linkage_gap_style,      # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                  # -- Pass image file name\n",
    "            img_file_path=report_image_path,                  # -- Pass image file path\n",
    "            doc_file_path=doc_file_msf_outlier_docx,          # -- Pass Word document path\n",
    "            doc_description=report_description,               # -- Pass description\n",
    "            doc_indicators_to_italicize=AGYW_Positive_Linkage_columns,  # -- Italicize AGYW Positive Linkage columns\n",
    "            doc_indicators_to_underline=AGYW_Positive_Linkage_gap_columns,  # -- Underline gap columns\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,          # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                  # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:                                    # -- Check if display is requested\n",
    "            widget_display_df(df_AGYW_Positive_Linkage_gap_style)       # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                    # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_AGYW_Positive_Linkage_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_AGYW_Positive_Linkage_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                            # -- Exit function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c60e1d-1d65-4bf5-b353-3dad03df1d94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### - AGYW TB Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ceb37e-cf14-4ee8-a62b-422e0d88668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process AGYW TB Screening gap\n",
    "def process_AGYW_TB_Screening_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW TB Screening gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_TB_Screening_columns = [                     # -- Define list of AGYW TB Screening columns in desired order\n",
    "            \"Number of AGYW newly started on ART during the reporting period\",\n",
    "            \"Number of AGYW screened for TB amongst those newly started on ART during the reporting period\"\n",
    "        ]\n",
    "        name = \"AGYW TB Screening gap\"                    # -- Define general name\n",
    "        AGYW_TB_Screening_gap_columns = [\"AGYW TB screening gap\"]  # -- Define list of gap column names\n",
    "        report_name = f\"{name}4\"                          # -- Define report name\n",
    "        AGYW_TB_Screening_msg = f\"No {report_name}\"       # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_TB_Screening = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key='AGYW MSF',                    # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,              # -- Use MSF hierarchy columns\n",
    "            data_columns=AGYW_TB_Screening_columns        # -- Include specified AGYW TB Screening columns\n",
    "        )\n",
    "        if df_AGYW_TB_Screening is None:                  # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_TB_Screening)\n",
    "        AGYW_TB_Screening_columns2 = wrap_column_headers2(AGYW_TB_Screening_columns)\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: AGYW TB Screening gap\n",
    "        df_AGYW_TB_Screening[AGYW_TB_Screening_gap_columns[0]] = np.where(  # -- Calculate TB Screening gap\n",
    "            df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[1]] != df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[0]],  # -- Condition for gap\n",
    "            df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[1]] - df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[0]],  # -- Gap value\n",
    "            0                                                 # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display is requested\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_TB_Screening_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_AGYW_TB_Screening.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:           # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(f\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    print(cached_display_name)              # -- Print display message\n",
    "                    print(f\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    display(process_AGYW_TB_Screening_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                  # -- Exit function\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_TB_Screening)          # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_wrap = wrap_column_headers2(AGYW_TB_Screening_columns)  # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_TB_Screening_gap_columns)  # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_AGYW_TB_Screening_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_AGYW_TB_Screening,                      # -- Input DataFrame\n",
    "            msg=AGYW_TB_Screening_msg,                    # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,      # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                   # -- No negative filter\n",
    "            opPos=None,                                   # -- No positive filter\n",
    "            opZero=None,                                  # -- No zero filter\n",
    "            opLT100=None                                  # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_AGYW_TB_Screening_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_AGYW_TB_Screening_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_AGYW_TB_Screening_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function\n",
    "        \n",
    "        if df_AGYW_TB_Screening_gap is None:                          # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_AGYW_TB_Screening_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_AGYW_TB_Screening_gap.style                # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                           # -- Hide index column\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # -- Highlight outliers in gap columns\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_AGYW_TB_Screening_gap.cached_style = df_AGYW_TB_Screening_gap_style  # -- Cache styled DataFrame\n",
    "        process_AGYW_TB_Screening_gap.cached_shape = df_AGYW_TB_Screening.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_AGYW_TB_Screening_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                   # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        # -- Step 9.1: Add description for AGYW Positive Linkage gap\n",
    "        if (df_AGYW_TB_Screening_gap[gap_columns_wrap[0]] != 0).any():  # -- Check if TB Screening gap exists\n",
    "            report_description = (                        # -- Add description for TB Screening gap\n",
    "                f\"Report Name: {AGYW_TB_Screening_gap_columns[0]}\"\n",
    "                f\"\\n{AGYW_TB_Screening_columns[1]}\\nshould be equal to {AGYW_TB_Screening_columns[0]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                     # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                      # -- Pass report name\n",
    "            df_style=df_AGYW_TB_Screening_gap_style,      # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,              # -- Pass image file name\n",
    "            img_file_path=report_image_path,              # -- Pass image file path\n",
    "            doc_file_path=doc_file_msf_outlier_docx,      # -- Pass Word document path\n",
    "            doc_description=report_description,           # -- Pass description\n",
    "            doc_indicators_to_italicize=AGYW_TB_Screening_columns,  # -- Italicize AGYW Positive Linkage columns\n",
    "            doc_indicators_to_underline=AGYW_TB_Screening_gap_columns,  # -- Underline gap columns\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,      # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name              # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:                                # -- Check if display is requested\n",
    "            widget_display_df(df_AGYW_TB_Screening_gap_style)       # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_AGYW_TB_Screening_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_AGYW_TB_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_AGYW_TB_Screening_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                            # -- Exit function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7503ceb-91b9-4a14-a53f-371916158c75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98450f84-6881-4b7a-971d-f09a53acf359",
   "metadata": {},
   "source": [
    "#### - ART Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac2e50d-78e2-4f50-bbd8-087bebb4eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ART positive and enrollment gap\n",
    "def process_ART_PosEnrolment_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART Positive and Enrolment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_PosEnrolment_columns = [                       # -- Define list of ART positive and enrollment columns\n",
    "            \"ART 1: Number of HIV positive persons newly enrolled in clinical care during the month\",\n",
    "            \"ART 2: Number of people living with HIV newly started on ART during the month (excludes ART transfer-in)\"\n",
    "        ]\n",
    "        ART_PosEnrolment_columns_desrpt = ART_PosEnrolment_columns + [\"Total Tested Positive\"]  # -- Extended list for description\n",
    "        name = \"ART Positive-Enrolment gap\"                # -- General report name\n",
    "        ART_PosEnrolment_gap_columns = [\"ART Enrolment gap\", \"ART Linkage gap\"]  # -- Gap column names\n",
    "        report_name = f\"{name}5\"                           # -- Report name with suffix\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_PosEnrolment = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key='ART MSF',                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_PosEnrolment_columns          # -- ART columns\n",
    "        )\n",
    "\n",
    "        # -- Step 3: Merge with external DataFrame\n",
    "        df_ART_PosEnrolment = Pre_MSF_positives_all.merge(  # -- Merge with positives data\n",
    "            df_ART_PosEnrolment,                           # -- Merge target\n",
    "            on=[\"ReportPeriod\", \"Cluster\", \"LGA\", \"FacilityName\"],  # -- Merge keys\n",
    "            how=\"left\"                                    # -- Keep all rows from df_ART_PosEnrolment\n",
    "        )\n",
    "        df_ART_PosEnrolment = df_ART_PosEnrolment.fillna(0)  # -- Step 3.1: Fill NaN with 0\n",
    "        float_columns = df_ART_PosEnrolment.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                          # -- Step 3.2: Cast float to int\n",
    "            df_ART_PosEnrolment[col] = df_ART_PosEnrolment[col].astype(int)\n",
    "\n",
    "        wrap_column_headers(df_ART_PosEnrolment)\n",
    "        ART_PosEnrolment_columns2 = wrap_column_headers2(ART_PosEnrolment_columns)\n",
    "\n",
    "        # -- Step 6: Calculate derived metrics\n",
    "        # -- Step 6.1: ART enrolment gap\n",
    "        df_ART_PosEnrolment[ART_PosEnrolment_gap_columns[0]] = np.where(  \n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]] != df_ART_PosEnrolment[\"Total new positive\"],\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]] - df_ART_PosEnrolment[\"Total new positive\"],\n",
    "            0\n",
    "        )\n",
    "        # -- Step 6.2: ART linkage gap\n",
    "        df_ART_PosEnrolment[ART_PosEnrolment_gap_columns[1]] = np.where(  \n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[1]] != df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]],\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[1]] - df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_PosEnrolment_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_PosEnrolment.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    for cluster, style in process_ART_PosEnrolment_gap.cached_styles.items():  # -- Iterate cached styles\n",
    "                        cached_display_name = f\"✔️ Displaying {cluster} {report_name} \"  # -- Display message\n",
    "                        print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                        print(cached_display_name)            # -- Message\n",
    "                        print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                        display(style)                        # -- Display cached style\n",
    "                    return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Initialize cache\n",
    "        if not hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # -- Check if cache exists\n",
    "            process_ART_PosEnrolment_gap.cached_styles = {}  # -- Initialize cache\n",
    "\n",
    "        # -- Step 7: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_ART_PosEnrolment['Cluster'].unique())  # -- Extract unique clusters\n",
    "\n",
    "        # -- Step 8: Process each cluster\n",
    "        for current_cluster in cluster_list:               # -- Iterate over clusters\n",
    "            cluster_filtered = df_ART_PosEnrolment[df_ART_PosEnrolment['Cluster'] == current_cluster]  # -- Step 8.1: Filter cluster\n",
    "            \n",
    "            ART_PosEnrolment_msg = f\"No {current_cluster} {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=cluster_filtered,\n",
    "                msg=ART_PosEnrolment_msg,\n",
    "                opNonZero=ART_PosEnrolment_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "            if cluster_filtered_gap is None:               # -- Check if no gaps\n",
    "                if current_cluster in process_ART_PosEnrolment_gap.cached_styles:  # -- Remove from cache\n",
    "                    del process_ART_PosEnrolment_gap.cached_styles[current_cluster]\n",
    "                continue                                   # -- Skip cluster\n",
    "\n",
    "            cluster_filtered_style = (                     # -- Step 8.3: Style DataFrame\n",
    "                cluster_filtered_gap.style\n",
    "                .hide(axis='index')\n",
    "                .map(outlier_red, subset=ART_PosEnrolment_gap_columns)\n",
    "            )\n",
    "\n",
    "            process_ART_PosEnrolment_gap.cached_styles[current_cluster] = cluster_filtered_style  # -- Step 8.4: Cache style\n",
    "\n",
    "            # -- Step 8.5: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # -- Cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # -- Image file name\n",
    "            #report_image_path = rf\"{sub_folder2_image_file_msf_outlier}\\{report_image_name}\"  # -- Image path\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # -- Excel sheet name\n",
    "\n",
    "            # -- Step 9: Create descriptions\n",
    "            report_description = []                        # -- Initialize descriptions\n",
    "            if (cluster_filtered_gap[ART_PosEnrolment_gap_columns[0]] != 0).any():  # -- Step 9.1: Enrolment gap desc\n",
    "                report_description.append(\n",
    "                    f\"Report Name: {ART_PosEnrolment_gap_columns[0]}\\n\"\n",
    "                    f\"{ART_PosEnrolment_columns_desrpt[0]}\\nshould be equal to {ART_PosEnrolment_columns_desrpt[2]}\\n\"\n",
    "                    f\"Note: Where this ART enrolment gap is true, please ignore the outlier.\"\n",
    "                )\n",
    "            if (cluster_filtered_gap[ART_PosEnrolment_gap_columns[1]] != 0).any():  # -- Step 9.2: Linkage gap desc\n",
    "                report_description.append(\n",
    "                    f\"Report Name: {ART_PosEnrolment_gap_columns[1]}\\n\"\n",
    "                    f\"{ART_PosEnrolment_columns_desrpt[1]}\\nshould be equal to {ART_PosEnrolment_columns_desrpt[0]}\\n\"\n",
    "                    f\"Note: Where this ART linkage gap is true, please ignore the outlier.\"\n",
    "                )\n",
    "            report_description = \"\\n\\n\".join(report_description)  # -- Step 9.3: Join descriptions\n",
    "\n",
    "            # -- Step 10: Export results\n",
    "            export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "                report_name=report_name_cluster,\n",
    "                df_style=cluster_filtered_style,\n",
    "                img_file_name=report_image_name,\n",
    "                img_file_path=sub_folder2_image_file_msf_outlier,\n",
    "                doc_description=report_description,\n",
    "                doc_indicators_to_italicize=ART_PosEnrolment_columns_desrpt,\n",
    "                doc_indicators_to_underline=ART_PosEnrolment_gap_columns,\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "                xlm_sheet_name=report_sheet_name\n",
    "            )\n",
    "\n",
    "            if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "                widget_display_df(cluster_filtered_style)\n",
    "\n",
    "        # -- Step 12: Cache overall unfiltered DataFrame shape\n",
    "        process_ART_PosEnrolment_gap.cached_shape = df_ART_PosEnrolment.shape  # -- Cache shape\n",
    "\n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_PosEnrolment_gap.cached_styles.clear()\n",
    "        if hasattr(process_ART_PosEnrolment_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_PosEnrolment_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f1f49",
   "metadata": {},
   "source": [
    "#### - ART Regimen Line, MMD and DSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3bc25-ae6d-4ee8-bf86-039d7e0f061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ART regimen line, MMD and SDS gap\n",
    "def process_ART_RegimentLine_MMD_DSD_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART Regimen line, MMD and DSD gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_RegimenLine_MMD_DSD_columns = [                       # -- Define list of ART positive and enrollment columns\n",
    "            \"ART 3: Number of people living with HIV who are currently receiving ART during the month (All regimens)\",\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens): By Regimen Line\",\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens) - Multi-Month Dispensing\",\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens) - DSD Model\"\n",
    "        ]\n",
    "        name = \"ART Regimen-Line MMD DSD gap\"              # -- General report name\n",
    "        ART_RegimenLine_MMD_DSD_gap_columns = [\"ART Regimen Line gap\", \"ART MMD gap\", \"ART DSD gap\"]  # -- Gap column names\n",
    "        report_name = f\"{name}6\"                           # -- Report name with suffix\n",
    "        ART_RegimenLine_MMD_DSD_msg = f\"No {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_RegimenLine_MMD_DSD = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF\",                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_RegimenLine_MMD_DSD_columns          # -- ART regimne columns\n",
    "        )\n",
    "        if df_ART_RegimenLine_MMD_DSD is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_ART_RegimenLine_MMD_DSD)\n",
    "        ART_RegimenLine_MMD_DSD_columns2 = wrap_column_headers2(ART_RegimenLine_MMD_DSD_columns)\n",
    "\n",
    "        # -- Step : ART regimen line gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[0]] = np.where(  \n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] != df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[1]],\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[1]],\n",
    "            0\n",
    "        )\n",
    "        # -- Step : ART MMD gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[1]] = np.where(  \n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] < df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[2]],\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[2]],\n",
    "            0\n",
    "        )\n",
    "        # -- Step : ART DSD gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[2]] = np.where(  \n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] < df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[3]],\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[3]],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_style'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_RegimenLine_MMD_DSD.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    print(cached_display_name)            # -- Message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    display(process_ART_RegimentLine_MMD_DSD_gap.cached_style)                        # -- Display cached style\n",
    "                return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_RegimenLine_MMD_DSD_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=df_ART_RegimenLine_MMD_DSD,\n",
    "                msg=ART_RegimenLine_MMD_DSD_msg,\n",
    "                opNonZero=ART_RegimenLine_MMD_DSD_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "        if df_ART_RegimenLine_MMD_DSD_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_ART_RegimentLine_MMD_DSD_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ART_RegimentLine_MMD_DSD_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function      \n",
    "\n",
    "        if df_ART_RegimenLine_MMD_DSD_gap is None:                          # -- Check if data preparation failed\n",
    "            return                         \n",
    "\n",
    "        df_ART_RegimenLine_MMD_DSD_gap_style = (                     # -- Step 8.3: Style DataFrame\n",
    "            df_ART_RegimenLine_MMD_DSD_gap.style\n",
    "            .hide(axis='index')\n",
    "            .map(outlier_red, subset=ART_RegimenLine_MMD_DSD_gap_columns)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_RegimentLine_MMD_DSD_gap.cached_style = df_ART_RegimenLine_MMD_DSD_gap_style  # -- Cache styled DataFrame\n",
    "        process_ART_RegimentLine_MMD_DSD_gap.cached_shape = df_ART_RegimenLine_MMD_DSD.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8.5: Define export variables\n",
    "        report_month = df_ART_RegimenLine_MMD_DSD_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"                # -- Image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Image path\n",
    "        report_sheet_name = f\"{report_name}\"                                   # -- Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions\n",
    "        report_description = []                        # -- Initialize descriptions\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[0]] != 0).any():  # -- Step 9.1: ART regimen line gap\n",
    "            report_description.append(\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[0]}\\n\"\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be equal to {ART_RegimenLine_MMD_DSD_columns[1]}\"\n",
    "            )\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[1]] != 0).any():  # -- Step 9.2: ART MMD gap\n",
    "            report_description.append(\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[1]}\\n\"\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be greater than {ART_RegimenLine_MMD_DSD_columns[2]}\\n\"\n",
    "            )\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[2]] != 0).any():  # -- Step 9.2: ART DSD gap\n",
    "            report_description.append(\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[2]}\\n\"\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be greater than {ART_RegimenLine_MMD_DSD_columns[3]}\\n\"\n",
    "            )\n",
    "        report_description = \"\\n\\n\".join(report_description)  # -- Step 9.3: Join descriptions\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "            report_name=report_name,\n",
    "            df_style=df_ART_RegimenLine_MMD_DSD_gap_style,\n",
    "            img_file_name=report_image_name,\n",
    "            img_file_path=report_image_path,\n",
    "            doc_description=report_description,\n",
    "            doc_indicators_to_italicize=ART_RegimenLine_MMD_DSD_columns,\n",
    "            doc_indicators_to_underline=ART_RegimenLine_MMD_DSD_gap_columns,\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "            xlm_sheet_name=report_sheet_name\n",
    "        )\n",
    "\n",
    "        if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "            widget_display_df(df_ART_RegimenLine_MMD_DSD_gap_style)\n",
    "            \n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_RegimentLine_MMD_DSD_gap.cached_style.clear()\n",
    "        if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_RegimentLine_MMD_DSD_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815c1df4",
   "metadata": {},
   "source": [
    "#### - ART TB Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80980f5-5c31-4577-81e2-b8918fedf27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ARTTB Screening gap\n",
    "def process_ART_TB_Screening_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART Regimen line, MMD and DSD gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Screening_columns = [\"ART 2: Number of people living with HIV newly started on ART during the month (excludes ART transfer-in)\"]\n",
    "        place_holder = [\"ART 10: Number of PLHIV on ART (Including PMTCT) who were Clinically Screened for TB in HIV Treatment Settings\"]\n",
    "        ART_TB_Screening_columns_new_old = ['Newly on ART', 'Already on ART']  # -- Define list of ART TB Screening columns\n",
    "\n",
    "        ART_TB_Screening_columns_desrpt = [\n",
    "            ART_TB_Screening_columns[0],\n",
    "            place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[0],\n",
    "            place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[1]\n",
    "        ]  # -- Extended list for description\n",
    "\n",
    "        name = \"ART Tx_New TB Screening gap\"              # -- General report name\n",
    "        ART_TB_Screening_gap_columns = ['ART Tx New TB screening gap']  # -- Gap column names\n",
    "        report_name = f\"{name}7\"                           # -- Report name with suffix\n",
    "        ART_RegimenLine_MMD_DSD_msg = f\"No {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Screening = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF\",                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_TB_Screening_columns          # -- ART regimne columns\n",
    "        )\n",
    "        if df_ART_TB_Screening is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 2.1: Prepare TB screening data\n",
    "        df_ART_TB_Screening_new_old = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF_tb screening\",        # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_TB_Screening_columns_new_old   # -- ART regimne columns\n",
    "        )\n",
    "        if df_ART_TB_Screening_new_old is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Merge with external DataFrame\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.merge(  # -- Merge with ART_tb screening data\n",
    "            df_ART_TB_Screening_new_old,                           # -- Merge target\n",
    "            on=[\"ReportPeriod\", \"Cluster\", \"LGA\", \"FacilityName\"],  # -- Merge keys\n",
    "            how=\"left\"                                    # -- Keep all rows from df_ART_PosEnrolment\n",
    "        )\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.fillna(0)  # -- Step 3.1: Fill NaN with 0\n",
    "        float_columns = df_ART_TB_Screening.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                          # -- Step 3.2: Cast float to int\n",
    "            df_ART_TB_Screening[col] = df_ART_TB_Screening[col].astype(int)\n",
    "        \n",
    "        # -- Step 3.3: Rename columns\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.rename(columns={\n",
    "            'Newly on ART': place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[0],\n",
    "            'Already on ART': place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[1]}\n",
    "        )   \n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Screening)\n",
    "        ART_TB_Screening_columns2 = wrap_column_headers2(ART_TB_Screening_columns_desrpt)\n",
    "\n",
    "        # -- Step : ART TB Screening gap\n",
    "        df_ART_TB_Screening[ART_TB_Screening_gap_columns[0]] = np.where(  \n",
    "            df_ART_TB_Screening[ART_TB_Screening_columns2[0]] != df_ART_TB_Screening[ART_TB_Screening_columns2[1]],\n",
    "            df_ART_TB_Screening[ART_TB_Screening_columns2[0]] - df_ART_TB_Screening[ART_TB_Screening_columns2[1]],\n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_style'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_TB_Screening_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_TB_Screening.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    print(cached_display_name)            # -- Message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    display(process_ART_TB_Screening_gap.cached_style)                        # -- Display cached style\n",
    "                return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_TB_Screening_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=df_ART_TB_Screening,\n",
    "                msg=ART_RegimenLine_MMD_DSD_msg,\n",
    "                opNonZero=ART_TB_Screening_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "        if df_ART_TB_Screening_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_ART_TB_Screening_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ART_TB_Screening_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function                       \n",
    "\n",
    "        if df_ART_TB_Screening_gap is None:      # -- Check if data preparation failed\n",
    "            return\n",
    "\n",
    "        df_ART_TB_Screening_gap_style = (                     # -- Step 8.3: Style DataFrame\n",
    "            df_ART_TB_Screening_gap.style\n",
    "            .hide(axis='index')\n",
    "            .map(outlier_red, subset=ART_TB_Screening_gap_columns)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Screening_gap.cached_style = df_ART_TB_Screening_gap_style  # -- Cache styled DataFrame\n",
    "        process_ART_TB_Screening_gap.cached_shape = df_ART_TB_Screening.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8.5: Define export variables\n",
    "        report_month = df_ART_TB_Screening_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"                # -- Image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Image path\n",
    "        report_sheet_name = f\"{report_name}\"                                   # -- Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions\n",
    "        if (df_ART_TB_Screening_gap[ART_TB_Screening_gap_columns[0]] != 0).any():  # -- Step 9.1: ART regimen line gap\n",
    "            report_description = (\n",
    "                f\"Report Name: {ART_TB_Screening_gap_columns[0]}\\n\"\n",
    "                f\"{ART_TB_Screening_columns_desrpt[0]}\\nshould be equal to {ART_TB_Screening_columns_desrpt[1]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "            report_name=report_name,\n",
    "            df_style=df_ART_TB_Screening_gap_style,\n",
    "            img_file_name=report_image_name,\n",
    "            img_file_path=report_image_path,\n",
    "            doc_description=report_description,\n",
    "            doc_indicators_to_italicize=ART_TB_Screening_columns_desrpt,\n",
    "            doc_indicators_to_underline=ART_TB_Screening_gap_columns,\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "            xlm_sheet_name=report_sheet_name\n",
    "        )\n",
    "\n",
    "        if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "            widget_display_df(df_ART_TB_Screening_gap_style)\n",
    "            \n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_TB_Screening_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_TB_Screening_gap.cached_style.clear()\n",
    "        if hasattr(process_ART_TB_Screening_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_TB_Screening_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf3157",
   "metadata": {},
   "source": [
    "#### - ART TB Presumptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d4cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ART Presumptive Test gap\n",
    "def process_ART_TB_Presumptive_Test_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART Presumptive Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Presumptive_Test_columns = [                       # -- Define list of ART presumptive test columns\n",
    "            \"ART 11: Number of PLHIV on ART with Presumptive TB during the month\",\n",
    "            \"ART 12: Number of PLHIV on ART with Presumptive TB and Tested for TB during the month\"\n",
    "        ]\n",
    "        name = \"ART TB Presumptive Test gap\"              # -- General report name\n",
    "        ART_TB_Presumptive_Test_gap_columns = [\"ART TB presumptive test gap\"]  # -- Gap column names\n",
    "        report_name = f\"{name}8\"                           # -- Report name with suffix\n",
    "        ART_TB_Presumptive_Test_msg = f\"No {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Presumptive_Test = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF\",                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_TB_Presumptive_Test_columns          # -- ART TB presumptive test columns\n",
    "        )\n",
    "        if df_ART_TB_Presumptive_Test is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Presumptive_Test)\n",
    "        ART_TB_Presumptive_Test_columns2 = wrap_column_headers2(ART_TB_Presumptive_Test_columns)\n",
    "\n",
    "        # -- Step : ART regimen line gap\n",
    "        df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_gap_columns[0]] = np.where(  \n",
    "            df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[0]] != df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[1]],\n",
    "            df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[0]] - df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[1]],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_style'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_TB_Presumptive_Test.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    print(cached_display_name)            # -- Message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    display(process_ART_TB_Presumptive_Test_gap.cached_style)                        # -- Display cached style\n",
    "                return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_TB_Presumptive_Test_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=df_ART_TB_Presumptive_Test,\n",
    "                msg=ART_TB_Presumptive_Test_msg,\n",
    "                opNonZero=ART_TB_Presumptive_Test_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "        if df_ART_TB_Presumptive_Test_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_ART_TB_Presumptive_Test_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ART_TB_Presumptive_Test_gap.cached_shape  # -- Clear cached shape\n",
    "            return   \n",
    "        \n",
    "        if df_ART_TB_Presumptive_Test_gap is None:      # -- Check if data preparation failed\n",
    "            return                                       # -- Exit function                              # -- Skip cluster\n",
    "\n",
    "        df_ART_TB_Presumptive_Test_gap_style = (                     # -- Step 8.3: Style DataFrame\n",
    "            df_ART_TB_Presumptive_Test_gap.style\n",
    "            .hide(axis='index')\n",
    "            .map(outlier_red, subset=ART_TB_Presumptive_Test_gap_columns)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Presumptive_Test_gap.cached_style = df_ART_TB_Presumptive_Test_gap_style  # -- Cache styled DataFrame\n",
    "        process_ART_TB_Presumptive_Test_gap.cached_shape = df_ART_TB_Presumptive_Test.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8.5: Define export variables\n",
    "        report_month = df_ART_TB_Presumptive_Test_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"                # -- Image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Image path\n",
    "        report_sheet_name = f\"{report_name}\"                                   # -- Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions\n",
    "        if (df_ART_TB_Presumptive_Test_gap[ART_TB_Presumptive_Test_gap_columns[0]] != 0).any():  # -- Step 9.1: ART regimen line gap\n",
    "            report_description = (\n",
    "                f\"Report Name: {ART_TB_Presumptive_Test_gap_columns[0]}\\n\"\n",
    "                f\"{ART_TB_Presumptive_Test_columns[0]}\\nshould be equal to {ART_TB_Presumptive_Test_columns[1]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "            report_name=report_name,\n",
    "            df_style=df_ART_TB_Presumptive_Test_gap_style,\n",
    "            img_file_name=report_image_name,\n",
    "            img_file_path=report_image_path,\n",
    "            doc_description=report_description,\n",
    "            doc_indicators_to_italicize=ART_TB_Presumptive_Test_columns,\n",
    "            doc_indicators_to_underline=ART_TB_Presumptive_Test_gap_columns,\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "            xlm_sheet_name=report_sheet_name\n",
    "        )\n",
    "\n",
    "        if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "            widget_display_df(df_ART_TB_Presumptive_Test_gap_style)\n",
    "            \n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_TB_Presumptive_Test_gap.cached_style.clear()\n",
    "        if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_TB_Presumptive_Test_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eab5d51",
   "metadata": {},
   "source": [
    "#### - ART TB Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ART TB Treatment gap\n",
    "def process_ART_TB_Treatment_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART TB Treatment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Treatment_columns = [                       # -- Define list of ART TB treatment columns\n",
    "            \"ART 13: Number of of PLHIV on ART who have Active TB Disease\",\n",
    "            \"ART 14: Number of PLHIV on ART with active TB disease who initiated TB treatment\"\n",
    "        ]\n",
    "        name = \"ART TB Treatment gap\"              # -- General report name\n",
    "        ART_TB_Treatment_gap_columns = [\"ART TB treatment gap\"]  # -- Gap column names\n",
    "        report_name = f\"{name}9\"                           # -- Report name with suffix\n",
    "        ART_TB_Treatment_msg = f\"No {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Treatment = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF\",                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_TB_Treatment_columns          # -- ART TB pretretament columns\n",
    "        )\n",
    "        if df_ART_TB_Treatment is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Treatment)\n",
    "        ART_TB_Treatment_columns_wrap = wrap_column_headers2(ART_TB_Treatment_columns)\n",
    "\n",
    "        # -- Step : ART regimen line gap\n",
    "        df_ART_TB_Treatment[ART_TB_Treatment_gap_columns[0]] = np.where(  \n",
    "            df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[0]] != df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[1]],\n",
    "            df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[0]] - df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[1]],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_style'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_TB_Treatment_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_TB_Treatment.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    print(cached_display_name)            # -- Message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    display(process_ART_TB_Treatment_gap.cached_style)  # -- Display cached style\n",
    "                return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_TB_Treatment_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=df_ART_TB_Treatment,\n",
    "                msg=ART_TB_Treatment_msg,\n",
    "                opNonZero=ART_TB_Treatment_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "        if df_ART_TB_Treatment_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_ART_TB_Treatment_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ART_TB_Treatment_gap.cached_shape  # -- Clear cached shape\n",
    "            return  \n",
    "        \n",
    "        if df_ART_TB_Treatment_gap is None:      # -- Check if data preparation failed\n",
    "            return                                      # -- Exit function                             \n",
    "\n",
    "        df_ART_TB_Treatment_gap_style = (                     # -- Step 8.3: Style DataFrame\n",
    "            df_ART_TB_Treatment_gap.style\n",
    "            .hide(axis='index')\n",
    "            .map(outlier_red, subset=ART_TB_Treatment_gap_columns)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Treatment_gap.cached_style = df_ART_TB_Treatment_gap_style  # -- Cache styled DataFrame\n",
    "        process_ART_TB_Treatment_gap.cached_shape = df_ART_TB_Treatment.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8.5: Define export variables\n",
    "        report_month = df_ART_TB_Treatment_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"                # -- Image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Image path\n",
    "        report_sheet_name = f\"{report_name}\"                                   # -- Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions\n",
    "        if (df_ART_TB_Treatment_gap[ART_TB_Treatment_gap_columns[0]] != 0).any():  # -- Step 9.1: ART regimen line gap\n",
    "            report_description = (\n",
    "                f\"Report Name: {ART_TB_Treatment_gap_columns[0]}\\n\"\n",
    "                f\"{ART_TB_Treatment_columns[1]}\\nshould be equal to {ART_TB_Treatment_columns[0]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "            report_name=report_name,\n",
    "            df_style=df_ART_TB_Treatment_gap_style,\n",
    "            img_file_name=report_image_name,\n",
    "            img_file_path=report_image_path,\n",
    "            doc_description=report_description,\n",
    "            doc_indicators_to_italicize=ART_TB_Treatment_columns,\n",
    "            doc_indicators_to_underline=ART_TB_Treatment_gap_columns,\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "            xlm_sheet_name=report_sheet_name\n",
    "        )\n",
    "\n",
    "        if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "            widget_display_df(df_ART_TB_Treatment_gap_style)\n",
    "            \n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_TB_Treatment_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_TB_Treatment_gap.cached_style.clear()\n",
    "        if hasattr(process_ART_TB_Treatment_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_TB_Treatment_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127532af",
   "metadata": {},
   "source": [
    "#### - ART Viral Load Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf446865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ART Viral Load Suppression gap\n",
    "def process_ART_Viral_Load_Suppression_gap(display_output=None):          # -- Define function\n",
    "    \"\"\"\n",
    "    Process ART Viral Laod Suppression gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_Viral_Load_Suppression_columns = [                       # -- Define list of ART viral load suppression columns\n",
    "            \"ART 6: Number of PLHIV on ART for at least 6 months with a VL test result during the month: Routine\",\n",
    "            \"ART 6: Number of PLHIV on ART for at least 6 months with a VL test result during the month: Targeted\",\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month: Routine\",\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month: Targeted\"\n",
    "        ]\n",
    "        ART_Viral_Load_Suppression_columns_cal = [\n",
    "            \"ART 6: Number of PLHIV on ART for at least 6 months with a VL test result during the month - Routine and Targated\",\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month - Routine and Targated\"\n",
    "        ]\n",
    "        name = \"ART Viral Load Suppression gap\"            # -- General report name\n",
    "        ART_Viral_Load_Suppression_gap_columns = [\"ART viral load suppression gap\"]  # -- Gap column names\n",
    "        report_name = f\"{name}10\"                          # -- Report name with suffix\n",
    "        No_gap_msg = f\"No {report_name}\"                   # -- Message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_Viral_Load_Suppression = prepare_and_convert_df(      # -- Fetch and prepare DataFrame\n",
    "            DHIS2_data_key=\"ART MSF\",                      # -- DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,               # -- MSF hierarchy columns\n",
    "            data_columns=ART_Viral_Load_Suppression_columns          # -- ART TB pretretament columns\n",
    "        )\n",
    "        if df_ART_Viral_Load_Suppression is None:      # -- Check if data preparation failed\n",
    "            return                                        # -- Exit function if no data\n",
    "\n",
    "        # -- Step : Calculate total viral laod results recieved\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_cal[0]] = (  \n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[0]] + df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[1]]\n",
    "        )\n",
    "\n",
    "        # -- Step : Calculate total viral laod results suppressed\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_cal[1]] = (  \n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[2]] + df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[3]]\n",
    "        )\n",
    "\n",
    "        # -- Step: Drop the original Routine and Targeted columns\n",
    "        df_ART_Viral_Load_Suppression = df_ART_Viral_Load_Suppression.drop(\n",
    "            columns=[\n",
    "                ART_Viral_Load_Suppression_columns[0],  # Routine (ART 6)\n",
    "                ART_Viral_Load_Suppression_columns[1],  # Targeted (ART 6)\n",
    "                ART_Viral_Load_Suppression_columns[2],  # Routine (ART 7)\n",
    "                ART_Viral_Load_Suppression_columns[3]   # Targeted (ART 7)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        wrap_column_headers(df_ART_Viral_Load_Suppression)\n",
    "        ART_Viral_Load_Suppression_columns_wrap = wrap_column_headers2(ART_Viral_Load_Suppression_columns_cal)\n",
    "\n",
    "        # -- Step : Viral load suppression gap\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_gap_columns[0]] = np.where(  \n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[1]] > df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[0]],\n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[1]] - df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[0]],\n",
    "            0\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_style'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_ART_Viral_Load_Suppression.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    print(cached_display_name)            # -- Message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                    display(process_ART_Viral_Load_Suppression_gap.cached_style)  # -- Display cached style\n",
    "                return                                 # -- Exit if cache used\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_Viral_Load_Suppression_gap = filter_gap_and_check_empty_df(  # -- Step 8.2: Filter gaps\n",
    "                df=df_ART_Viral_Load_Suppression,\n",
    "                msg=No_gap_msg,\n",
    "                opNonZero=ART_Viral_Load_Suppression_gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "        if df_ART_Viral_Load_Suppression_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_ART_Viral_Load_Suppression_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ART_Viral_Load_Suppression_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function                            \n",
    "        \n",
    "        if df_ART_Viral_Load_Suppression_gap is None:      # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        df_ART_Viral_Load_Suppression_gap_style = (                     # -- Step 8.3: Style DataFrame\n",
    "            df_ART_Viral_Load_Suppression_gap.style\n",
    "            .hide(axis='index')\n",
    "            .map(outlier_red, subset=ART_Viral_Load_Suppression_gap_columns)\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_Viral_Load_Suppression_gap.cached_style = df_ART_Viral_Load_Suppression_gap_style  # -- Cache styled DataFrame\n",
    "        process_ART_Viral_Load_Suppression_gap.cached_shape = df_ART_Viral_Load_Suppression.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 8.5: Define export variables\n",
    "        report_month = df_ART_Viral_Load_Suppression_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"                # -- Image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Image path\n",
    "        report_sheet_name = f\"{report_name}\"                                   # -- Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions\n",
    "        if (df_ART_Viral_Load_Suppression_gap[ART_Viral_Load_Suppression_gap_columns[0]] != 0).any():  # -- Step 9.1: ART regimen line gap\n",
    "            report_description = (\n",
    "                f\"Report Name: {ART_Viral_Load_Suppression_gap_columns[0]}\\n\"\n",
    "                f\"{ART_Viral_Load_Suppression_columns[2]}\\nplus{ART_Viral_Load_Suppression_columns[3]}\\n\"\n",
    "                f\"should not be greater than {ART_Viral_Load_Suppression_columns[0]}\\nplus{ART_Viral_Load_Suppression_columns[1]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "            report_name=report_name,\n",
    "            df_style=df_ART_Viral_Load_Suppression_gap_style,\n",
    "            img_file_name=report_image_name,\n",
    "            img_file_path=report_image_path,\n",
    "            doc_description=report_description,\n",
    "            doc_indicators_to_italicize=ART_Viral_Load_Suppression_columns,\n",
    "            doc_indicators_to_underline=ART_Viral_Load_Suppression_gap_columns,\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "            xlm_sheet_name=report_sheet_name\n",
    "        )\n",
    "\n",
    "        if display_output:                             # -- Step 11: Display styled DataFrame\n",
    "            widget_display_df(df_ART_Viral_Load_Suppression_gap_style)\n",
    "            \n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_ART_Viral_Load_Suppression_gap.cached_style.clear()\n",
    "        if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_ART_Viral_Load_Suppression_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295aab1",
   "metadata": {},
   "source": [
    "### HTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33641b7",
   "metadata": {},
   "source": [
    "#### - HTS New Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71380eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HTS New Positive gap\n",
    "def process_HTS_New_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS New Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_New_Positive_columns = [                     # -- Define list of HTS New Positive columns\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Number of people who tested HIV positive and received results (Community)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\",\n",
    "            \"HTS total tested - positive\",\n",
    "            \"HTS total tested - previously known positive\",\n",
    "            \"HTS total tested - new positive (excluding previously known)\",\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient)\",\n",
    "            \"Number of people who tested HIV positive and received results (Outpatient)\",\n",
    "            \"Number of people who tested HIV positive and received results (Standalone)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Inpatient)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Outpatient)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Standalone)\"\n",
    "        ]\n",
    "\n",
    "        HTS_New_Positive_columns_order = [               # -- Define the desired order of columns\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Number of people who tested HIV positive and received results (Community)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\",\n",
    "            \"HTS total tested - positive\",\n",
    "            \"HTS total tested - previously known positive\",\n",
    "            \"HTS total tested - new positive (excluding previously known)\"\n",
    "        ]\n",
    "        \n",
    "        Gap_title_special = [\"Community testing gap\"]    # -- Define special gap title\n",
    "        name = \"HTS New Positive gap\"                    # -- Define general name\n",
    "        HTS_New_Positive_gap_columns = [\"HTS total tested - new positive (excluding previously known)\"]  # -- Define gap column\n",
    "        report_name = f\"{name}11\"                        # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                 # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_New_Positive = Pre_HTS_MSF_positive.copy()  # -- Copy of HTS total positives\n",
    "\n",
    "        # -- Step 3: Calculate total HTS New Positive results\n",
    "        df_HTS_New_Positive[HTS_New_Positive_columns[0]] = (  \n",
    "            df_HTS_New_Positive.iloc[:, 4:7].sum(axis=1)  # -- Calculate total HTS New Positive results\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Calculate total HTS New Positive results previously known\n",
    "        df_HTS_New_Positive[HTS_New_Positive_columns[2]] = (  \n",
    "            df_HTS_New_Positive.iloc[:, 8:11].sum(axis=1)  # -- Calculate total HTS New Positive results previously known\n",
    "        )\n",
    "\n",
    "        # -- Step 5: Drop the original HTS SDP columns\n",
    "        df_HTS_New_Positive = df_HTS_New_Positive.drop(\n",
    "            columns=[\n",
    "                HTS_New_Positive_columns[7],\n",
    "                HTS_New_Positive_columns[8],\n",
    "                HTS_New_Positive_columns[9],\n",
    "                HTS_New_Positive_columns[10],\n",
    "                HTS_New_Positive_columns[11],\n",
    "                HTS_New_Positive_columns[12]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # -- Step 6: Reorder the columns to match the desired order\n",
    "        df_HTS_New_Positive = df_HTS_New_Positive[MSF_hierarchy + HTS_New_Positive_columns_order]  # -- Reorder columns\n",
    "\n",
    "        wrap_column_headers(df_HTS_New_Positive)  # -- Wrap column headers for better readability\n",
    "        HTS_New_Positive_columns_wrap = wrap_column_headers2(HTS_New_Positive_columns_order)\n",
    "        HTS_New_Positive_gap_columns_wrap = wrap_column_headers2(HTS_New_Positive_gap_columns)\n",
    "\n",
    "        # -- Step 7: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display is requested\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_New_Positive_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_HTS_New_Positive.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(f\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    print(cached_display_name)             # -- Print display message\n",
    "                    print(f\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    display(process_HTS_New_Positive_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                 # -- Exit function\n",
    "\n",
    "        # -- Step 8: Filter and validate gaps\n",
    "        df_HTS_New_Positive_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HTS_New_Positive,                      # -- Input DataFrame\n",
    "            msg=No_gap_msg,                              # -- Message for empty result\n",
    "            opNonZero=None,                              # -- No non-zero filter\n",
    "            opNeg=HTS_New_Positive_columns_wrap,         # -- Filter for negative values\n",
    "            opPos=None,                                  # -- No positive filter\n",
    "            opZero=None,                                 # -- No zero filter\n",
    "            opLT100=None                                 # -- No less-than-100 filter\n",
    "        )\n",
    "        \n",
    "        if df_HTS_New_Positive_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_HTS_New_Positive_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HTS_New_Positive_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function\n",
    "        \n",
    "        if df_HTS_New_Positive_gap is None:\n",
    "            None\n",
    "\n",
    "        # -- Step 9: Style the DataFrame\n",
    "        df_HTS_New_Positive_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_HTS_New_Positive_gap.style            # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                      # -- Hide index column\n",
    "            .map(outlier_red_LT0, subset=HTS_New_Positive_columns_wrap)  # -- Highlight outliers in gap columns\n",
    "        )\n",
    "\n",
    "        # -- Step 10: Cache styled DataFrame and shape\n",
    "        process_HTS_New_Positive_gap.cached_style = df_HTS_New_Positive_style  # -- Cache styled DataFrame\n",
    "        process_HTS_New_Positive_gap.cached_shape = df_HTS_New_Positive.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 11: Define export variables\n",
    "        report_month = df_HTS_New_Positive['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                   # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 12: Create descriptions for Word document\n",
    "        report_description = []\n",
    "        if (df_HTS_New_Positive[HTS_New_Positive_gap_columns_wrap[0]] < 0).any():  # -- Check if HTS positive gap exists\n",
    "            report_description.append(                        # -- Add description for HTS positive gap\n",
    "                f\"Report Name: {HTS_New_Positive_gap_columns[0]}\\n\"\n",
    "                f\"{HTS_New_Positive_columns[6]}\\nshould not be less than 0\"\n",
    "            )\n",
    "        if (df_HTS_New_Positive[HTS_New_Positive_columns_wrap[1]] != 0).any() or (df_HTS_New_Positive[HTS_New_Positive_columns_wrap[3]] != 0).any():  # -- Check if HTS community testing gap exists\n",
    "            report_description.append(                        # -- Add description for HTS community testing gap\n",
    "                f\"Report Name: {Gap_title_special[0]}\\n\"\n",
    "                f\"{HTS_New_Positive_columns[1]}\\n\"\n",
    "                f\"plus {HTS_New_Positive_columns[3]} should not be greater than 0\"\n",
    "            )\n",
    "        report_description = \"\\n\\n\".join(report_description)  # -- Join descriptions\n",
    "\n",
    "        # -- Step 13: Export results\n",
    "        export_df_to_doc_image_excel(                     # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                      # -- Pass report name\n",
    "            df_style=df_HTS_New_Positive_style,           # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,              # -- Pass image file name\n",
    "            img_file_path=report_image_path,              # -- Pass image file path\n",
    "            doc_file_path=doc_file_msf_outlier_docx,      # -- Pass Word document path\n",
    "            doc_description=report_description,           # -- Pass description\n",
    "            doc_indicators_to_italicize=HTS_New_Positive_columns,  # -- Italicize HTS columns\n",
    "            doc_indicators_to_underline=HTS_New_Positive_gap_columns,  # -- Underline gap columns\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,      # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name              # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 14: Optionally display styled DataFrame\n",
    "        if display_output:                                # -- Check if display is requested\n",
    "            widget_display_df(df_HTS_New_Positive_style)  # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                                # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_HTS_New_Positive_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_HTS_New_Positive_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HTS_New_Positive_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                            # -- Exit function#\n",
    "    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47cbc54",
   "metadata": {},
   "source": [
    "#### - HTS TB Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757c9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HTS TB Screening gap\n",
    "def process_HTS_TB_Screening_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS TB Screening gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_TB_Screening_columns = [                     # -- Define list of HTS TB Screening columns\n",
    "            \"Number of people who tested HIV negative and received their results. (Inpatient)\",\n",
    "            \"Number of people who tested HIV negative and received their results. (Outpatient)\",\n",
    "            \"Number of people who tested HIV negative and received their results. (Standalone)\",\n",
    "            \"Number of people who tested HIV negative and received their results. (Community)\",\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient)\",\n",
    "            \"Number of people who tested HIV positive and received results (Outpatient)\",\n",
    "            \"Number of people who tested HIV positive and received results (Standalone)\",\n",
    "            \"Number of people who tested HIV positive and received results (Community)\",\n",
    "            \"Number of HTS clients clinically screened for TB (Inpatient)\",\n",
    "            \"Number of HTS clients clinically screened for TB (Outpatient)\",\n",
    "            \"Number of HTS clients clinically screened for TB (Standalone)\",\n",
    "            \"Number of HTS clients clinically screened for TB (Community)\"\n",
    "        ]\n",
    "        HTS_TB_Screening_columns_spec = [                # -- Define specific columns for summary\n",
    "            \"Number of people who tested HIV negative and received their results. (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Number of HTS clients clinically screened for TB (Inpatient, Outpatient, Standalone)\"\n",
    "        ]\n",
    "        name = \"HTS TB Screening gap\"                   # -- Define general name\n",
    "        Gap_columns = [\"HTS TB screening gap\"]          # -- Define gap column name\n",
    "        report_name = f\"{name}12\"                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_TB_Screening = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,            # -- Use MSF hierarchy columns\n",
    "            data_columns=HTS_TB_Screening_columns       # -- Include specified HTS TB Screening columns\n",
    "        )\n",
    "        if df_HTS_TB_Screening is None:                 # -- Check if data preparation failed\n",
    "            return                                      # -- Exit function if no data\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: Calculate total HTS testing\n",
    "        df_HTS_TB_Screening[\"HTS total tested\"] = (  \n",
    "            df_HTS_TB_Screening.iloc[:, 4:12].sum(axis=1)  # -- Sum columns for total HTS testing\n",
    "        )\n",
    "\n",
    "        # -- Step 3.2: Calculate total HTS TB screening\n",
    "        df_HTS_TB_Screening[\"HTS TB total screened\"] = (  \n",
    "            df_HTS_TB_Screening.iloc[:, 12:16].sum(axis=1)  # -- Sum columns for total HTS TB screening\n",
    "        )\n",
    "\n",
    "        # -- Step 3.3: Calculate HTS TB Screening gap\n",
    "        df_HTS_TB_Screening[Gap_columns[0]] = np.where(  \n",
    "            df_HTS_TB_Screening[\"HTS total tested\"] != df_HTS_TB_Screening[\"HTS TB total screened\"],  # -- Condition for gap\n",
    "            df_HTS_TB_Screening[\"HTS TB total screened\"] - df_HTS_TB_Screening[\"HTS total tested\"],  # -- Gap value\n",
    "            0                                               # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Drop original columns\n",
    "        df_HTS_TB_Screening = df_HTS_TB_Screening.drop(\n",
    "            columns=HTS_TB_Screening_columns  # -- Drop original detailed columns\n",
    "        )\n",
    "\n",
    "        wrap_column_headers(df_HTS_TB_Screening)  # -- Wrap column headers for better readability\n",
    "        HTS_TB_Screening_columns_wrap = wrap_column_headers2(HTS_TB_Screening_columns)\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display is requested\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_TB_Screening_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_HTS_TB_Screening.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    print(cached_display_name)            # -- Print display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    display(process_HTS_TB_Screening_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                # -- Exit function\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_HTS_TB_Screening_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HTS_TB_Screening,                      # -- Input DataFrame\n",
    "            msg=No_gap_msg,                              # -- Message for empty result\n",
    "            opNonZero=Gap_columns,                       # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                  # -- No negative filter\n",
    "            opPos=None,                                  # -- No positive filter\n",
    "            opZero=None,                                 # -- No zero filter\n",
    "            opLT100=None                                 # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_HTS_TB_Screening_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_HTS_TB_Screening_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HTS_TB_Screening_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                        # -- Exit function\n",
    "        \n",
    "        if df_HTS_TB_Screening_gap is None:                 # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_HTS_TB_Screening_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_HTS_TB_Screening_gap.style                # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                          # -- Hide index column\n",
    "            .map(outlier_red, subset=Gap_columns)        # -- Highlight outliers in gap column\n",
    "        )\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_HTS_TB_Screening_gap.cached_style = df_HTS_TB_Screening_gap_style  # -- Cache styled DataFrame\n",
    "        process_HTS_TB_Screening_gap.cached_shape = df_HTS_TB_Screening.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_HTS_TB_Screening_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"         # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"     # -- Define image file path\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_HTS_TB_Screening_gap[Gap_columns[0]] != 0).any():       # -- Check if any gaps exist\n",
    "            report_description = (                                     # -- Define report description\n",
    "                f\"Report Name: {Gap_columns[0]}\\n\"\n",
    "                f\"{HTS_TB_Screening_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {HTS_TB_Screening_columns_spec[0]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                   # -- Pass report name\n",
    "            df_style=df_HTS_TB_Screening_gap_style,    # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,           # -- Pass image file name\n",
    "            img_file_path=report_image_path,           # -- Pass image file path\n",
    "            doc_description=report_description,        # -- Pass description\n",
    "            doc_indicators_to_italicize=HTS_TB_Screening_columns_spec,  # -- Italicize specific columns\n",
    "            doc_indicators_to_underline=Gap_columns,   # -- Underline gap column\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name           # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:                             # -- Check if display is requested\n",
    "            widget_display_df(df_HTS_TB_Screening_gap_style)  # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                             # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_HTS_TB_Screening_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_HTS_TB_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HTS_TB_Screening_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                          # -- Exit function\n",
    "    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b16fdf",
   "metadata": {},
   "source": [
    "#### - HTS Positive Enrolment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HTS Enrolment gap\n",
    "def process_HTS_Enrolment_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS Enrolment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_Enrolment_columns = [                     # -- Define list of HTS Enrolment columns\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Inpatient)\",\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Outpatient)\",\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Standalone)\",\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Community)\"\n",
    "        ]\n",
    "        HTS_Enrolment_columns_spec = [                # -- Define specific columns for summary\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Inpatient, Outpatient, Standalone)\",\n",
    "            \"HTS total tested - new positive (excluding previously known)\"\n",
    "        ]\n",
    "        columns_to_keep = MSF_hierarchy + [\"HTS total tested - new positive (excluding previously known)\"]  # -- Columns to retain from Pre_MSF_positives_all\n",
    "        Pre_MSF_positives_subset = Pre_MSF_positives_all[columns_to_keep]  # -- Subset of Pre_MSF_positives_all DataFrame\n",
    "        name = \"HTS Enrolment gap\"                   # -- Define general name\n",
    "        Gap_columns = [\"HTS enrolment gap\"]          # -- Define gap column name\n",
    "        report_name = f\"{name}13\"                    # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"             # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_Enrolment = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,         # -- Use MSF hierarchy columns\n",
    "            data_columns=HTS_Enrolment_columns       # -- Include specified HTS Enrolment columns\n",
    "        )\n",
    "        if df_HTS_Enrolment is None:                 # -- Check if data preparation failed\n",
    "            return                                   # -- Exit function if no data\n",
    "\n",
    "        # -- Step 3: Merge with Pre_MSF_positives_all subset\n",
    "        df_HTS_Enrolment = Pre_MSF_positives_subset.merge(  # -- Merge with positives data\n",
    "            df_HTS_Enrolment,                           # -- Merge target\n",
    "            on=MSF_hierarchy,                           # -- Merge keys\n",
    "            how=\"left\"                                  # -- Keep all rows from Pre_MSF_positives_subset\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Sort and clean data\n",
    "        df_HTS_Enrolment.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # -- Sort by hierarchy columns\n",
    "        df_HTS_Enrolment = df_HTS_Enrolment.fillna(0)  # -- Fill NaN with 0\n",
    "        float_columns = df_HTS_Enrolment.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                     # -- Convert float columns to int\n",
    "            df_HTS_Enrolment[col] = df_HTS_Enrolment[col].astype(int)\n",
    "\n",
    "        # -- Step 5: Calculate derived metrics\n",
    "        # -- Step 5.1: Calculate total enrolment\n",
    "        df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] = (  \n",
    "            df_HTS_Enrolment.iloc[:, 5:9].sum(axis=1)  # -- Sum columns for total enrolment\n",
    "        )\n",
    "\n",
    "        # -- Step 5.2: Calculate enrolment gap\n",
    "        df_HTS_Enrolment[Gap_columns[0]] = np.where(  \n",
    "            df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] != df_HTS_Enrolment[HTS_Enrolment_columns_spec[1]],  # -- Condition for gap\n",
    "            df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] - df_HTS_Enrolment[HTS_Enrolment_columns_spec[1]],  # -- Gap value\n",
    "            0                                               # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 6: Drop original columns\n",
    "        df_HTS_Enrolment = df_HTS_Enrolment.drop(\n",
    "            columns=HTS_Enrolment_columns  # -- Drop original detailed columns\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_Enrolment)  \n",
    "        HTS_Enrolment_columns_wrap = wrap_column_headers2(HTS_Enrolment_columns)\n",
    "\n",
    "        # -- Step 8: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display is requested\n",
    "            if hasattr(process_HTS_Enrolment_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_Enrolment_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_HTS_Enrolment.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    print(cached_display_name)            # -- Print display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    display(process_HTS_Enrolment_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                # -- Exit function\n",
    "\n",
    "        # -- Step 9: Filter and validate gaps\n",
    "        df_HTS_Enrolment_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HTS_Enrolment,                      # -- Input DataFrame\n",
    "            msg=No_gap_msg,                           # -- Message for empty result\n",
    "            opNonZero=Gap_columns,                    # -- Filter for non-zero gaps\n",
    "            opNeg=None,                               # -- No negative filter\n",
    "            opPos=None,                               # -- No positive filter\n",
    "            opZero=None,                              # -- No zero filter\n",
    "            opLT100=None                              # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_HTS_Enrolment_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_HTS_Enrolment_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_HTS_Enrolment_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_HTS_Enrolment_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HTS_Enrolment_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                     # -- Exit function\n",
    "        \n",
    "        if df_HTS_Enrolment_gap is None:                 # -- Check if data preparation failed\n",
    "            return \n",
    "\n",
    "        # -- Step 10: Style the DataFrame\n",
    "        df_HTS_Enrolment_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_HTS_Enrolment_gap.style                # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                       # -- Hide index column\n",
    "            .map(outlier_red, subset=Gap_columns)     # -- Highlight outliers in gap column\n",
    "        )\n",
    "\n",
    "        # -- Step 11: Cache styled DataFrame and shape\n",
    "        process_HTS_Enrolment_gap.cached_style = df_HTS_Enrolment_gap_style  # -- Cache styled DataFrame\n",
    "        process_HTS_Enrolment_gap.cached_shape = df_HTS_Enrolment.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 12: Define export variables\n",
    "        report_month = df_HTS_Enrolment_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"      # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define image file path\n",
    "        report_sheet_name = report_name                              # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 13: Create descriptions for Word document\n",
    "        if (df_HTS_Enrolment_gap[Gap_columns[0]] != 0).any():       # -- Check if any gaps exist\n",
    "            report_description = (                                 # -- Define report description\n",
    "                f\"Report Name: {Gap_columns[0]}\\n\"\n",
    "                f\"{HTS_Enrolment_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {HTS_Enrolment_columns_spec[0]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 14: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                   # -- Pass report name\n",
    "            df_style=df_HTS_Enrolment_gap_style,       # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,           # -- Pass image file name\n",
    "            img_file_path=report_image_path,           # -- Pass image file path\n",
    "            doc_description=report_description,        # -- Pass description\n",
    "            doc_indicators_to_italicize=HTS_Enrolment_columns_spec,  # -- Italicize specific columns\n",
    "            doc_indicators_to_underline=Gap_columns,   # -- Underline gap column\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name           # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 15: Optionally display styled DataFrame\n",
    "        if display_output:                             # -- Check if display is requested\n",
    "            widget_display_df(df_HTS_Enrolment_gap_style)  # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                             # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_HTS_Enrolment_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_HTS_Enrolment_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_HTS_Enrolment_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HTS_Enrolment_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                          # -- Exit function\n",
    "    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ac988a",
   "metadata": {},
   "source": [
    "#### - HTS Couple Counselling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HTS Couple Counselling gap\n",
    "def process_HTS_Couple_Counselling_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS Couple Counselling gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_Couple_Counselling_columns = [                     # -- Define list of HTS Couple Counselling columns\n",
    "            \"No of couples counselled, tested for HIV and received result (Inpatient)\",\n",
    "            \"No of couples counselled, tested for HIV and received result (Outpatient)\",\n",
    "            \"No of couples counselled, tested for HIV and received result (Standalone)\",\n",
    "            \"No of couples counselled, tested for HIV and received result (Community)\",\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Inpatient)\",\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Outpatient)\",\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Standalone)\",\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Community)\"\n",
    "        ]\n",
    "        HTS_Couple_Counselling_columns_spec = [                # -- Define specific columns for summary\n",
    "            \"No of couples counselled, tested for HIV and received result (Inpatient, Outpatient, Standalone)\",\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Inpatient, Outpatient, Standalone)\"\n",
    "        ]\n",
    "        name = \"HTS Discordant Couple Test gap\"                # -- Define general name\n",
    "        Gap_columns = [\"HTS Discordant Couple Test gap\"]       # -- Define gap column name\n",
    "        report_name = f\"{name}14\"                              # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                       # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_Couple_Counselling = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                         # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                  # -- Use MSF hierarchy columns\n",
    "            data_columns=HTS_Couple_Counselling_columns        # -- Include specified HTS Couple Counselling columns\n",
    "        )\n",
    "        if df_HTS_Couple_Counselling is None:                 # -- Check if data preparation failed\n",
    "            return                                            # -- Exit function if no data\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: Calculate total couples counselled and tested\n",
    "        df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]] = (  \n",
    "            df_HTS_Couple_Counselling.iloc[:, 4:8].sum(axis=1)  # -- Sum columns for total couples counselled and tested\n",
    "        )\n",
    "\n",
    "        # -- Step 3.2: Calculate total discordant results\n",
    "        df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]] = (  \n",
    "            df_HTS_Couple_Counselling.iloc[:, 8:12].sum(axis=1)  # -- Sum columns for total discordant results\n",
    "        )\n",
    "\n",
    "        # -- Step 3.3: Calculate discordant couple test gap\n",
    "        df_HTS_Couple_Counselling[Gap_columns[0]] = np.where(  \n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]] > df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]],  # -- Condition for gap\n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]] - df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]],  # -- Gap value\n",
    "            0                                                  # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Drop original columns\n",
    "        df_HTS_Couple_Counselling = df_HTS_Couple_Counselling.drop(\n",
    "            columns=HTS_Couple_Counselling_columns  # -- Drop original detailed columns\n",
    "        )\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_Couple_Counselling)  \n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(HTS_Couple_Counselling_columns)\n",
    "        Gap_columns_wrap = wrap_column_headers2(Gap_columns)\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display is requested\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_Couple_Counselling_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_HTS_Couple_Counselling.shape  # -- Get current unfiltered shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Define display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    print(cached_display_name)             # -- Print display message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator line\n",
    "                    display(process_HTS_Couple_Counselling_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                 # -- Exit function\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HTS_Couple_Counselling_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HTS_Couple_Counselling,                      # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                    # -- Message for empty result\n",
    "            opNonZero=Gap_columns_wrap,                        # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                        # -- No negative filter\n",
    "            opPos=None,                                        # -- No positive filter\n",
    "            opZero=None,                                       # -- No zero filter\n",
    "            opLT100=None                                       # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_HTS_Couple_Counselling_gap is None:              # -- Check if no gaps found\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_HTS_Couple_Counselling_gap.cached_style  # -- Clear cached style\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HTS_Couple_Counselling_gap.cached_shape  # -- Clear cached shape\n",
    "            return                                             # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HTS_Couple_Counselling_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_HTS_Couple_Counselling_gap.style                # -- Start with DataFrame style object\n",
    "            .hide(axis='index')                                # -- Hide index column\n",
    "            .map(outlier_red, subset=Gap_columns)              # -- Highlight outliers in gap column\n",
    "        )\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HTS_Couple_Counselling_gap.cached_style = df_HTS_Couple_Counselling_gap_style  # -- Cache styled DataFrame\n",
    "        process_HTS_Couple_Counselling_gap.cached_shape = df_HTS_Couple_Counselling.shape  # -- Cache unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HTS_Couple_Counselling_gap['ReportPeriod'].iloc[0]  # -- Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"               # -- Define image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"           # -- Define image file path\n",
    "        report_sheet_name = report_name                                       # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_HTS_Couple_Counselling_gap[Gap_columns[0]] != 0).any():        # -- Check if any gaps exist\n",
    "            report_description = (                                           # -- Define report description\n",
    "                f\"Report Name: {Gap_columns[0]}\\n\"\n",
    "                f\"{HTS_Couple_Counselling_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {HTS_Couple_Counselling_columns_spec[0]}\"\n",
    "            )\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                  # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                   # -- Pass report name\n",
    "            df_style=df_HTS_Couple_Counselling_gap_style,  # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,           # -- Pass image file name\n",
    "            img_file_path=report_image_path,           # -- Pass image file path\n",
    "            doc_description=report_description,        # -- Pass description\n",
    "            doc_indicators_to_italicize=HTS_Couple_Counselling_columns_spec,  # -- Italicize specific columns\n",
    "            doc_indicators_to_underline=Gap_columns,   # -- Underline gap column\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name           # -- Pass Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                             # -- Check if display is requested\n",
    "            widget_display_df(df_HTS_Couple_Counselling_gap_style)  # -- Display styled DataFrame\n",
    "\n",
    "    except Exception as e:                             # -- Catch any exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_HTS_Couple_Counselling_gap.cached_style  # -- Clear cached style\n",
    "        if hasattr(process_HTS_Couple_Counselling_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HTS_Couple_Counselling_gap.cached_shape  # -- Clear cached shape\n",
    "        return                                          # -- Exit function\n",
    "    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d0aa8",
   "metadata": {},
   "source": [
    "#### - HTS CD4 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb8ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HTS CD4 gap\n",
    "def process_HTS_CD4_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS CD4 gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_CD4_columns = [                     # -- Define list of HTS CD4 columns\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Inpatient)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Outpatient)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0 (Standalone)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Community)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Inpatient)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Outpatient)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Standalone)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Community)\"\n",
    "        ]\n",
    "        HTS_CD4_columns_spec = [                # -- Define specific columns for summary\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period  (Inpatient, Outpatient, Standalone)\",\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period  (Inpatient, Outpatient, Standalone)\",\n",
    "            \"HTS total tested - new positive (excluding previously known)\",\n",
    "            \"Total Number of newly diagnosed PLHIV who received CD4 (<200 and >200) cells/mm3\"\n",
    "        ]\n",
    "        columns_to_keep = MSF_hierarchy + [\"HTS total tested - new positive (excluding previously known)\"]  # -- Columns to retain from Pre_MSF_positives_all\n",
    "        Pre_MSF_positives_subset = Pre_MSF_positives_all[columns_to_keep]  # -- Subset of Pre_MSF_positives_all DataFrame\n",
    "        name = \"HTS CD4 gap\"                   # -- Define general name\n",
    "        Gap_columns = [\"HTS CD4 gap\"]          # -- Define gap column name\n",
    "        report_name = f\"{name}15\"              # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"       # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_CD4 = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",           # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,    # -- Use MSF hierarchy columns\n",
    "            data_columns=HTS_CD4_columns        # -- Include specified HTS CD4 columns\n",
    "        )\n",
    "        if df_HTS_CD4 is None:                  # -- Check if data preparation failed\n",
    "            return                              # -- Exit function if no data\n",
    "\n",
    "        # -- Step 3: Merge with Pre_MSF_positives_all subset\n",
    "        df_HTS_CD4 = Pre_MSF_positives_subset.merge(  # -- Merge with positives data\n",
    "            df_HTS_CD4,                               # -- Merge target\n",
    "            on=MSF_hierarchy,                         # -- Merge keys\n",
    "            how=\"left\"                                # -- Keep all rows from Pre_MSF_positives_subset\n",
    "        )\n",
    "\n",
    "        # -- Step 4: Sort and clean data\n",
    "        df_HTS_CD4.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # -- Sort by hierarchy columns\n",
    "        df_HTS_CD4 = df_HTS_CD4.fillna(0)  # -- Fill NaN with 0\n",
    "        float_columns = df_HTS_CD4.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                     # -- Convert float columns to int\n",
    "            df_HTS_CD4[col] = df_HTS_CD4[col].astype(int)\n",
    "\n",
    "        # -- Step 5: Calculate derived metrics\n",
    "        # -- Step 5.1: Calculate total CD4 <200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[0]] = (  \n",
    "            df_HTS_CD4.iloc[:, 5:9].sum(axis=1)  # -- Sum columns for total CD4 <200\n",
    "        )\n",
    "\n",
    "        # -- Step 5.2: Calculate total CD4 >200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[1]] = (  \n",
    "            df_HTS_CD4.iloc[:, 9:13].sum(axis=1)  # -- Sum columns for total CD4 >200\n",
    "        )\n",
    "\n",
    "        # -- Step 5.3: Calculate total CD4 <200 and >200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[3]] = (  \n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[0]] + df_HTS_CD4[HTS_CD4_columns_spec[1]]  # -- Sum columns for total CD4\n",
    "        )\n",
    "\n",
    "        # -- Step 5.4: Calculate CD4 gap\n",
    "        df_HTS_CD4[Gap_columns[0]] = np.where(  \n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[2]] != df_HTS_CD4[HTS_CD4_columns_spec[3]],  # -- Condition for gap\n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[2]] - df_HTS_CD4[HTS_CD4_columns_spec[3]],  # -- Gap value\n",
    "            0                                               # -- Default to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 6: Drop original columns\n",
    "        columns_to_drop = HTS_CD4_columns + [HTS_CD4_columns_spec[0], HTS_CD4_columns_spec[1]]\n",
    "        df_HTS_CD4 = df_HTS_CD4.drop(\n",
    "            columns=columns_to_drop  # -- Drop original detailed columns\n",
    "        )\n",
    "\n",
    "        # -- Step 7: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_CD4)  \n",
    "        HTS_CD4_columns_wrap = wrap_column_headers2(HTS_CD4_columns_spec)\n",
    "\n",
    "        # -- Step 8: Check and display cached styled DataFrames\n",
    "        if display_output:                                 # -- Check if display requested\n",
    "            if hasattr(process_HTS_CD4_gap, 'cached_styles'):  # -- Check cache existence\n",
    "                cached_shape = getattr(process_HTS_CD4_gap, 'cached_shape', None)  # -- Get cached shape\n",
    "                current_shape = df_HTS_CD4.shape  # -- Get current shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes\n",
    "                    for cluster, style in process_HTS_CD4_gap.cached_styles.items():  # -- Iterate cached styles\n",
    "                        cached_display_name = f\"✔️ Displaying {cluster} {report_name} \"  # -- Display message\n",
    "                        print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                        print(cached_display_name)            # -- Message\n",
    "                        print(\"-\" * len(cached_display_name))  # -- Separator\n",
    "                        display(style)                        # -- Display cached style\n",
    "                    return                                 # -- Exit if cache used\n",
    "\n",
    "        # -- Step 9: Initialize cache\n",
    "        if not hasattr(process_HTS_CD4_gap, 'cached_styles'):  # -- Check if cache exists\n",
    "            process_HTS_CD4_gap.cached_styles = {}  # -- Initialize cache\n",
    "\n",
    "        # -- Step 10: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_HTS_CD4['Cluster'].unique())  # -- Extract unique clusters\n",
    "\n",
    "        # -- Step 11: Process each cluster\n",
    "        for current_cluster in cluster_list:               # -- Iterate over clusters\n",
    "            cluster_filtered = df_HTS_CD4[df_HTS_CD4['Cluster'] == current_cluster]  # -- Filter cluster\n",
    "            \n",
    "            HTS_CD4_msg = f\"No {current_cluster} {report_name}\"  # -- Message for no gaps\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # -- Filter gaps\n",
    "                df=cluster_filtered,\n",
    "                msg=HTS_CD4_msg,\n",
    "                opNonZero=Gap_columns,\n",
    "                opNeg=None,\n",
    "                opPos=None,\n",
    "                opZero=None,\n",
    "                opLT100=None\n",
    "            )\n",
    "\n",
    "            if cluster_filtered_gap is None:               # -- Check if no gaps\n",
    "                if current_cluster in process_HTS_CD4_gap.cached_styles:  # -- Remove from cache\n",
    "                    del process_HTS_CD4_gap.cached_styles[current_cluster]\n",
    "                continue                                   # -- Skip cluster\n",
    "\n",
    "            cluster_filtered_style = (                     # -- Style DataFrame\n",
    "                cluster_filtered_gap.style\n",
    "                .hide(axis='index')\n",
    "                .map(outlier_red, subset=Gap_columns)\n",
    "            )\n",
    "\n",
    "            process_HTS_CD4_gap.cached_styles[current_cluster] = cluster_filtered_style  # -- Cache style\n",
    "\n",
    "            # -- Step 12: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # -- Cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # -- Extract report month\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # -- Image file name\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # -- Excel sheet name\n",
    "\n",
    "            # -- Step 13: Create descriptions\n",
    "            report_description = []                        # -- Initialize descriptions\n",
    "            if (cluster_filtered_gap[Gap_columns[0]] != 0).any():  # -- Check for gaps\n",
    "                report_description.append(\n",
    "                    f\"Report Name: {Gap_columns[0]}\\n\"\n",
    "                    f\"{HTS_CD4_columns_spec[2]}\\nshould be equal to {HTS_CD4_columns_spec[3]}\\n\"\n",
    "                    f\"Note: Where this CD4 gap is true, please ignore the outlier.\"\n",
    "                )\n",
    "            report_description = \"\\n\\n\".join(report_description)  # -- Join descriptions\n",
    "\n",
    "            # -- Step 14: Export results\n",
    "            export_df_to_doc_image_excel(                  # -- Export DataFrame\n",
    "                report_name=report_name_cluster,\n",
    "                df_style=cluster_filtered_style,\n",
    "                img_file_name=report_image_name,\n",
    "                img_file_path=sub_folder2_image_file_msf_outlier,\n",
    "                doc_description=report_description,\n",
    "                doc_indicators_to_italicize=HTS_CD4_columns_spec,\n",
    "                doc_indicators_to_underline=Gap_columns,\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,\n",
    "                xlm_sheet_name=report_sheet_name\n",
    "            )\n",
    "\n",
    "            if display_output:                             # -- Display styled DataFrame\n",
    "                widget_display_df(cluster_filtered_style)\n",
    "\n",
    "        # -- Step 15: Cache overall unfiltered DataFrame shape\n",
    "        process_HTS_CD4_gap.cached_shape = df_HTS_CD4.shape  # -- Cache shape\n",
    "\n",
    "    except Exception as e:                                 # -- Catch exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error\n",
    "        if hasattr(process_HTS_CD4_gap, 'cached_styles'):  # -- Clear cache on error\n",
    "            process_HTS_CD4_gap.cached_styles.clear()\n",
    "        if hasattr(process_HTS_CD4_gap, 'cached_shape'):  # -- Clear shape on error\n",
    "            del process_HTS_CD4_gap.cached_shape\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1b209",
   "metadata": {},
   "source": [
    "### HIVST MSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca501e",
   "metadata": {},
   "source": [
    "#### - HIVST Distribution Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5bde0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Distribution Mode gap\n",
    "def process_HIVST_Distr_Mode_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Distribution Mode gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                     # -- Define list of HIVST columns\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By)\",\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By)\"\n",
    "        ]\n",
    "        df_columns_spec = [                # -- Define specific columns for summary\n",
    "            \"Number of individual HIVST kits distributed - Assisted\",\n",
    "            \"Number of individual HIVST kits distributed - Uassisted\",\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By) (Distribution Mode)\",\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By) (Distribution Mode)\"\n",
    "        ]\n",
    "        columns_to_keep = MSF_hierarchy + [\"Assisted\", \"Unassisted\"]  # -- Columns to retain from HTS MSF_hivst approach\n",
    "        name = \"HIVST Distribution Mode gap\"                   # -- Define general name for reporting\n",
    "        gap_columns = [\"Assisted distribution mode gap\", \"Uassisted distribution mode gap\"]  # -- Define gap column names\n",
    "        report_name = f\"{name}16\"                    # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"             # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_HIVST_Distri_Mode = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,         # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                  # -- Include specified HTS Enrolment columns\n",
    "        )\n",
    "        if df_HIVST_Distri_Mode is None:                 # -- Check if data preparation failed\n",
    "            print(f\"⦸ No data retrieved for {report_name}\")  # -- Notify user of data failure\n",
    "            return                                   # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_HIVST_Mode_extra = prepare_and_convert_df(    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF_hivst approach\",     # -- Specify DHIS2 data key for HIVST approach\n",
    "            hierarchy_columns=MSF_hierarchy,             # -- Use MSF hierarchy columns\n",
    "            data_columns=[\"Assisted\", \"Unassisted\"]      # -- Include specified HIVST mode columns\n",
    "        )\n",
    "        if df_HIVST_Mode_extra is None:                 # -- Check if data preparation failed\n",
    "            print(f\"⦸ No extra data retrieved for {report_name}\")  # -- Notify user of data failure\n",
    "            return                                      # -- Exit function if no data\n",
    "\n",
    "        df_HIVST_Mode_extra = df_HIVST_Mode_extra[columns_to_keep]  # -- Subset to retain only necessary columns\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Mode_extra.merge(  # -- Merge HIVST mode data with primary data\n",
    "            df_HIVST_Distri_Mode,                          # -- Target DataFrame for merge\n",
    "            on=MSF_hierarchy,                              # -- Merge on MSF hierarchy columns\n",
    "            how=\"right\"                                    # -- Right join to keep all rows from primary data\n",
    "        )\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode.rename(columns={\n",
    "            \"Assisted\": f\"{df_columns_spec[0]}\",\n",
    "            \"Unassisted\": f\"{df_columns_spec[1]}\",\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By)\": f\"{df_columns_spec[2]}\",\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By)\": f\"{df_columns_spec[3]}\"\n",
    "        })  # -- Rename columns to align with specified column names\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_HIVST_Distri_Mode.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # -- Sort by hierarchy\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode.fillna(0)  # -- Replace NaN with 0\n",
    "        float_columns = df_HIVST_Distri_Mode.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                     # -- Convert float columns to integers\n",
    "            df_HIVST_Distri_Mode[col] = df_HIVST_Distri_Mode[col].astype(int)\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_HIVST_Distri_Mode[gap_columns[0]] = np.where(\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[2]] != df_HIVST_Distri_Mode[df_columns_spec[0]],  # -- Check for Assisted gap\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[2]] - df_HIVST_Distri_Mode[df_columns_spec[0]],  # -- Calculate gap\n",
    "            0                                               # -- Set to 0 if no gap\n",
    "        )\n",
    "        df_HIVST_Distri_Mode[gap_columns[1]] = np.where(\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[3]] != df_HIVST_Distri_Mode[df_columns_spec[1]],  # -- Check for Unassisted gap\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[3]] - df_HIVST_Distri_Mode[df_columns_spec[1]],  # -- Calculate gap\n",
    "            0                                               # -- Set to 0 if no gap\n",
    "        )\n",
    "\n",
    "        # -- Step 8: Reorder columns for output\n",
    "        reorder_columns = MSF_hierarchy + [\n",
    "            df_columns_spec[0], df_columns_spec[2], gap_columns[0], \n",
    "            df_columns_spec[1], df_columns_spec[3], gap_columns[1]\n",
    "        ]\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode[reorder_columns]  # -- Reorder DataFrame columns\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Distri_Mode)  # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)  # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                 # -- Check if display output is requested\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_HIVST_Distr_Mode_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_HIVST_Distri_Mode.shape  # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:          # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator\n",
    "                    print(cached_display_name)            # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))  # -- Print separator\n",
    "                    display(process_HIVST_Distr_Mode_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_HIVST_Distri_Mode_gap = filter_gap_and_check_empty_df(  # -- Filter rows with non-zero gaps\n",
    "            df=df_HIVST_Distri_Mode,                      # -- Input DataFrame\n",
    "            msg=No_gap_msg,                           # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                # -- Filter for non-zero gaps\n",
    "            opNeg=None,                               # -- No negative value filter\n",
    "            opPos=None,                               # -- No positive value filter\n",
    "            opZero=None,                              # -- No zero value filter\n",
    "            opLT100=None                              # -- No less-than-100 filter\n",
    "        )\n",
    "        if df_HIVST_Distri_Mode_gap is None:              # -- Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_HIVST_Distr_Mode_gap.cached_style  # -- Remove cached style\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_HIVST_Distr_Mode_gap.cached_shape  # -- Remove cached shape\n",
    "            print(f\"⦸ {No_gap_msg}\")                     # -- Notify user of no gaps\n",
    "            return                                     # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_HIVST_Distri_Mode_gap_style = (                # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Distri_Mode_gap.style                # -- Create style object\n",
    "            .hide(axis='index')                       # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)     # -- Highlight non-zero gaps in red\n",
    "        )\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_HIVST_Distr_Mode_gap.cached_style = df_HIVST_Distri_Mode_gap_style  # -- Store styled DataFrame\n",
    "        process_HIVST_Distr_Mode_gap.cached_shape = df_HIVST_Distri_Mode.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_HIVST_Distri_Mode_gap['ReportPeriod'].iloc[0]  # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"      # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # -- Define path for image export\n",
    "        report_sheet_name = report_name                              # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []                                    # -- Initialize list for descriptions\n",
    "        if (df_HIVST_Distri_Mode_gap[gap_columns_wrap[0]] != 0).any():  # -- Check for Assisted gaps\n",
    "            report_description.append(                             # -- Add description for Assisted gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"\n",
    "            )\n",
    "        if (df_HIVST_Distri_Mode_gap[gap_columns_wrap[1]] != 0).any():  # -- Check for Unassisted gaps\n",
    "            report_description.append(                             # -- Add description for Unassisted gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[1]}\"\n",
    "            )\n",
    "        report_description = \"\\n\\n\".join(report_description)  # -- Combine descriptions with newlines\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                  # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                   # -- Report identifier\n",
    "            df_style=df_HIVST_Distri_Mode_gap_style,   # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,           # -- Image file name\n",
    "            img_file_path=report_image_path,           # -- Image file path\n",
    "            doc_description=report_description,        # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns_spec,  # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,   # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,   # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name           # -- Excel sheet name\n",
    "        )\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                             # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Distri_Mode_gap_style)  # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                             # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # -- Print error details\n",
    "        if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_HIVST_Distr_Mode_gap.cached_style  # -- Remove cached style\n",
    "        if hasattr(process_HIVST_Distr_Mode_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_HIVST_Distr_Mode_gap.cached_shape  # -- Remove cached shape\n",
    "        return                                          # -- Exit function on error\n",
    "    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18a61b",
   "metadata": {},
   "source": [
    "#### - HIVST Testing Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72fa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Testing Frequency gap\n",
    "def process_HIVST_Test_Freq_gap(display_output=None):                    # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process HIVST Testing Frequency gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST testing frequency columns\n",
    "            \"Number of individual HIVST kits distributed (Directly Assisted & Unassisted)\",\n",
    "            \"Number of individual HIVST kits distributed (Testing Frequency)\"\n",
    "        ]\n",
    "        name = \"HIVST Testing Frequency gap\"                            # -- Define general name\n",
    "        gap_columns = [\"HIVST Testing Frequency gap\"]                   # -- Define gap column name\n",
    "        report_name = f\"{name}17\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Test_Freq = prepare_and_convert_df(                    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_HIVST_Test_Freq is None:                                  # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3.3: Calculate discordant couple test gap\n",
    "        df_HIVST_Test_Freq[gap_columns[0]] = np.where(  \n",
    "            df_HIVST_Test_Freq[df_columns[1]] > df_HIVST_Test_Freq[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Test_Freq[df_columns[1]] - df_HIVST_Test_Freq[df_columns[0]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Test_Freq)                         # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):    # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Test_Freq_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Test_Freq.shape                # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_HIVST_Test_Freq_gap.cached_style)   # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Test_Freq_gap = filter_gap_and_check_empty_df(        # -- Filter DataFrame for gaps\n",
    "            df=df_HIVST_Test_Freq,                                      # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_HIVST_Test_Freq_gap is None:                              # -- Check if no gaps found\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):    # -- Check if cached style exists\n",
    "                del process_HIVST_Test_Freq_gap.cached_style            # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_shape'):    # -- Check if cached shape exists\n",
    "                del process_HIVST_Test_Freq_gap.cached_shape            # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Test_Freq_gap_style = (                                # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Test_Freq_gap.style                                # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Test_Freq_gap.cached_style = df_HIVST_Test_Freq_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_HIVST_Test_Freq_gap.cached_shape = df_HIVST_Test_Freq.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Test_Freq_gap['ReportPeriod'].iloc[0]  # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_HIVST_Test_Freq_gap[gap_columns_wrap[0]] != 0).any():   # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_HIVST_Test_Freq_gap_style,                     # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                           # -- Pass image file name\n",
    "            img_file_path=report_image_path,                           # -- Pass image file path\n",
    "            doc_description=report_description,                        # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                    # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                   # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                           # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Test_Freq_gap_style)            # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):       # -- Check if cached style exists\n",
    "            del process_HIVST_Test_Freq_gap.cached_style               # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Test_Freq_gap, 'cached_shape'):       # -- Check if cached shape exists\n",
    "            del process_HIVST_Test_Freq_gap.cached_shape               # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                                      # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d89fde",
   "metadata": {},
   "source": [
    "#### - HIVST Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Result gap\n",
    "def process_HIVST_Result_gap(display_output=None):                    # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process HIVST Result gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST testing frequency columns\n",
    "            \"Number of individual HIVST kits distributed (Directly Assisted & Unassisted)\",\n",
    "            \"Number of individual reporting HIVST results\"\n",
    "        ]\n",
    "        name = \"HIVST Result gap\"                            # -- Define general name\n",
    "        gap_columns = [\"HIVST Result gap\"]                   # -- Define gap column name\n",
    "        report_name = f\"{name}18\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Result = prepare_and_convert_df(                    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_HIVST_Result is None:                                  # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3.3: Calculate discordant couple test gap\n",
    "        df_HIVST_Result[gap_columns[0]] = np.where(  \n",
    "            df_HIVST_Result[df_columns[1]] != df_HIVST_Result[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Result[df_columns[0]] - df_HIVST_Result[df_columns[1]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Result)                         # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_style'):    # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Result_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Result.shape                # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_HIVST_Result_gap.cached_style)   # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Test_Freq_gap = filter_gap_and_check_empty_df(        # -- Filter DataFrame for gaps\n",
    "            df=df_HIVST_Result,                                      # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                         # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_HIVST_Test_Freq_gap is None:                              # -- Check if no gaps found\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_style'):    # -- Check if cached style exists\n",
    "                del process_HIVST_Result_gap.cached_style            # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_shape'):    # -- Check if cached shape exists\n",
    "                del process_HIVST_Result_gap.cached_shape            # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Test_Freq_gap_style = (                                # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Test_Freq_gap.style                                # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Result_gap.cached_style = df_HIVST_Test_Freq_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_HIVST_Result_gap.cached_shape = df_HIVST_Result.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Test_Freq_gap['ReportPeriod'].iloc[0]  # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_HIVST_Test_Freq_gap[gap_columns[0]] != 0).any():   # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_HIVST_Test_Freq_gap_style,                     # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                           # -- Pass image file name\n",
    "            img_file_path=report_image_path,                           # -- Pass image file path\n",
    "            doc_description=report_description,                        # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                    # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                   # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                           # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Test_Freq_gap_style)            # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_HIVST_Result_gap, 'cached_style'):       # -- Check if cached style exists\n",
    "            del process_HIVST_Result_gap.cached_style               # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Result_gap, 'cached_shape'):       # -- Check if cached shape exists\n",
    "            del process_HIVST_Result_gap.cached_shape               # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                                      # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a0acb",
   "metadata": {},
   "source": [
    "#### - HIVST Reactive Confirmation and Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Reactive and Linkage gap\n",
    "def process_HIVST_Reactive_Link_gap(display_output=None):                    # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process HIVST Reactive and Linkaget gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                    # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                      # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of individual reporting HIVST results\",\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test (HTS)\",\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV positive test results.\",\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV negative test results.\",\n",
    "            \"Number of individuals with confirmed HIV-positive results who are successfully linked with HIV care and treatment\"\n",
    "        ]\n",
    "        name = \"HIVST Reactive Linkage gap\"                                 # -- Define general name\n",
    "        gap_columns = [\n",
    "            \"HIVST Reactive Referral for Confirmatory gap\", \n",
    "            \"HIVST Confirmatory Test Rsult gap\",\n",
    "            \"HIVST Confirmed Positive Linkage gap\"\n",
    "        ]                                                                   # -- Define gap column names\n",
    "        report_name = f\"{name}19\"                                           # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                    # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Reactive_Link = prepare_and_convert_df(                    # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                       # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                                # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                         # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_HIVST_Reactive_Link is None:                                  # -- Check if data preparation failed\n",
    "            return                                                          # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3.3: Calculate discordant couple test gap\n",
    "        df_HIVST_Reactive_Link[gap_columns[0]] = np.where(  \n",
    "            df_HIVST_Reactive_Link[df_columns[1]] > df_HIVST_Reactive_Link[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Reactive_Link[df_columns[1]] - df_HIVST_Reactive_Link[df_columns[0]],  # -- Calculate gap if condition met\n",
    "            0                                                               # -- Set gap to 0 if no discrepancy\n",
    "        )                                                                   # -- Assign calculated referral gap to new column\n",
    "\n",
    "        df_HIVST_Reactive_Link[gap_columns[1]] = np.where(\n",
    "            df_HIVST_Reactive_Link[df_columns[2:4]].sum(axis=1) != df_HIVST_Reactive_Link[df_columns[1]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Reactive_Link[df_columns[2:4]].sum(axis=1) - df_HIVST_Reactive_Link[df_columns[1]],  # -- Calculate gap if condition met\n",
    "            0                                                               # -- Set gap to 0 if no discrepancy\n",
    "        )                                                                   # -- Assign calculated confirmatory test gap to new column\n",
    "\n",
    "        df_HIVST_Reactive_Link[gap_columns[2]] = np.where(\n",
    "            df_HIVST_Reactive_Link[df_columns[2]] != df_HIVST_Reactive_Link[df_columns[4]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Reactive_Link[df_columns[4]] - df_HIVST_Reactive_Link[df_columns[2]],  # -- Calculate gap if condition met\n",
    "            0                                                               # -- Set gap to 0 if no discrepancy\n",
    "        )                                                                   # -- Assign calculated linkage gap to new column\n",
    "\n",
    "        reorder_columns = MSF_hierarchy + [\n",
    "            df_columns[0], df_columns[1], gap_columns[0], \n",
    "            df_columns[2], df_columns[3], gap_columns[1],\n",
    "            df_columns[4], gap_columns[2]\n",
    "        ]                                                                   # -- Define column order for DataFrame\n",
    "\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link[reorder_columns]    # -- Reorder DataFrame columns\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Reactive_Link)                         # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)                # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                                  # -- Check if display is requested\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):    # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Reactive_Link_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Reactive_Link.shape                # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                           # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator line above message\n",
    "                    print(cached_display_name)                              # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator line below message\n",
    "                    display(process_HIVST_Reactive_Link_gap.cached_style)   # -- Render cached styled DataFrame\n",
    "                    return                                                  # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Reactive_Link_gap = filter_gap_and_check_empty_df(        # -- Filter DataFrame for gaps\n",
    "            df=df_HIVST_Reactive_Link,                                      # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                                 # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                     # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                     # -- No negative value filter\n",
    "            opPos=None,                                                     # -- No positive value filter\n",
    "            opZero=None,                                                    # -- No zero value filter\n",
    "            opLT100=None                                                    # -- No less-than-100 filter\n",
    "        )                                                                   # -- Store filtered DataFrame with gaps\n",
    "        if df_HIVST_Reactive_Link_gap is None:                              # -- Check if no gaps found\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):    # -- Check if cached style exists\n",
    "                del process_HIVST_Reactive_Link_gap.cached_style            # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_shape'):    # -- Check if cached shape exists\n",
    "                del process_HIVST_Reactive_Link_gap.cached_shape            # -- Remove cached shape\n",
    "            return                                                          # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Reactive_Link_gap_style = (                                # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Reactive_Link_gap.style                                # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                             # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                      # -- Highlight non-zero gaps in red\n",
    "        )                                                                   # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Reactive_Link_gap.cached_style = df_HIVST_Reactive_Link_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_HIVST_Reactive_Link_gap.cached_shape = df_HIVST_Reactive_Link.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Reactive_Link_gap['ReportPeriod'].iloc[0]  # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"            # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"        # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                    # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        report_description = []                                             # -- Initialize report description\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns_wrap[0]] != 0).any():   # -- Check if any non-zero gaps exist\n",
    "            report_description.append(                                       # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"\n",
    "            )                                                               # -- Add referral gap description\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns_wrap[1]] != 0).any():   # -- Check if any non-zero gaps exist\n",
    "            report_description.append(                                       # -- Define report description\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\nplus {df_columns[3]}\\n\"\n",
    "                f\"should be equal to {df_columns[1]}\"\n",
    "            )                                                               # -- Add confirmatory test gap description\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns_wrap[2]] != 0).any():   # -- Check if any non-zero gaps exist\n",
    "            report_description.append(                                       # -- Define report description\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns[4]}\\n\"\n",
    "                f\"should be equal to {df_columns[2]}\"\n",
    "            )                                                               # -- Add linkage gap description\n",
    "        report_description = \"\\n\\n\".join(report_description)                # -- Join all descriptions into a single string\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                       # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                        # -- Pass report name\n",
    "            df_style=df_HIVST_Reactive_Link_gap_style,                     # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                               # -- Pass image file name\n",
    "            img_file_path=report_image_path,                               # -- Pass image file path\n",
    "            doc_description=report_description,                            # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                        # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                       # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                       # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                               # -- Pass Excel sheet name\n",
    "        )                                                                   # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                                  # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Reactive_Link_gap_style)             # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                                  # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")               # -- Log general error\n",
    "        if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):        # -- Check if cached style exists\n",
    "            del process_HIVST_Reactive_Link_gap.cached_style                # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Reactive_Link_gap, 'cached_shape'):        # -- Check if cached shape exists\n",
    "            del process_HIVST_Reactive_Link_gap.cached_shape                # -- Remove cached shape\n",
    "        return                                                             # -- Exit function on general error\n",
    "    # -- End of function                                                                                  # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7477b73",
   "metadata": {},
   "source": [
    "#### - HIVST Prevention Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Prevention Service gap\n",
    "def process_HIVST_Prevention_Serv_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process HIVST Prevention Service gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of individual reporting HIVST results\",\n",
    "            \"Number of individuals reporting non reactive HIVST results that referred prevention services.\",\n",
    "            \"Number of individuals reporting non reactive HIVST results that accessed prevention services\"\n",
    "        ]\n",
    "        name = \"HIVST Prevention Service gap\"                           # -- Define general name\n",
    "        gap_columns = [\n",
    "            \"HIVST Non-Reactive Referral for Prevention Services gap\", \n",
    "            \"HIVST Non-Reactive Client that Accessed for Prevention Services gap\"\n",
    "        ]                                                               # -- Define gap column names\n",
    "        report_name = f\"{name}20\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Prevention_Serv = prepare_and_convert_df(              # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_HIVST_Prevention_Serv is None:                            # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_HIVST_Prevention_Serv[gap_columns[0]] = np.where(  \n",
    "            df_HIVST_Prevention_Serv[df_columns[1]] > df_HIVST_Prevention_Serv[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Prevention_Serv[df_columns[1]] - df_HIVST_Prevention_Serv[df_columns[0]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated referral gap to new column\n",
    "\n",
    "        df_HIVST_Prevention_Serv[gap_columns[1]] = np.where(  \n",
    "            df_HIVST_Prevention_Serv[df_columns[2]] != df_HIVST_Prevention_Serv[df_columns[1]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Prevention_Serv[df_columns[2]] - df_HIVST_Prevention_Serv[df_columns[1]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated access gap to new column\n",
    "\n",
    "        reorder_columns = MSF_hierarchy + [\n",
    "            df_columns[0], df_columns[1], gap_columns[0], \n",
    "            df_columns[2], gap_columns[1]\n",
    "        ]                                                               # -- Define column order for DataFrame\n",
    "\n",
    "        df_HIVST_Prevention_Serv = df_HIVST_Prevention_Serv[reorder_columns]  # -- Reorder DataFrame columns\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Prevention_Serv)                   # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Prevention_Serv_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Prevention_Serv.shape          # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_HIVST_Prevention_Serv_gap.cached_style)  # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Prevention_Serv_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HIVST_Prevention_Serv,                                # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_HIVST_Prevention_Serv_gap is None:                        # -- Check if no gaps found\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "                del process_HIVST_Prevention_Serv_gap.cached_style      # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HIVST_Prevention_Serv_gap.cached_shape      # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Prevention_Serv_gap_style = (                          # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Prevention_Serv_gap.style                          # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap[0])               # -- Highlight first gap column in red\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap[1])            # -- Highlight second gap column in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Prevention_Serv_gap.cached_style = df_HIVST_Prevention_Serv_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_HIVST_Prevention_Serv_gap.cached_shape = df_HIVST_Prevention_Serv.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Prevention_Serv_gap['ReportPeriod'].iloc[0]  # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        report_description = []                                         # -- Initialize report description\n",
    "        if (df_HIVST_Prevention_Serv_gap[gap_columns_wrap[0]] != 0).any():  # -- Check if any non-zero gaps exist\n",
    "            report_description.append(                                  # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"\n",
    "            )                                                           # -- Add referral gap description\n",
    "        if (df_HIVST_Prevention_Serv_gap[gap_columns_wrap[1]] != 0).any():  # -- Check if any non-zero gaps exist\n",
    "            report_description.append(                                  # -- Define report description\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[1]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Add access gap description\n",
    "        report_description = \"\\n\\n\".join(report_description)            # -- Join all descriptions into a single string\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_HIVST_Prevention_Serv_gap_style,               # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                           # -- Pass image file name\n",
    "            img_file_path=report_image_path,                           # -- Pass image file path\n",
    "            doc_description=report_description,                        # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                    # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                   # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                           # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Prevention_Serv_gap_style)       # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "            del process_HIVST_Prevention_Serv_gap.cached_style          # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HIVST_Prevention_Serv_gap.cached_shape          # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                              # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86635fa",
   "metadata": {},
   "source": [
    "#### - HIVST Partner Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf21ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process HIVST Partner Screening gap\n",
    "def process_HIVST_Partner_Screening_gap(display_output=None):            # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process HIVST Partner Screening  gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of partners of people living with HIV screened with HIVST kit (confirmed during follow up)\",\n",
    "            \"Number of partners of people living with HIV reporting HIVST results\"\n",
    "        ]\n",
    "        name = \"HIVST Partner Screening gap\"                            # -- Define general name\n",
    "        gap_columns = [\"HIVST Partner Screening gap\"]                    # -- Define gap column names\n",
    "        report_name = f\"{name}21\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Partner_Screening = prepare_and_convert_df(            # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_HIVST_Partner_Screening is None:                          # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_HIVST_Partner_Screening[gap_columns[0]] = np.where(  \n",
    "            df_HIVST_Partner_Screening[df_columns[1]] != df_HIVST_Partner_Screening[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_HIVST_Partner_Screening[df_columns[1]] - df_HIVST_Partner_Screening[df_columns[0]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated screening gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Partner_Screening)                 # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Partner_Screening_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Partner_Screening.shape        # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_HIVST_Partner_Screening_gap.cached_style)  # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Partner_Screening_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for gaps\n",
    "            df=df_HIVST_Partner_Screening,                              # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_HIVST_Partner_Screening_gap is None:                        # -- Check if no gaps found\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "                del process_HIVST_Partner_Screening_gap.cached_style    # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_HIVST_Partner_Screening_gap.cached_shape    # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Partner_Screening_gap_style = (                          # -- Apply styling to filtered DataFrame\n",
    "            df_HIVST_Partner_Screening_gap.style                          # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)               # -- Highlight gap column in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Partner_Screening_gap.cached_style = df_HIVST_Partner_Screening_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_HIVST_Partner_Screening_gap.cached_shape = df_HIVST_Partner_Screening.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Partner_Screening_gap['ReportPeriod'].iloc[0]  # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_HIVST_Partner_Screening_gap[gap_columns_wrap[0]] != 0).any():  # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_HIVST_Partner_Screening_gap_style,               # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                           # -- Pass image file name\n",
    "            img_file_path=report_image_path,                           # -- Pass image file path\n",
    "            doc_description=report_description,                        # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                    # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                   # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                   # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                           # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_HIVST_Partner_Screening_gap_style)       # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "            del process_HIVST_Partner_Screening_gap.cached_style        # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Partner_Screening_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_HIVST_Partner_Screening_gap.cached_shape        # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d488869f",
   "metadata": {},
   "source": [
    "### ICT MSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6796d064",
   "metadata": {},
   "source": [
    "#### - ICT Offereing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ICT Index Acceptance gap\n",
    "def process_ICT_Index_Acceptance_gap(display_output=None):               # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process ICT Index Acceptance  gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of HIV Positive Clients Offered Index Testing\",\n",
    "            \"Number of HIV Positive Clients Accepting Index Testing\"\n",
    "        ]\n",
    "        name = \"ICT Index Acceptance gap\"                               # -- Define general name\n",
    "        gap_columns = [\"ICT Index Acceptance gap\"]                          # -- Define gap column names\n",
    "        report_name = f\"{name}22\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_main[gap_columns[0]] = np.where(  \n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],            # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],            # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated acceptance gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):  # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Index_Acceptance_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_ICT_Index_Acceptance_gap.cached_style)  # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(                   # -- Filter DataFrame for gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_mine_gap is None:                                         # -- Check if no gaps found\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "                del process_ICT_Index_Acceptance_gap.cached_style       # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ICT_Index_Acceptance_gap.cached_shape       # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_mine_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style                                           # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight gap column in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_ICT_Index_Acceptance_gap.cached_style = df_mine_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_ICT_Index_Acceptance_gap.cached_shape = df_main.shape  # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]             # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():              # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_mine_gap_style,                                 # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                            # -- Pass image file name\n",
    "            img_file_path=report_image_path,                            # -- Pass image file path\n",
    "            doc_description=report_description,                         # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_mine_gap_style)                        # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):   # -- Check if cached style exists\n",
    "            del process_ICT_Index_Acceptance_gap.cached_style           # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_ICT_Index_Acceptance_gap, 'cached_shape'):   # -- Check if cached shape exists\n",
    "            del process_ICT_Index_Acceptance_gap.cached_shape           # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb07f43",
   "metadata": {},
   "source": [
    "#### - ICT Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16484272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ICT Contact gap\n",
    "def process_ICT_Contact_gap(display_output=None):                        # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process ICT Contact gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of HIV Positive Clients Accepting Index Testing\",   # -- Define list of HIVST reactive confirmed and linkage columns\n",
    "            \"Number of Children enumerated and Partners elicited from index client\"\n",
    "        ]\n",
    "        name = \"ICT Contact gap\"                                        # -- Define general name\n",
    "        gap_columns = [\"ICT Contact gap\"]                               # -- Define gap column names\n",
    "        report_name = f\"{name}23\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_main[gap_columns[0]] = np.where(  \n",
    "            df_main[df_columns[1]] < df_main[df_columns[0]],            # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],            # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated contact gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_style'):        # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Contact_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_ICT_Contact_gap.cached_style)       # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(                   # -- Filter DataFrame for gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_mine_gap is None:                                         # -- Check if no gaps found\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_style'):        # -- Check if cached style exists\n",
    "                del process_ICT_Contact_gap.cached_style                # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_shape'):        # -- Check if cached shape exists\n",
    "                del process_ICT_Contact_gap.cached_shape                # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_mine_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style                                           # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)               # -- Highlight gap column in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_ICT_Contact_gap.cached_style = df_mine_gap_style        # -- Store styled DataFrame in cache\n",
    "        process_ICT_Contact_gap.cached_shape = df_main.shape            # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]             # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():              # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be greater than {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_mine_gap_style,                                 # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                            # -- Pass image file name\n",
    "            img_file_path=report_image_path,                            # -- Pass image file path\n",
    "            doc_description=report_description,                         # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_mine_gap_style)                        # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_ICT_Contact_gap, 'cached_style'):            # -- Check if cached style exists\n",
    "            del process_ICT_Contact_gap.cached_style                    # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_ICT_Contact_gap, 'cached_shape'):            # -- Check if cached shape exists\n",
    "            del process_ICT_Contact_gap.cached_shape                    # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1337349",
   "metadata": {},
   "source": [
    "#### - ICT HTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d23d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ICT HTS gap\n",
    "def process_ICT_HTS_gap(display_output=None):                            # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process ICT HTS gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of ICT HTS columns\n",
    "            \"Number of Children enumerated and Partners elicited from index client\",\n",
    "            \"Number of contacts of index clients tested HIV Positive\",\n",
    "            \"Number of contacts of index clients tested HIV Negative\"\n",
    "        ]\n",
    "        name = \"ICT Contact Testing gap\"                                # -- Define general name\n",
    "        gap_columns = [\"ICT Contact Testing gap\"]                       # -- Define gap column names\n",
    "        report_name = f\"{name}24\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_main[gap_columns[0]] = np.where(  \n",
    "            df_main[df_columns[1:3]].sum(axis=1) != df_main[df_columns[0]],  # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated testing gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_ICT_HTS_gap, 'cached_style'):            # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_HTS_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_ICT_HTS_gap.cached_style)           # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(                   # -- Filter DataFrame for gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_mine_gap is None:                                         # -- Check if no gaps found\n",
    "            if hasattr(process_ICT_HTS_gap, 'cached_style'):            # -- Check if cached style exists\n",
    "                del process_ICT_HTS_gap.cached_style                    # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_ICT_HTS_gap, 'cached_shape'):            # -- Check if cached shape exists\n",
    "                del process_ICT_HTS_gap.cached_shape                    # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_mine_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style                                           # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)               # -- Highlight gap column in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_ICT_HTS_gap.cached_style = df_mine_gap_style            # -- Store styled DataFrame in cache\n",
    "        process_ICT_HTS_gap.cached_shape = df_main.shape                # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]             # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():              # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\npluse {df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_mine_gap_style,                                 # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                            # -- Pass image file name\n",
    "            img_file_path=report_image_path,                            # -- Pass image file path\n",
    "            doc_description=report_description,                         # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_mine_gap_style)                        # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_ICT_HTS_gap, 'cached_style'):                # -- Check if cached style exists\n",
    "            del process_ICT_HTS_gap.cached_style                        # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_ICT_HTS_gap, 'cached_shape'):                # -- Check if cached shape exists\n",
    "            del process_ICT_HTS_gap.cached_shape                        # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5e9ce",
   "metadata": {},
   "source": [
    "#### - ICT Positive Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process ICT Positive Linkagegap\n",
    "def process_ICT_Positive_Link_gap(display_output=None):                  # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process ICT Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of ICT HTS columns\n",
    "            \"Number of contacts of index clients tested HIV Positive\",\n",
    "            \"Number of contacts of index clients linked to ART\"\n",
    "        ]\n",
    "        name = \"ICT Contact Testing gap\"                                # -- Define general name\n",
    "        gap_columns = [\"ICT Contact Testing gap\"]                       # -- Define gap column names\n",
    "        report_name = f\"{name}24\"                                       # -- Define report name\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"HTS MSF\",                                   # -- Specify DHIS2 data key\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns                                     # -- Include specified HTS columns\n",
    "        )\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        df_main[gap_columns[0]] = np.where(  \n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],           # -- Check if Testing Frequency exceeds Assisted & Unassisted\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],            # -- Calculate gap if condition met\n",
    "            0                                                           # -- Set gap to 0 if no discrepancy\n",
    "        )                                                               # -- Assign calculated linkage gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Modify DataFrame headers for readability\n",
    "        HTS_Couple_Counselling_columns_wrap = wrap_column_headers2(df_columns)  # -- Wrap specific column names for consistency\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names for output\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):   # -- Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Positive_Link_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure data consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Create message for cached display\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line above message\n",
    "                    print(cached_display_name)                          # -- Print cached display message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator line below message\n",
    "                    display(process_ICT_Positive_Link_gap.cached_style) # -- Render cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(                   # -- Filter DataFrame for gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame for filtering\n",
    "            msg=No_gap_msg,                                             # -- Message for empty result\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_mine_gap is None:                                         # -- Check if no gaps found\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):  # -- Check if cached style exists\n",
    "                del process_ICT_Positive_Link_gap.cached_style          # -- Remove cached styled DataFrame\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_ICT_Positive_Link_gap.cached_shape          # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_mine_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style                                           # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight gap column in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_ICT_Positive_Link_gap.cached_style = df_mine_gap_style  # -- Store styled DataFrame in cache\n",
    "        process_ICT_Positive_Link_gap.cached_shape = df_main.shape      # -- Store original DataFrame shape in cache\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]             # -- Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Create image file name with report period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Specify path for image export\n",
    "        report_sheet_name = report_name                                # -- Set Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():              # -- Check if any non-zero gaps exist\n",
    "            report_description = (                                      # -- Define report description\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )                                                           # -- Store description for Word document\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        export_df_to_doc_image_excel(                                   # -- Export DataFrame to multiple formats\n",
    "            report_name=report_name,                                    # -- Pass report name\n",
    "            df_style=df_mine_gap_style,                                 # -- Pass styled DataFrame\n",
    "            img_file_name=report_image_name,                            # -- Pass image file name\n",
    "            img_file_path=report_image_path,                            # -- Pass image file path\n",
    "            doc_description=report_description,                         # -- Pass description\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specific columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap column in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Pass Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Pass Excel sheet name\n",
    "        )                                                               # -- Execute export to image, Excel, and Word\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_mine_gap_style)                        # -- Render styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Catch any unhandled exceptions\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Log general error\n",
    "        if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):      # -- Check if cached style exists\n",
    "            del process_ICT_Positive_Link_gap.cached_style              # -- Remove cached styled DataFrame\n",
    "        if hasattr(process_ICT_Positive_Link_gap, 'cached_shape'):      # -- Check if cached shape exists\n",
    "            del process_ICT_Positive_Link_gap.cached_shape              # -- Remove cached shape\n",
    "        return                                                         # -- Exit function on general error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa865ba",
   "metadata": {},
   "source": [
    "## PMCTCT MSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594b292",
   "metadata": {},
   "source": [
    "#### - New ANC HTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT New ANC HTS gap\n",
    "def process_PMTCT_ANC_Optmz_gap(display_output=None):                    # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT New ANC HTS gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of PMTCT New ANC columns\n",
    "            \"Number of new ANC Clients\",                                # -- Column for new ANC clients\n",
    "            \"Number of pregnant women with previously known HIV positive infection\"  # -- Column for known HIV positives\n",
    "        ]                                                               \n",
    "        df_columns_spec = ['Number of new ANC Clients',                 # -- Define all relevant columns\n",
    "                           'Number of pregnant women with previously known HIV positive infection',  # -- Known HIV positives column\n",
    "                           'Number of pregnant women HIV tested and received results (ANC)',  # -- ANC tested results column\n",
    "                           'Number of pregnant women HIV tested and received results (L&D)',  # -- L&D tested results column\n",
    "                           'Number of pregnant women HIV tested and received results (<72hrs Postpartum)'  # -- <72hrs Postpartum tested results column\n",
    "        ]                                                               # -- Close list of specific columns\n",
    "        df_columns2 = ['ANC', 'L&D', '<72hrs Postpartum']               # -- Define service delivery point columns\n",
    "        name = \"PMTCT New ANC HTS Optimization gap\"                     # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT New ANC HTS gap\"]                        # -- Define gap column names\n",
    "        report_name = f\"{name}25\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_main2 = prepare_and_convert_df(                              # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp\",                             # -- Specify DHIS2 data key for HIVST approach\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns2                                    # -- Include specified HIVST mode columns\n",
    "        )                                                               # -- Store additional DataFrame\n",
    "        if df_main2 is None:                                            # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_main = df_main.merge(                                        # -- Merge HIVST mode data with primary data\n",
    "            df_main2,                                                   # -- Target DataFrame for merge\n",
    "            on=MSF_hierarchy,                                           # -- Merge on MSF hierarchy columns\n",
    "            how=\"left\"                                                  # -- Right join to keep all rows from primary data\n",
    "        )                                                               # -- Update df_main with merged data\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_main = df_main.rename(columns={                              # -- Rename columns to align with specified names\n",
    "            f\"{df_columns2[0]}\": f\"{df_columns_spec[2]}\",               # -- Rename ANC column\n",
    "            f\"{df_columns2[1]}\": f\"{df_columns_spec[3]}\",               # -- Rename L&D column\n",
    "            f\"{df_columns2[2]}\": f\"{df_columns_spec[4]}\"                # -- Rename <72hrs Postpartum column\n",
    "        })                                                              # -- Apply renamed columns to DataFrame\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_main.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # -- Sort by hierarchy\n",
    "        df_main = df_main.fillna(0)                                     # -- Replace NaN with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                                       # -- Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)                     # -- Apply integer conversion\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT ANC HTS gap\n",
    "            df_main[df_columns_spec[1:3]].sum(axis=1) != df_main[df_columns[0]],  # -- Check for Assisted gap\n",
    "            df_main[df_columns_spec[1:3]].sum(axis=1) - df_main[df_columns[0]],  # -- Calculate gap as sum minus new ANC clients\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):    # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_ANC_Optmz_gap.cached_style)   # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):    # -- Clear cache if it exists\n",
    "                del process_PMTCT_ANC_Optmz_gap.cached_style            # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape'):    # -- Clear cached shape\n",
    "                del process_PMTCT_ANC_Optmz_gap.cached_shape            # -- Remove cached shape\n",
    "            print(f\"⦸ {No_gap_msg}\")                                   # -- Notify user of no gaps\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_ANC_Optmz_gap.cached_style = df_main_gap_style    # -- Store styled DataFrame\n",
    "        process_PMTCT_ANC_Optmz_gap.cached_shape = df_main.shape        # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for Assisted gaps\n",
    "            report_description = (                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\npluse {df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"              # -- Describe expected equality\n",
    "            )                                                           # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns_spec,                # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):        # -- Clear cache if it exists\n",
    "            del process_PMTCT_ANC_Optmz_gap.cached_style                # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape'):        # -- Clear cached shape\n",
    "            del process_PMTCT_ANC_Optmz_gap.cached_shape                # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab63c92",
   "metadata": {},
   "source": [
    "#### - PMTCT Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3318518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Positive gap\n",
    "def process_PMTCT_Positive_gap(display_output=None):                    # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of PMTCT New ANC columns\n",
    "            \"Number of pregnant women HIV tested and received results (ANC)\",  # -- ANC tested results column\n",
    "            \"Number of pregnant women HIV tested and received results (L&D)\",  # -- L&D tested results column\n",
    "            \"Number of pregnant women HIV tested and received results (<72hrs Postpartum)\",  # -- <72hrs Postpartum tested results column\n",
    "            \"Number of pregnant women tested HIV positive (ANC)\",        # -- ANC positives column\n",
    "            \"Number of pregnant women tested HIV positive (L&D)\",        # -- L&D positives column\n",
    "            \"Number of pregnant women tested HIV positive (<72hrs Postpartum)\"  # -- <72hrs Postpartum positives column\n",
    "        ]                                                               # -- Close list of specific columns\n",
    "        df_columns2 = ['ANC', 'L&D', '<72hrs Postpartum']               # -- Define service delivery point columns\n",
    "        name = \"PMTCT Positive gap\"                                     # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT Positive (ANC) gap\",                      # -- ANC gap column\n",
    "                       \"PMTCT Positive (L&D) gap\",                      # -- L&D gap column\n",
    "                       \"PMTCT Positive (<72hrs Postpartum) gap\"]        # -- <72hrs Postpartum gap column\n",
    "        report_name = f\"{name}26\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp\",                             # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns2                                    # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_main2 = prepare_and_convert_df(                              # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp_pos\",                         # -- Specify DHIS2 data key for HIVST approach\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns\n",
    "            data_columns=df_columns2                                    # -- Include specified HIVST mode columns\n",
    "        )                                                               # -- Store additional DataFrame\n",
    "        if df_main2 is None:                                            # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_main = df_main.merge(                                        # -- Merge HIVST mode data with primary data\n",
    "            df_main2,                                                   # -- Target DataFrame for merge\n",
    "            on=MSF_hierarchy,                                           # -- Merge on MSF hierarchy columns\n",
    "            how=\"left\"                                                  # -- Right join to keep all rows from primary data\n",
    "        )                                                               # -- Update df_main with merged data\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_main = df_main.rename(columns={                              # -- Rename columns to align with specified names\n",
    "            f'ANC_x': f\"{df_columns[0]}\",                               # -- Rename ANC tested column\n",
    "            'L&D_x': f\"{df_columns[1]}\",                                # -- Rename L&D tested column\n",
    "            '<72hrs Postpartum_x': f\"{df_columns[2]}\",                  # -- Rename <72hrs Postpartum tested column\n",
    "            'ANC_y': f\"{df_columns[3]}\",                                # -- Rename ANC positives column\n",
    "            'L&D_y': f\"{df_columns[4]}\",                                # -- Rename L&D positives column\n",
    "            '<72hrs Postpartum_y': f\"{df_columns[5]}\"                   # -- Rename <72hrs Postpartum positives column\n",
    "        })                                                              # -- Apply renamed columns to DataFrame\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_main.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # -- Sort by hierarchy\n",
    "        df_main = df_main.fillna(0)                                     # -- Replace NaN with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                                       # -- Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)                     # -- Apply integer conversion\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT ANC positive gap\n",
    "            df_main[df_columns[3]] > df_main[df_columns[0]],            # -- Check if ANC positives exceed tested\n",
    "            df_main[df_columns[3]] - df_main[df_columns[0]],            # -- Calculate gap as positives minus tested\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        df_main[gap_columns[1]] = np.where(                             # -- Calculate PMTCT L&D positive gap\n",
    "            df_main[df_columns[4]] > df_main[df_columns[1]],            # -- Check if L&D positives exceed tested\n",
    "            df_main[df_columns[4]] - df_main[df_columns[1]],            # -- Calculate gap as positives minus tested\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        df_main[gap_columns[2]] = np.where(                             # -- Calculate PMTCT <72hrs Postpartum positive gap\n",
    "            df_main[df_columns[5]] > df_main[df_columns[2]],            # -- Check if <72hrs Postpartum positives exceed tested\n",
    "            df_main[df_columns[5]] - df_main[df_columns[2]],            # -- Calculate gap as positives minus tested\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_style'):     # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Positive_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Positive_gap.cached_style)    # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_style'):     # -- Clear cache if it exists\n",
    "                del process_PMTCT_Positive_gap.cached_style             # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_shape'):     # -- Clear cached shape\n",
    "                del process_PMTCT_Positive_gap.cached_shape             # -- Remove cached shape\n",
    "            print(f\"⦸ {No_gap_msg}\")                                   # -- Notify user of no gaps\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Positive_gap.cached_style = df_main_gap_style     # -- Store styled DataFrame\n",
    "        process_PMTCT_Positive_gap.cached_shape = df_main.shape         # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []                                         # -- Initialize description list\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for ANC gaps\n",
    "            report_description.append(                                  # -- Add description for ANC gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"           # -- Describe expected ANC constraint\n",
    "            )                                                           # -- Close ANC description string\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():              # -- Check for L&D gaps\n",
    "            report_description.append(                                  # -- Add description for L&D gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[4]}\\n\"\n",
    "                f\"should not be greater than {df_columns[1]}\"           # -- Describe expected L&D constraint\n",
    "            )                                                           # -- Close L&D description string\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():              # -- Check for <72hrs Postpartum gaps\n",
    "            report_description.append(                                  # -- Add description for <72hrs Postpartum gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns[5]}\\n\"\n",
    "                f\"should not be greater than {df_columns[2]}\"           # -- Describe expected <72hrs Postpartum constraint\n",
    "            )                                                           # -- Close <72hrs Postpartum description string\n",
    "        report_description = \"\\n\\n\".join(report_description)           # -- Join descriptions with newlines\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_Positive_gap, 'cached_style'):         # -- Clear cache if it exists\n",
    "            del process_PMTCT_Positive_gap.cached_style                 # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Positive_gap, 'cached_shape'):         # -- Clear cached shape\n",
    "            del process_PMTCT_Positive_gap.cached_shape                 # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b10ec6",
   "metadata": {},
   "source": [
    "#### - PMTCT Previouly Known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1e8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Previously Known gap\n",
    "def process_PMTCT_PK_gap(display_output=None):                          # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Previously Known gap, comparing known HIV-positive pregnant women\n",
    "    to those already on ART prior to pregnancy. Exports results as image, Excel, and\n",
    "    Word files. Caches the styled DataFrame and displays it on subsequent calls if\n",
    "    data shape is unchanged.\n",
    "\n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gaps.\n",
    "            Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of PMTCT columns\n",
    "            \"Number of pregnant women with previously known HIV positive infection\",  # -- Known HIV positives column\n",
    "            \"Number of HIV positive pregnant women already on ART prior to this pregnancy\"  # -- ART prior to pregnancy column\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Previously Known gap\"                             # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT Previously Known gap\"]                    # -- Define gap column name\n",
    "        report_name = f\"{name}27\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified PMTCT columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "\n",
    "        # -- Step 4: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT previously known gap\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],           # -- Check if ART counts differ from known positives\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],            # -- Calculate gap as ART minus known positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names (commented-out, undefined)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_style'):           # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_PK_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_PK_gap.cached_style)          # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_style'):           # -- Clear cache if it exists\n",
    "                del process_PMTCT_PK_gap.cached_style                   # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_shape'):           # -- Clear cached shape\n",
    "                del process_PMTCT_PK_gap.cached_shape                   # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 8: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_PMTCT_PK_gap.cached_style = df_main_gap_style           # -- Store styled DataFrame\n",
    "        process_PMTCT_PK_gap.cached_shape = df_main.shape               # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 10: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        report_description = \"\"                                         # -- Initialize description string\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for previously known gaps\n",
    "            report_description = (                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"                   # -- Describe expected equality\n",
    "            )                                                           # -- Close description string\n",
    "\n",
    "        # -- Step 12: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                   # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                           # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 13: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "        # -- Step 14: Handle errors\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_PK_gap, 'cached_style'):               # -- Clear cache if it exists\n",
    "            del process_PMTCT_PK_gap.cached_style                       # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_PK_gap, 'cached_shape'):               # -- Clear cached shape\n",
    "            del process_PMTCT_PK_gap.cached_shape                       # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff78ed",
   "metadata": {},
   "source": [
    "#### - PMTCT Linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90960490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Positive Linkage gap\n",
    "def process_PMTCT_Positive_Linkage_gap(display_output=None):            # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of PMTCT New ANC columns\n",
    "            \"Number of pregnant women tested HIV positive\",             # -- Total HIV positives column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during ANC <36wks of pregnancy\",  # -- ART initiation ANC <36wks column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during ANC >36wks of pregnancy\",  # -- ART initiation ANC >36wks column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Labour\",  # -- ART initiation Labour column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (<72 hrs)\",  # -- ART initiation Postpartum <72hrs column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (>72 hrs - < 6 months)\",  # -- ART initiation Postpartum >72hrs-<6 months column\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (>6 - 12 months)\"  # -- ART initiation Postpartum >6-12 months column\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Positive Linkage Known gap\"                       # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT Positive Linkage gap\"]                    # -- Define gap column name\n",
    "        report_name = f\"{name}28\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[1:7]].sum(axis=1) != df_main[df_columns[0]],  # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[1:7]].sum(axis=1) - df_main[df_columns[0]],  # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Positive_Linkage_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Positive_Linkage_gap.cached_style     # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Positive_Linkage_gap.cached_shape     # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Positive_Linkage_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Positive_Linkage_gap.cached_shape = df_main.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description = (                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\npluse {df_columns[2]}\\npluse {df_columns[3]}\\npluse {df_columns[4]}\"\n",
    "                f\"\\npluse {df_columns[5]}\\npluse {df_columns[6]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"                   # -- Describe expected equality\n",
    "            )                                                           # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_PMTCT_Positive_Linkage_gap.cached_style         # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_PMTCT_Positive_Linkage_gap.cached_shape         # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdd57a",
   "metadata": {},
   "source": [
    "#### - PMTCT Seroconversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Seroconversion gap\n",
    "def process_PMTCT_Seroconversion_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Seroconversion gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of Seroconversion columns\n",
    "            \"Number of pregnant women retested after initial HIV negative test\",  # -- Retested women column\n",
    "            \"Number of pregnant women retested who seroconverted to HIV positive after initial HIV negative test\"  # -- Seroconverted women column\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Seroconversion gap\"                               # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT Seroconversion check\"]                    # -- Define gap column name\n",
    "        report_name = f\"{name}29\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[1]] > 0,                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[1]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Seroconversion_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Seroconversion_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Seroconversion_gap.cached_style       # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Seroconversion_gap.cached_shape       # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)               # -- Highlight non-zero gaps in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Seroconversion_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Seroconversion_gap.cached_shape = df_main.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description = (                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"Note: {df_columns[1]} is a quality indicator and should review thoroughly.\"  # -- Describe expected equality\n",
    "            )                                                           # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "        # -- Step 18: Handle errors\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_PMTCT_Seroconversion_gap.cached_style           # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Seroconversion_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_PMTCT_Seroconversion_gap.cached_shape           # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca72ad",
   "metadata": {},
   "source": [
    "#### - PMTCT Coinfection (syphilis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Syphilis Test gap\n",
    "def process_PMTCT_Syphilis_Test_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Syphilis Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of Syphilis Test columns\n",
    "            \"Number of new ANC Clients\",\n",
    "            \"Number of new ANC Clients tested for syphilis\",\n",
    "            \"Number of new ANC Clients tested positive for syphilis\",\n",
    "            \"Number of the ANC Clients treated for Syphilis\"  # -- Seroconverted women column\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Syphilis Test gap\"                               # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT New ANC Syphilis Test gap\",\n",
    "                       \"PMTCT Syphilis Positive gap\",\n",
    "                       \"PMTCT Syphilis Positive Treatment gap\"]                    # -- Define gap column name\n",
    "        report_name = f\"{name}30\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        ) \n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[2]] > df_main[df_columns[1]],                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[2]] - df_main[df_columns[1]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        ) \n",
    "        \n",
    "        df_main[gap_columns[2]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[2]],                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[3]] - df_main[df_columns[2]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Syphilis_Test_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Syphilis_Test_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Syphilis_Test_gap.cached_style       # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Syphilis_Test_gap.cached_shape       # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap[0])\n",
    "            .map(outlier_red, subset=gap_columns_wrap[1:3])               # -- Highlight non-zero gaps in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Syphilis_Test_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Syphilis_Test_gap.cached_shape = df_main.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should not be greater than {df_columns[1]}\"\n",
    "            )\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should be equal to {df_columns[2]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )\n",
    "        report_description = \"\\n\\n\".join(report_description)                                                       # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "        # -- Step 18: Handle errors\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_PMTCT_Syphilis_Test_gap.cached_style           # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_PMTCT_Syphilis_Test_gap.cached_shape           # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5112e5",
   "metadata": {},
   "source": [
    "#### - PMTCT Coinfection (HBV, HCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Hepatitis Test gap\n",
    "def process_PMTCT_Hepatitis_Test_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Hepatitis Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of Syphilis Test columns\n",
    "            \"Number of new ANC Clients\",\n",
    "            \"Number of new ANC Clients tested for HBV ( ANC, L&D, <72hrs Post Partum)\",\n",
    "            \"Number of new ANC Clients tested for HCV ( ANC, L&D, < 72hrs Post Partum)\"\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Syphilis Test gap\"                               # -- Define general name for reporting\n",
    "        gap_columns = [\n",
    "            \"PMTCT Hepatitis B Test gap\",\n",
    "            \"PMTCT Hepatitis C Positive gap\"\n",
    "        ]                    \n",
    "        report_name = f\"{name}31\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        ) \n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(                             # -- Calculate PMTCT positive linkage gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[0]],                                 # -- Check if ART initiations sum differs from positives\n",
    "            df_main[df_columns[2]] - df_main[df_columns[0]],                                     # -- Calculate gap as ART sum minus positives\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                           # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)    # -- Wrap specific column names\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Hepatitis_Test_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Hepatitis_Test_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                   # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Hepatitis_Test_gap.cached_style       # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Hepatitis_Test_gap.cached_shape       # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)               # -- Highlight non-zero gaps in yellow\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Hepatitis_Test_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Hepatitis_Test_gap.cached_shape = df_main.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]             # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"        # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"    # -- Define path for image export\n",
    "        report_sheet_name = report_name                                # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():              # -- Check for positive linkage gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )\n",
    "        report_description = \"\\n\\n\".join(report_description)                                                       # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "        # -- Step 18: Handle errors\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")           # -- Print error details\n",
    "        if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_PMTCT_Hepatitis_Test_gap.cached_style           # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_PMTCT_Hepatitis_Test_gap.cached_shape           # -- Remove cached shape\n",
    "        return                                                      # -- Exit function on error\n",
    "    # -- End of function                                                                          # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b2fc2",
   "metadata": {},
   "source": [
    "#### - PMTCT Labour and Delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f524f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Labour and Delivery gap\n",
    "def process_PMTCT_Labour_Delivery_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Labour and Delivery gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of labour and delivery columns\n",
    "            \"Total deliveries at facility (booked and unbooked pregnant women) - Total\",\n",
    "            \"Number of booked HIV positive pregnant women who delivered at facility - Total\",\n",
    "            \"Number of unbooked HIV positive pregnant women who delivered at the facility - Total\",\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\"\n",
    "        ]                                                               # -- Close list of columns\n",
    "        name = \"PMTCT Labour and Delivery gap\"                          # -- Define general name for reporting\n",
    "        gap_columns = [                                                 # -- Define list of gap columns\n",
    "            \"PMTCT Facility Delivery by PPW gap\",\n",
    "            \"PMTCT Facility Livebirth by PPW gap\"\n",
    "        ]                                                               # -- Close list of gap columns\n",
    "        report_name = f\"{name}32\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified HTS Enrolment columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(                             # -- Calculate PMTCT Facility Delivery by PPW gap\n",
    "            df_main[df_columns[1:3]].sum(axis=1) > df_main[df_columns[0]],  # -- Check if sum of booked/unbooked exceeds total deliveries\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # -- Calculate gap as sum minus total deliveries\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(                             # -- Calculate PMTCT Facility Livebirth by PPW gap\n",
    "            df_main[df_columns[3]] < df_main[df_columns[1:3]].sum(axis=1),  # -- Check if live births are less than sum of booked/unbooked\n",
    "            df_main[df_columns[3]] - df_main[df_columns[1:3]].sum(axis=1),  # -- Calculate gap as live births minus sum\n",
    "            0                                                           # -- Set to 0 if no gap\n",
    "        )                                                               # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                    # -- Apply wrapping to DataFrame headers\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)            # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                              # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                           # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                       # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"  # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    print(cached_display_name)                          # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))               # -- Print separator\n",
    "                    display(process_PMTCT_Labour_Delivery_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                              # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                    # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                 # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                             # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                 # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                 # -- No negative value filter\n",
    "            opPos=None,                                                 # -- No positive value filter\n",
    "            opZero=None,                                                # -- No zero value filter\n",
    "            opLT100=None                                                # -- No less-than-100 filter\n",
    "        )                                                               # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                         # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Labour_Delivery_gap.cached_style       # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Labour_Delivery_gap.cached_shape       # -- Remove cached shape\n",
    "            return                                                      # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                           # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                           # -- Create style object\n",
    "            .hide(axis='index')                                         # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                  # -- Highlight non-zero gaps in red\n",
    "        )                                                               # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Labour_Delivery_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Labour_Delivery_gap.cached_shape = df_main.shape  # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]              # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"         # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"     # -- Define path for image export\n",
    "        report_sheet_name = report_name                                 # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []                                         # -- Initialize descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():               # -- Check for PMTCT Facility Delivery by PPW gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"           # -- Describe expected equality\n",
    "            )                                                           # -- Close description string\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():               # -- Check for PMTCT Facility Livebirth by PPW gaps\n",
    "            report_description.append(                                      # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should not be less than {df_columns[1]}\\nplus {df_columns[2]}\"  # -- Describe expected equality\n",
    "                f\"Note: Where this PMTCT livebirth gap is true, please ignore the outlier.\"\n",
    "            )                                                           # -- Close description string\n",
    "        report_description = \"\\n\\n\".join(report_description)                                                       # -- Close description string\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                   # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                    # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                 # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                            # -- Image file name\n",
    "            img_file_path=report_image_path,                            # -- Image file path\n",
    "            doc_description=report_description,                         # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                     # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                    # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                    # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                            # -- Excel sheet name\n",
    "        )                                                               # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                              # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                        # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                              # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")            # -- Print error details\n",
    "        if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "            del process_PMTCT_Labour_Delivery_gap.cached_style           # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "            del process_PMTCT_Labour_Delivery_gap.cached_shape           # -- Remove cached shape\n",
    "        return                                                          # -- Exit function on error\n",
    "    # -- End of function                                                # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95091eb1",
   "metadata": {},
   "source": [
    "#### - PMTCT Facility HEI ARVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0ffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT Facility HEI ARVs gap\n",
    "def process_PMTCT_Facility_HEI_ARVs_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT Facility HEI ARVs gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of facility HEI ARVs columns\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # -- Total live births column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery\",  # -- ARV within 72hrs column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery\"  # -- ARV after 72hrs column\n",
    "        ]                                                               # -- Close list of facility HEI ARVs columns\n",
    "        df_columns2 = MSF_hierarchy + ['Facility']                      # -- Combine hierarchy and Facility columns\n",
    "        columns_to_keep = MSF_hierarchy + [df_columns[0]] + [f\"{df_columns[1]} (within the Facility)\"] + [f\"{df_columns[2]} (within the Facility)\"]  # -- Combine hierarchy and data columns\n",
    "        name = \"PMTCT Facility HEI ARVs gap\"                            # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT Facility HEI ARVs gap\"]                   # -- Define list of gap columns\n",
    "        report_name = f\"{name}33\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified PMTCT columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Rename and prepare ARV within 72hrs data\n",
    "        df_main2 = DHIS2_data['PMTCT MSF_sd<72_in-outside'][df_columns2].rename(  # -- Select and rename columns from <72hrs dataset\n",
    "            columns={\"Facility\": f\"{df_columns[1]} (within the Facility)\"}   # -- Rename Facility to ARV within 72hrs\n",
    "        )                                                                   # -- Store renamed DataFrame\n",
    "\n",
    "        # -- Step 4: Rename and prepare ARV after 72hrs data\n",
    "        df_main3 = DHIS2_data['PMTCT MSF_sd>72_in-outside'][df_columns2].rename(  # -- Select and rename columns from >72hrs dataset\n",
    "            columns={\"Facility\": f\"{df_columns[2]} (within the Facility)\"}   # -- Rename Facility to ARV after 72hrs\n",
    "        )                                                                   # -- Store renamed DataFrame\n",
    "\n",
    "        # -- Step 5: Merge primary data with ARV data\n",
    "        df_main = df_main.merge(df_main2, on=MSF_hierarchy, how='left')      # -- Merge primary data with ARV within 72hrs data\n",
    "        df_main = df_main.merge(df_main3, on=MSF_hierarchy, how='left')      # -- Merge primary data with ARV after 72hrs data\n",
    "\n",
    "        # -- Step 6: Retain specified columns\n",
    "        df_main = df_main[columns_to_keep]                                   # -- Filter to hierarchy and data columns\n",
    "\n",
    "        # -- Step 7: Clean and convert data types\n",
    "        df_main[df_columns[0]] = pd.to_numeric(df_main[df_columns[0]], errors='coerce')  # -- Convert total live births to numeric\n",
    "        df_main[f\"{df_columns[1]} (within the Facility)\"] = pd.to_numeric(df_main[f\"{df_columns[1]} (within the Facility)\"], errors='coerce')  # -- Convert ARV within 72hrs to numeric\n",
    "        df_main[f\"{df_columns[2]} (within the Facility)\"] = pd.to_numeric(df_main[f\"{df_columns[2]} (within the Facility)\"], errors='coerce')  # -- Convert ARV after 72hrs to numeric\n",
    "        df_main = df_main.fillna(0)                                         # -- Replace NaN with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                                           # -- Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)                         # -- Apply integer conversion\n",
    "\n",
    "        # -- Step 8: Calculate PMTCT Facility Delivery by PPW gap\n",
    "        df_main[gap_columns[0]] = np.where(                                 # -- Calculate PMTCT ARV prophylaxis gap\n",
    "            df_main[[f\"{df_columns[1]} (within the Facility)\", f\"{df_columns[2]} (within the Facility)\"]].sum(axis=1) != df_main[df_columns[0]],  # -- Check if sum of ARV prophylaxis differs from total live births\n",
    "            df_main[[f\"{df_columns[1]} (within the Facility)\", f\"{df_columns[2]} (within the Facility)\"]].sum(axis=1) - df_main[df_columns[0]],  # -- Calculate gap as sum minus total live births\n",
    "            0                                                               # -- Set to 0 if no gap\n",
    "        )                                                                   # -- Assign calculated gap to new column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                        # -- Apply wrapping to DataFrame headers\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)                # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                                  # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                               # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                           # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"    # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    print(cached_display_name)                              # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    display(process_PMTCT_Facility_HEI_ARVs_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                                  # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                        # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                     # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                                 # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                     # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                     # -- No negative value filter\n",
    "            opPos=None,                                                     # -- No positive value filter\n",
    "            opZero=None,                                                    # -- No zero value filter\n",
    "            opLT100=None                                                    # -- No less-than-100 filter\n",
    "        )                                                                   # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                             # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_Facility_HEI_ARVs_gap.cached_style         # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_Facility_HEI_ARVs_gap.cached_shape         # -- Remove cached shape\n",
    "            return                                                          # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                               # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                               # -- Create style object\n",
    "            .hide(axis='index')                                             # -- Hide row index for cleaner output\n",
    "            .map(outlier_red, subset=gap_columns_wrap)                      # -- Highlight non-zero gaps in red\n",
    "        )                                                                   # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Facility_HEI_ARVs_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_Facility_HEI_ARVs_gap.cached_shape = df_main.shape    # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]                  # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"             # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"         # -- Define path for image export\n",
    "        report_sheet_name = report_name                                     # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():                   # -- Check for PMTCT Facility Delivery by PPW gaps\n",
    "            report_description = (                                          # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  \n",
    "                f\"REPORT ONLY HEI ARVs FOR 2025 LIVE BIRTHS BY PPW.\"         \n",
    "                f\"Note: Where this PMTCT livebirth gap is true, please ignore the outlier.\"\n",
    "            )                                                               # -- Close description\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                       # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                        # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                     # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                                # -- Image file name\n",
    "            img_file_path=report_image_path,                                # -- Image file path\n",
    "            doc_description=report_description,                             # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                         # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                        # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                        # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                                # -- Excel sheet name\n",
    "        )                                                                   # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                                  # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                            # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                                  # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")                # -- Print error details\n",
    "        if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):    # -- Clear cache if it exists\n",
    "            del process_PMTCT_Facility_HEI_ARVs_gap.cached_style             # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape'):    # -- Clear cached shape\n",
    "            del process_PMTCT_Facility_HEI_ARVs_gap.cached_shape             # -- Remove cached shape\n",
    "        return                                                              # -- Exit function on error\n",
    "    # -- End of function                                                    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c4cc7e",
   "metadata": {},
   "source": [
    "#### - PMTCT EID PCR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf40201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT EID PCR Test gap\n",
    "def process_PMTCT_EID_PCR_Test_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT EID PCR Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of facility HEI ARVs columns\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # -- Total live births column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery\",  # -- ARV within 72hrs column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery\",\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\"  # -- ARV after 72hrs column\n",
    "        ] \n",
    "        df_columns_spec = [                                                  # -- Define list of facility HEI ARVs columns\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # -- Total live births column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery (outside the Facility)\",  # -- ARV within 72hrs column\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery (outside the Facility)\",\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\"  # -- ARV after 72hrs column\n",
    "        ]                                                                                                                   # -- Close list of facility HEI ARVs columns\n",
    "        df_columns2 = MSF_hierarchy + ['Outside Facility']                      # -- Combine hierarchy and Facility columns\n",
    "        columns_to_keep = (\n",
    "            MSF_hierarchy + [df_columns_spec[0]] + [df_columns_spec[1]] + \n",
    "            [df_columns_spec[2]] + [df_columns_spec[3]] + [df_columns_spec[4]]\n",
    "        ) # -- Combine hierarchy and data columns\n",
    "        name = \"PMTCT EID PCR Test gap\"                            # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT EID PCR Test gap\"]                   # -- Define list of gap columns\n",
    "        report_name = f\"{name}34\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified PMTCT columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 3: Rename and prepare ARV within 72hrs data\n",
    "        df_main2 = DHIS2_data['PMTCT MSF_sd<72_in-outside'][df_columns2].rename(  # -- Select and rename columns from <72hrs dataset\n",
    "            columns={\"Outside Facility\": df_columns_spec[1]}   # -- Rename Facility to ARV within 72hrs\n",
    "        )                                                                   # -- Store renamed DataFrame\n",
    "\n",
    "        # -- Step 4: Rename and prepare ARV after 72hrs data\n",
    "        df_main3 = DHIS2_data['PMTCT MSF_sd>72_in-outside'][df_columns2].rename(  # -- Select and rename columns from >72hrs dataset\n",
    "            columns={\"Outside Facility\": df_columns_spec[2]}   # -- Rename Facility to ARV after 72hrs\n",
    "        )                                                                   # -- Store renamed DataFrame\n",
    "\n",
    "        # -- Step 5: Merge primary data with ARV data\n",
    "        df_main = df_main.merge(df_main2, on=MSF_hierarchy, how='left')      # -- Merge primary data with ARV within 72hrs data\n",
    "        df_main = df_main.merge(df_main3, on=MSF_hierarchy, how='left')      # -- Merge primary data with ARV after 72hrs data\n",
    "\n",
    "        # -- Step 6: Retain specified columns\n",
    "        df_main = df_main[columns_to_keep]                                   # -- Filter to hierarchy and data columns\n",
    "\n",
    "        # -- Step 7: Clean and convert data types\n",
    "        df_main = df_main.fillna(0)                                         # -- Replace NaN with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # -- Identify float columns\n",
    "        for col in float_columns:                                           # -- Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)                         # -- Apply integer conversion\n",
    "\n",
    "        # -- Step 8: Calculate PMTCT EID gap\n",
    "        df_main[gap_columns[0]] = np.where(                                 # -- Calculate PMTCT ARV prophylaxis gap\n",
    "            df_main[df_columns_spec[5:7]].sum(axis=1) != df_main[df_columns_spec[7:9]].sum(axis=1),  # -- Check if sum of ARV prophylaxis differs from total live births\n",
    "            df_main[df_columns_spec[5:7]].sum(axis=1) - df_main[df_columns_spec[7:9]].sum(axis=1),  # -- Calculate gap as sum minus total live births\n",
    "            0                                                               # -- Set to 0 if no gap\n",
    "        ).astype(int)        \n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                        # -- Apply wrapping to DataFrame headers\n",
    "        df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)                # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                                  # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_EID_PCR_Test_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                               # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                           # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"    # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    print(cached_display_name)                              # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    display(process_PMTCT_EID_PCR_Test_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                                  # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                        # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                     # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                                 # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                     # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                     # -- No negative value filter\n",
    "            opPos=None,                                                     # -- No positive value filter\n",
    "            opZero=None,                                                    # -- No zero value filter\n",
    "            opLT100=None                                                    # -- No less-than-100 filter\n",
    "        )                                                                   # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                             # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_EID_PCR_Test_gap.cached_style         # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_EID_PCR_Test_gap.cached_shape         # -- Remove cached shape\n",
    "            return                                                          # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                               # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                               # -- Create style object\n",
    "            .hide(axis='index')                                             # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)                      # -- Highlight non-zero gaps in red\n",
    "        )                                                                   # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_EID_PCR_Test_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_EID_PCR_Test_gap.cached_shape = df_main.shape    # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]                  # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"             # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"         # -- Define path for image export\n",
    "        report_sheet_name = report_name                                     # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():                   # -- Check for PMTCT Facility Delivery by PPW gaps\n",
    "            report_description = (                                          # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[0]}\\nplus {df_columns_spec[1]}\\nplus {df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[3]}\\nplus {df_columns_spec[4]}\\n\"  \n",
    "                f\"REPORT ONLY EID PCR TEST FOR 2025 LIVE BIRTHS BY PPW.\"         \n",
    "                f\"Note: Where this PMTCT EID PCR Test gap is true, please ignore the outlier.\"\n",
    "            )                                                               # -- Close description\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                       # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                        # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                     # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                                # -- Image file name\n",
    "            img_file_path=report_image_path,                                # -- Image file path\n",
    "            doc_description=report_description,                             # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                         # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                        # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                        # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                                # -- Excel sheet name\n",
    "        )                                                                   # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                                  # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                            # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                                  # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")                # -- Print error details\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_style'):    # -- Clear cache if it exists\n",
    "            del process_PMTCT_EID_PCR_Test_gap.cached_style             # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_shape'):    # -- Clear cached shape\n",
    "            del process_PMTCT_EID_PCR_Test_gap.cached_shape             # -- Remove cached shape\n",
    "        return                                                              # -- Exit function on error\n",
    "    # -- End of function                                                    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39d1ff",
   "metadata": {},
   "source": [
    "#### - PMTCT EID PCR Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3702ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Define the main function to process PMTCT EID PCR Test gap\n",
    "def process_PMTCT_EID_PCR_Test_Result_gap(display_output=None):              # -- Define function with optional display parameter\n",
    "    \"\"\"\n",
    "    Process PMTCT EID PCR Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:                                                                # -- Begin exception handling block\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [                                                  # -- Define list of facility HEI ARVs columns\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\",\n",
    "            \"Number of HIV PCR results received for babies whose samples were taken within 72 hrs of birth\",\n",
    "            \"Number of HIV PCR results received for babies whose samples were taken between >72 hrs - < 2 months of birth\"  # -- ARV after 72hrs column\n",
    "        ]                                                                                                                  # -- Close list of facility HEI ARVs columns\n",
    "        name = \"PMTCT EID PCR Test Result gap\"                            # -- Define general name for reporting\n",
    "        gap_columns = [\"PMTCT EID PCR Test Result gap\"]                   # -- Define list of gap columns\n",
    "        report_name = f\"{name}35\"                                       # -- Define unique report identifier\n",
    "        No_gap_msg = f\"No {report_name}\"                                # -- Define message for no gaps scenario\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(                               # -- Fetch and prepare DataFrame from DHIS2 data\n",
    "            DHIS2_data_key=\"PMTCT MSF\",                                 # -- Specify DHIS2 data key for PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,                            # -- Use MSF hierarchy columns for organization\n",
    "            data_columns=df_columns                                     # -- Include specified PMTCT columns\n",
    "        )                                                               # -- Store prepared DataFrame\n",
    "        if df_main is None:                                             # -- Check if data preparation failed\n",
    "            return                                                      # -- Exit function if no data\n",
    "        \n",
    "        # -- Step 8: Calculate PMTCT EID gap\n",
    "        df_main[gap_columns[0]] = np.where(                                 # -- Calculate PMTCT ARV prophylaxis gap\n",
    "            df_main[df_columns[0:2]].sum(axis=1) != df_main[df_columns[2:4]].sum(axis=1),  # -- Check if sum of ARV prophylaxis differs from total live births\n",
    "            df_main[df_columns[0:2]].sum(axis=1) - df_main[df_columns[2:4]].sum(axis=1),  # -- Calculate gap as sum minus total live births\n",
    "            0                                                               # -- Set to 0 if no gap\n",
    "        )       \n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)                                        # -- Apply wrapping to DataFrame headers\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)                # -- Wrap gap column names\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:                                                  # -- Check if display output is requested\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_style'):  # -- Check for cached styled DataFrame\n",
    "                cached_shape = getattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_shape', None)  # -- Retrieve cached shape\n",
    "                current_shape = df_main.shape                               # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:                           # -- Compare shapes to ensure consistency\n",
    "                    cached_display_name = f\"✔️ Displaying {report_name} \"    # -- Display message for cached data\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    print(cached_display_name)                              # -- Print message\n",
    "                    print(\"-\" * len(cached_display_name))                   # -- Print separator\n",
    "                    display(process_PMTCT_EID_PCR_Test_Result_gap.cached_style)  # -- Display cached styled DataFrame\n",
    "                    return                                                  # -- Exit function after displaying cache\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(                        # -- Filter rows with non-zero gaps\n",
    "            df=df_main,                                                     # -- Input DataFrame\n",
    "            msg=No_gap_msg,                                                 # -- Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,                                     # -- Filter for non-zero gaps\n",
    "            opNeg=None,                                                     # -- No negative value filter\n",
    "            opPos=None,                                                     # -- No positive value filter\n",
    "            opZero=None,                                                    # -- No zero value filter\n",
    "            opLT100=None                                                    # -- No less-than-100 filter\n",
    "        )                                                                   # -- Store filtered DataFrame with gaps\n",
    "        if df_main_gap is None:                                             # -- Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_style'):  # -- Clear cache if it exists\n",
    "                del process_PMTCT_EID_PCR_Test_Result_gap.cached_style         # -- Remove cached style\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_shape'):  # -- Clear cached shape\n",
    "                del process_PMTCT_EID_PCR_Test_Result_gap.cached_shape         # -- Remove cached shape\n",
    "            return                                                          # -- Exit function\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (                                               # -- Apply styling to filtered DataFrame\n",
    "            df_main_gap.style                                               # -- Create style object\n",
    "            .hide(axis='index')                                             # -- Hide row index for cleaner output\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)                      # -- Highlight non-zero gaps in red\n",
    "        )                                                                   # -- Store styled DataFrame\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_EID_PCR_Test_Result_gap.cached_style = df_main_gap_style  # -- Store styled DataFrame\n",
    "        process_PMTCT_EID_PCR_Test_Result_gap.cached_shape = df_main.shape    # -- Store DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]                  # -- Extract report period\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"             # -- Define image file name with period\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"         # -- Define path for image export\n",
    "        report_sheet_name = report_name                                     # -- Define Excel sheet name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():                   # -- Check for PMTCT Facility Delivery by PPW gaps\n",
    "            report_description = (                                          # -- Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[0]}\\nplus {df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[2]}\\nplus {df_columns[3]}\\n\"  \n",
    "                f\"REPORT ONLY EID PCR TEST RESULT FOR 2025 LIVE BIRTHS BY PPW.\"         \n",
    "                f\"Note: Where this {name} is true, please ignore the outlier.\"\n",
    "            )                                                               # -- Close description\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        export_df_to_doc_image_excel(                                       # -- Export styled DataFrame and descriptions\n",
    "            report_name=report_name,                                        # -- Report identifier\n",
    "            df_style=df_main_gap_style,                                     # -- Styled DataFrame for export\n",
    "            img_file_name=report_image_name,                                # -- Image file name\n",
    "            img_file_path=report_image_path,                                # -- Image file path\n",
    "            doc_description=report_description,                             # -- Description for Word document\n",
    "            doc_indicators_to_italicize=df_columns,                         # -- Italicize specified columns in Word\n",
    "            doc_indicators_to_underline=gap_columns,                        # -- Underline gap columns in Word\n",
    "            xlm_file_path=doc_file_msf_outlier_xlsx,                        # -- Excel file path\n",
    "            xlm_sheet_name=report_sheet_name                                # -- Excel sheet name\n",
    "        )                                                                   # -- Execute export to multiple formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:                                                  # -- Check if display is requested\n",
    "            widget_display_df(df_main_gap_style)                            # -- Display styled DataFrame in widget\n",
    "\n",
    "    except Exception as e:                                                  # -- Handle any errors during execution\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")                # -- Print error details\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_style'):    # -- Clear cache if it exists\n",
    "            del process_PMTCT_EID_PCR_Test_Result_gap.cached_style             # -- Remove cached style\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_shape'):    # -- Clear cached shape\n",
    "            del process_PMTCT_EID_PCR_Test_Result_gap.cached_shape             # -- Remove cached shape\n",
    "        return                                                              # -- Exit function on error\n",
    "    # -- End of function                                                    # -- End of function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a58abb-0bde-4c1e-a614-10e7b141c454",
   "metadata": {},
   "source": [
    "## Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fb0e5-ba42-4cdf-83e8-ced3d4616b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- List of function descriptions for display\n",
    "function_description_name = [\n",
    "    \"Get Data\",                                # -- Description for LGA report rate gap\n",
    "    \"Generate Report\",                         # -- Description for report generating\n",
    "    \"ANSO Report Rate\",                        # -- Description for LGA report rate gap\n",
    "    \"LGA Report Rate\",                         # -- Description for facility report rate gap\n",
    "    \"AGYW HTS\",                                # -- Description for AGYW HTS gap\n",
    "    \"AGYW Pos\",                                # -- Description for AGYW positive gap\n",
    "    \"AGYW Pos Linkage\",                        # -- Description for AGYW positive linkage gap \n",
    "    \"AGYW TB Screening\",                       # -- Description for AGYW TB screening gap\n",
    "    \"ART PosEnrolment\",                        # -- Description for ART positive enrolment gap \n",
    "    \"ART-3 subsets\",                           # -- Description for ART regimen line, MMD and DSD\n",
    "    \"ART Tx_New TB Screening\",                 # -- Description for ART Tx_New TB screening gap\n",
    "    \"ART TB Presumptive Test\",                 # -- Description for ART TB presumptive test gap\n",
    "    \"ART TB Treatment\",                        # -- Description for ART TB treatment gap\n",
    "    \"ART Viral Load Suppression\",              # -- Description for ART viral load suppression gap\n",
    "    \"HTS New Positive\",                        # -- Description for HTS new positive gap\n",
    "    \"HTS TB Screening\",                        # -- Description for HTS TB screning gap\n",
    "    \"HTS Enrolment\",                           # -- Description for HTS enrolment \n",
    "    \"HTS Discordant Couples Test\",             # -- Description for HTS discordant couple testing gap\n",
    "    \"HTS CD4 Test\",                            # -- Description for HTS CD4 test result gap\n",
    "    \"HIVST Mode\",                              # -- Description for HIVST distribution mode gap\n",
    "    \"HIVST Test Freq.\",                        # -- Description for HIVST distribution mode gap\n",
    "    \"HIVST Result\",                            # -- Description for HIVST result gap \n",
    "    \"HIVST Reactive Link\",                     # -- Description for HIVST reactive, confirmation and linkage gap\n",
    "    \"HIVST Prevention Service\",                # -- Description for HIVST prevention service and linkage gap\n",
    "    \"HIVST Partner Screening\",                 # -- Description for HIVST partner screening gap \n",
    "    \"ICT Index Acceptance\",                    # -- Description for ICT index acceptance gap\n",
    "    \"ICT Contact\",                             # -- Description for ICT contact gap\n",
    "    \"ICT HTS\",                                 # -- Description for ICT HTS gap \n",
    "    \"ICT Positive Linkage\",                    # -- Description for ICT poisitive linkage gap\n",
    "    \"PMTCT New ANC HTS\",                       # -- Description for PMTCT new ANC gap\n",
    "    \"PMTCT Positive\",                          # -- Description for PMTCT positive gap\n",
    "    \"PMTCT Previously Known\",                  # -- Description for PMTCT previously known gap \n",
    "    \"PMTCT Positive Linkage\",                  # -- Description for PMTCT positive linkage\n",
    "    \"PMTCT Seroconversion\",                    # -- Description for PMTCT seroconversion gap \n",
    "    \"PMTCT Syphilis Test\",                     # -- Description for PMTCT syphilis test gap \n",
    "    \"PMTCT Hepatitis Test\",                    # -- Description for PMTCT syphilis test gap \n",
    "    \"PMTCT Labour and Delivery\",               # -- Description for PMTCT labour and delivery gap \n",
    "    \"PMTCT Facility HEI ARVs\",                 # -- Description for PMTCT facility HEI ARVs gap \n",
    "    \"PMTCT EID PCR Test\"                       # -- Description for PMTCT EID PCR test gap  \n",
    "]\n",
    "\n",
    "# -- Define constants for UI elements\n",
    "ui_title = \"ANSO IHVN DHIS2 MSF Console\"       # -- Report title to be displayed in bold\n",
    "author = \"Reuben Edidiong\"                     # -- Author name, kept plain due to terminal italic limitation\n",
    "version = \"msf.vlr v1.0\"                       # -- Version identifier for the report\n",
    "ui_sepperator_line = 150                       # -- Length of separator lines (adjustable; 80 for cleaner look)\n",
    "bold = \"\\033[1m\"                               # -- ANSI code for bold text\n",
    "reset = \"\\033[0m\"                              # -- ANSI code to reset formatting\n",
    "\n",
    "# -- Core components for separators\n",
    "header = f\"{bold}{ui_title}{reset} {f'© {author} {version}':>122}\"  # -- Header with bold title, right-aligned copyright\n",
    "top_line = f\"{'-' * ui_sepperator_line}\\n\"       # -- Top separator line\n",
    "bottom_line = f\"\\n{'-' * ui_sepperator_line}\"  # -- Bottom separator line\n",
    "spacing = \"\\n\" * 15                            # -- Empty line gap in ui_separator_clear\n",
    "\n",
    "# -- Separator definitions\n",
    "ui_separator_top = f\"{header}\\n{top_line}\"     # -- Top separator: header followed by a single line\n",
    "ui_separator_bottom = f\"{bottom_line}\"         # -- Bottom separator: just a single line\n",
    "ui_separator_clear = (                         # -- Full clear separator: header, top line, spacing, bottom line\n",
    "    f\"{header}\\n\"\n",
    "    f\"{top_line}\"\n",
    "    f\"{spacing}\"\n",
    "    f\"{bottom_line}\"\n",
    ")\n",
    "\n",
    "def run_jupyter_mode():\n",
    "    \"\"\"\n",
    "    Runs an interactive Jupyter interface with buttons to execute report processing functions.\n",
    "    Group names are displayed horizontally with a dropdown arrow, bold text, and font size increased by 2 points.\n",
    "    Sub-buttons appear when a group name is clicked.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        None \n",
    "    \"\"\"\n",
    "\n",
    "    # -- Step 1: Create buttons with descriptive labels\n",
    "    botton0 = widgets.Button(description=f\"{function_description_name[0]}\")\n",
    "    botton1 = widgets.Button(description=f\"{function_description_name[1]}\")\n",
    "    botton2 = widgets.Button(description=f\"{function_description_name[2]}\")\n",
    "    botton3 = widgets.Button(description=f\"{function_description_name[3]}\")\n",
    "    botton4 = widgets.Button(description=f\"{function_description_name[4]}\")\n",
    "    botton5 = widgets.Button(description=f\"{function_description_name[5]}\")\n",
    "    botton6 = widgets.Button(description=f\"{function_description_name[6]}\")\n",
    "    botton7 = widgets.Button(description=f\"{function_description_name[7]}\")\n",
    "    botton8 = widgets.Button(description=f\"{function_description_name[8]}\")\n",
    "    botton9 = widgets.Button(description=f\"{function_description_name[9]}\")\n",
    "    botton10 = widgets.Button(description=f\"{function_description_name[10]}\")\n",
    "    botton11 = widgets.Button(description=f\"{function_description_name[11]}\")\n",
    "    botton12 = widgets.Button(description=f\"{function_description_name[12]}\")\n",
    "    botton13 = widgets.Button(description=f\"{function_description_name[13]}\")\n",
    "    botton14 = widgets.Button(description=f\"{function_description_name[14]}\")\n",
    "    botton15 = widgets.Button(description=f\"{function_description_name[15]}\")\n",
    "    botton16 = widgets.Button(description=f\"{function_description_name[16]}\")\n",
    "    botton17 = widgets.Button(description=f\"{function_description_name[17]}\")\n",
    "    botton18 = widgets.Button(description=f\"{function_description_name[18]}\")\n",
    "    botton19 = widgets.Button(description=f\"{function_description_name[19]}\")\n",
    "    botton20 = widgets.Button(description=f\"{function_description_name[20]}\")\n",
    "    botton21 = widgets.Button(description=f\"{function_description_name[21]}\")\n",
    "    botton22 = widgets.Button(description=f\"{function_description_name[22]}\")\n",
    "    botton23 = widgets.Button(description=f\"{function_description_name[23]}\")\n",
    "    botton24 = widgets.Button(description=f\"{function_description_name[24]}\")\n",
    "    botton25 = widgets.Button(description=f\"{function_description_name[25]}\")\n",
    "    botton26 = widgets.Button(description=f\"{function_description_name[26]}\")\n",
    "    botton27 = widgets.Button(description=f\"{function_description_name[27]}\")\n",
    "    botton28 = widgets.Button(description=f\"{function_description_name[28]}\")\n",
    "    botton29 = widgets.Button(description=f\"{function_description_name[29]}\")\n",
    "    botton30 = widgets.Button(description=f\"{function_description_name[30]}\")\n",
    "    botton31 = widgets.Button(description=f\"{function_description_name[31]}\")\n",
    "    botton32 = widgets.Button(description=f\"{function_description_name[32]}\")\n",
    "    botton33 = widgets.Button(description=f\"{function_description_name[33]}\") \n",
    "    botton34 = widgets.Button(description=f\"{function_description_name[34]}\")\n",
    "    botton35 = widgets.Button(description=f\"{function_description_name[35]}\") \n",
    "    botton36 = widgets.Button(description=f\"{function_description_name[36]}\")\n",
    "    botton37 = widgets.Button(description=f\"{function_description_name[37]}\")\n",
    "    botton38 = widgets.Button(description=f\"{function_description_name[38]}\")\n",
    "    clear_button = widgets.Button(description=\"Clear screen\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # -- Step 2: Define button handlers \n",
    "    def on_botton0_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            fetch_dhis2_data_interactive_jupyter_mode()\n",
    "            print(ui_separator_bottom)\n",
    "            \n",
    "    def on_botton2_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_lga_report_rate_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton3_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_facility_report_rate_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton4_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_HTS_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton5_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton6_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_Positive_Linkage_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton7_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton8_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_PosEnrolment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton9_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_RegimentLine_MMD_DSD_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton10_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton11_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Presumptive_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton12_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Treatment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton13_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_Viral_Load_Suppression_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton14_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_New_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton15_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton16_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_Enrolment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton17_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_Couple_Counselling_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton18_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_CD4_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton19_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Distr_Mode_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton20_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Test_Freq_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton21_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Result_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton22_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Reactive_Link_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton23_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Prevention_Serv_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton24_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Partner_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton25_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Index_Acceptance_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton26_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Contact_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton27_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_HTS_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton28_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Positive_Link_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton29_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_ANC_Optmz_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton30_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton31_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_PK_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton32_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Positive_Linkage_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton33_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Seroconversion_gap(display_output=True)\n",
    "            print(ui_separator_bottom) \n",
    "    \n",
    "    def on_botton34_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Syphilis_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton35_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Hepatitis_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton36_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Labour_Delivery_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton37_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Facility_HEI_ARVs_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton38_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_EID_PCR_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_clear_button_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_clear)\n",
    "\n",
    "    def on_botton1_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_lga_report_rate_gap(display_output=False)\n",
    "            process_facility_report_rate_gap(display_output=False)\n",
    "            process_AGYW_HTS_gap(display_output=False)\n",
    "            process_AGYW_Positive_gap(display_output=False)\n",
    "            process_AGYW_Positive_Linkage_gap(display_output=False)\n",
    "            process_AGYW_TB_Screening_gap(display_output=False)\n",
    "            process_ART_PosEnrolment_gap(display_output=False)\n",
    "            process_ART_RegimentLine_MMD_DSD_gap(display_output=False)\n",
    "            process_ART_TB_Screening_gap(display_output=False)\n",
    "            process_ART_TB_Presumptive_Test_gap(display_output=False)\n",
    "            process_ART_TB_Treatment_gap(display_output=False)\n",
    "            process_ART_Viral_Load_Suppression_gap(display_output=False)\n",
    "            process_HTS_New_Positive_gap(display_output=False)\n",
    "            process_HTS_TB_Screening_gap(display_output=False)\n",
    "            process_HTS_Couple_Counselling_gap(display_output=False)\n",
    "            process_HTS_Enrolment_gap(display_output=False)\n",
    "            process_HTS_CD4_gap(display_output=False)\n",
    "            process_HIVST_Distr_Mode_gap(display_output=False)\n",
    "            process_HIVST_Test_Freq_gap(display_output=False)\n",
    "            process_HIVST_Result_gap(display_output=False)\n",
    "            process_HIVST_Reactive_Link_gap(display_output=False)\n",
    "            process_HIVST_Prevention_Serv_gap(display_output=False)\n",
    "            process_HIVST_Partner_Screening_gap(display_output=False)\n",
    "            process_ICT_Index_Acceptance_gap(display_output=False)\n",
    "            process_ICT_Contact_gap(display_output=False)\n",
    "            process_ICT_HTS_gap(display_output=False)\n",
    "            process_ICT_Positive_Link_gap(display_output=False)\n",
    "            process_PMTCT_ANC_Optmz_gap(display_output=False)\n",
    "            process_PMTCT_Positive_gap(display_output=False) \n",
    "            process_PMTCT_PK_gap(display_output=False)\n",
    "            process_PMTCT_Positive_Linkage_gap(display_output=False)\n",
    "            process_PMTCT_Seroconversion_gap(display_output=False)\n",
    "            process_PMTCT_Syphilis_Test_gap(display_output=False)\n",
    "            process_PMTCT_Hepatitis_Test_gap(display_output=False)\n",
    "            process_PMTCT_Labour_Delivery_gap(display_output=False)\n",
    "            process_PMTCT_Facility_HEI_ARVs_gap(display_output=False)\n",
    "            process_PMTCT_EID_PCR_Test_gap(display_output=False)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    # -- Step 3: Link buttons to their handlers\n",
    "    botton0.on_click(on_botton0_click)\n",
    "    botton1.on_click(on_botton1_click)\n",
    "    botton2.on_click(on_botton2_click)\n",
    "    botton3.on_click(on_botton3_click)\n",
    "    botton4.on_click(on_botton4_click)\n",
    "    botton5.on_click(on_botton5_click)\n",
    "    botton6.on_click(on_botton6_click)\n",
    "    botton7.on_click(on_botton7_click)\n",
    "    botton8.on_click(on_botton8_click)\n",
    "    botton9.on_click(on_botton9_click)\n",
    "    botton10.on_click(on_botton10_click)\n",
    "    botton11.on_click(on_botton11_click)\n",
    "    botton12.on_click(on_botton12_click)\n",
    "    botton13.on_click(on_botton13_click)\n",
    "    botton14.on_click(on_botton14_click)\n",
    "    botton15.on_click(on_botton15_click)\n",
    "    botton16.on_click(on_botton16_click)\n",
    "    botton17.on_click(on_botton17_click)\n",
    "    botton18.on_click(on_botton18_click)\n",
    "    botton19.on_click(on_botton19_click)\n",
    "    botton20.on_click(on_botton20_click)\n",
    "    botton21.on_click(on_botton21_click)\n",
    "    botton22.on_click(on_botton22_click)\n",
    "    botton23.on_click(on_botton23_click)\n",
    "    botton24.on_click(on_botton24_click)\n",
    "    botton25.on_click(on_botton25_click)\n",
    "    botton26.on_click(on_botton26_click)\n",
    "    botton27.on_click(on_botton27_click)\n",
    "    botton28.on_click(on_botton28_click)\n",
    "    botton29.on_click(on_botton29_click)\n",
    "    botton30.on_click(on_botton30_click)\n",
    "    botton31.on_click(on_botton31_click)\n",
    "    botton32.on_click(on_botton32_click)\n",
    "    botton33.on_click(on_botton33_click)\n",
    "    botton34.on_click(on_botton34_click)\n",
    "    botton35.on_click(on_botton35_click)\n",
    "    botton36.on_click(on_botton36_click)\n",
    "    botton37.on_click(on_botton37_click)\n",
    "    botton38.on_click(on_botton38_click)\n",
    "    clear_button.on_click(on_clear_button_click)\n",
    "\n",
    "    # -- Step 4: Create group buttons with dropdown arrow, bold text, and larger font\n",
    "    # -- Define a consistent layout for button width\n",
    "    group_button_layout = widgets.Layout(width='150px')  # You can adjust the width as needed\n",
    "\n",
    "    # -- Define style for button text\n",
    "    group_button_style = {'font_weight': 'bold', 'font_size': '12px'}\n",
    "    \n",
    "    general_button = widgets.Button(\n",
    "        description=\"General Actions ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    report_rate_botton = widgets.Button(\n",
    "        description=\"Report Rates ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    agyw_button = widgets.Button(\n",
    "        description=\"AGYW Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    art_button = widgets.Button(\n",
    "        description=\"ART Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    hts_button = widgets.Button(\n",
    "        description=\"HTS Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    hivst_button = widgets.Button(\n",
    "        description=\"HIVST Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    ict_button = widgets.Button(\n",
    "        description=\"ICT Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    pmtct_button = widgets.Button(\n",
    "        description=\"PMTCT Reports ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "\n",
    "\n",
    "    # -- Define sub-button containers\n",
    "    general_sub_buttons = widgets.HBox([botton0, botton1, clear_button])\n",
    "    report_rate_sub_botton = widgets.HBox([botton2, botton3, clear_button])\n",
    "    agyw_sub_buttons = widgets.HBox([botton4, botton5, botton6, botton7, clear_button])\n",
    "    art_sub_buttons = widgets.HBox([botton8, botton9, botton10, botton11, botton12, botton13, clear_button])\n",
    "    hts_sub_buttons = widgets.HBox([botton14, botton15, botton16, botton17, botton18,  clear_button])\n",
    "    hivst_sub_buttons = widgets.HBox([botton19, botton20, botton21, botton22, botton23, botton24, clear_button])\n",
    "    ict_sub_buttons = widgets.HBox([botton25, botton26, botton27, botton28, clear_button])\n",
    "    pmtct_sub_buttons = widgets.HBox([botton29, botton30, botton31, botton32, botton33, botton34, \n",
    "                                      botton35, botton36, botton37, botton38, clear_button])\n",
    "\n",
    "    # -- Track the currently open group\n",
    "    current_open = [None]\n",
    "    sub_button_area = widgets.VBox([])\n",
    "\n",
    "    # -- Step 5: Define group button handlers to toggle sub-buttons\n",
    "    def update_button_descriptions(closed_button, opened_button):\n",
    "        for btn in [general_button, report_rate_botton, agyw_button, art_button, \n",
    "                    hts_button, hivst_button, ict_button, pmtct_button]:\n",
    "            if btn != opened_button and btn.description.endswith(\"▲\"):\n",
    "                btn.description = btn.description.replace(\"▲\", \"▼\")\n",
    "        if closed_button and closed_button.description.endswith(\"▲\"):\n",
    "            closed_button.description = closed_button.description.replace(\"▲\", \"▼\")\n",
    "        if opened_button and not opened_button.description.endswith(\"▲\"):\n",
    "            opened_button.description = opened_button.description.replace(\"▼\", \"▲\")\n",
    "\n",
    "    def on_general_button_click(b):\n",
    "        if current_open[0] == general_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(general_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [general_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], general_button)\n",
    "            current_open[0] = general_button\n",
    "\n",
    "    def on_report_rate_botton_click(b):\n",
    "        if current_open[0] == report_rate_botton:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(report_rate_botton, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [report_rate_sub_botton]\n",
    "            update_button_descriptions(current_open[0], report_rate_botton)\n",
    "            current_open[0] = report_rate_botton\n",
    "\n",
    "    def on_agyw_button_click(b):\n",
    "        if current_open[0] == agyw_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(agyw_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [agyw_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], agyw_button)\n",
    "            current_open[0] = agyw_button\n",
    "\n",
    "    def on_art_button_click(b):\n",
    "        if current_open[0] == art_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(art_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [art_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], art_button)\n",
    "            current_open[0] = art_button\n",
    "    \n",
    "    def on_hts_button_click(b):\n",
    "        if current_open[0] == hts_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(hts_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [hts_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], hts_button)\n",
    "            current_open[0] = hts_button\n",
    "\n",
    "    def on_hivst_button_click(b):\n",
    "        if current_open[0] == hivst_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(hivst_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [hivst_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], hivst_button)\n",
    "            current_open[0] = hivst_button\n",
    "    \n",
    "    def on_ict_button_click(b):\n",
    "        if current_open[0] == ict_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(ict_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [ict_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], ict_button)\n",
    "            current_open[0] = ict_button\n",
    "    \n",
    "    def on_pmtct_button_click(b):\n",
    "        if current_open[0] == pmtct_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(pmtct_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [pmtct_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], pmtct_button)\n",
    "            current_open[0] = pmtct_button\n",
    "\n",
    "\n",
    "\n",
    "    # -- Step 6: Link group buttons to their handlers\n",
    "    general_button.on_click(on_general_button_click)\n",
    "    report_rate_botton.on_click(on_report_rate_botton_click)\n",
    "    agyw_button.on_click(on_agyw_button_click)\n",
    "    art_button.on_click(on_art_button_click)\n",
    "    hts_button.on_click(on_hts_button_click)\n",
    "    hivst_button.on_click(on_hivst_button_click)\n",
    "    ict_button.on_click(on_ict_button_click)\n",
    "    pmtct_button.on_click(on_pmtct_button_click)\n",
    "    # -- Step 7: Create a horizontal layout for group buttons\n",
    "    group_buttons = widgets.HBox([\n",
    "        general_button,\n",
    "        report_rate_botton,\n",
    "        agyw_button,\n",
    "        art_button,\n",
    "        hts_button,\n",
    "        hivst_button,\n",
    "        ict_button,\n",
    "        pmtct_button\n",
    "    ], layout=widgets.Layout(\n",
    "        align_items=\"flex-start\",\n",
    "        padding=\"10px\"\n",
    "    ))\n",
    "\n",
    "    # -- Step 8: Create the main layout\n",
    "    layout = widgets.VBox([\n",
    "        group_buttons,\n",
    "        sub_button_area,\n",
    "        output\n",
    "\n",
    "    ], layout=widgets.Layout(\n",
    "        align_items=\"flex-start\",\n",
    "        padding=\"10px\"\n",
    "    ))\n",
    "\n",
    "    # -- Step 9: Display the interface\n",
    "    display(layout)\n",
    "\n",
    "# -- Ensure this is the last cell in your notebook\n",
    "run_jupyter_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d88b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
