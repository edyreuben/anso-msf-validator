{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc88fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - IHVN DHIS2 API\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# Purpose: Fetch and process data from the IHVN DHIS2 API, transforming it into structured DataFrames.\n",
    "#          The script handles multiple report types (e.g., Report Rate, ART, PMTCT), maps data element IDs\n",
    "#          to human-readable names or descriptions, and organizes organizational units (OUs) with their\n",
    "#          hierarchies and cluster mappings for Local Government Areas (LGAs) in Anambra, Nigeria.\n",
    "\n",
    "import requests        # Library for making HTTP requests to interact with DHIS2 API endpoints\n",
    "from requests.auth import HTTPBasicAuth  # Module for HTTP Basic Authentication to secure API requests\n",
    "from requests.exceptions import HTTPError, RequestException  # Exceptions to handle HTTP and network errors\n",
    "import pandas as pd    # Library for data manipulation, used to create and process DataFrames\n",
    "import re              # Library for regular expressions, used to parse URL parameters (e.g., data elements)\n",
    "import time            # Library for time-related functions, used for retry delays during API failures\n",
    "import socket          # Library for network operations, used to check internet connectivity\n",
    "import ipywidgets as widgets  # Library for Jupyter interactive widgets, used for real-time progress display\n",
    "from IPython.display import display, clear_output  # Functions for managing output in Jupyter notebooks\n",
    "\n",
    "# Dictionary of named URLs for DHIS2 reports (shortened for brevity)\n",
    "# Keys are report names; values are URL-encoded DHIS2 API endpoints specifying dimensions:\n",
    "# - dx: Data elements (indicators or metrics)\n",
    "# - ou: Organizational units (e.g., facilities, LGAs)\n",
    "# - pe: Periods (e.g., months in YYYYMM format)\n",
    "# URL encoding uses %3A for ':' and %3B for ';'. Parameters like showHierarchy and includeMetadataDetails\n",
    "# ensure metadata (e.g., names, hierarchies) is included in API responses.\n",
    "named_urls = {\n",
    "    \"Report Rate Facility\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=pe%3A202501&dimension=ou%3AKH62ia35VIZ%3Bum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&dimension=dx%3AZ7E9RxXmwxG.REPORTING_RATE%3BVmGwLcfPS2N.REPORTING_RATE%3BYFnIy7lATQL.REPORTING_RATE%3BNkuV7xoThHV.REPORTING_RATE%3BHwfLR3npibF.REPORTING_RATE%3BvN9rk5ChByM.REPORTING_RATE%3BoxUN7AXSF8r.REPORTING_RATE&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false\",\n",
    "    \"Report Rate LGA\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=pe%3A202501&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-lmSTo2yxNsA&dimension=dx%3AZ7E9RxXmwxG.REPORTING_RATE%3BVmGwLcfPS2N.REPORTING_RATE%3BYFnIy7lATQL.REPORTING_RATE%3BNkuV7xoThHV.REPORTING_RATE%3BHwfLR3npibF.REPORTING_RATE%3BvN9rk5ChByM.REPORTING_RATE%3BoxUN7AXSF8r.REPORTING_RATE&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"AGYW MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AQ1KKjeS4seJ%3BzhvcKIWKvEX%3BpgsZWQLbTvw%3BdPefeXOI0MT%3Bb62rwfvBP13%3Bechn4uCHBhF%3BeoSKe92wBYa%3BIYJciZgP6Yt%3BbbSqZH1OAxk%3By5mYZFQbMe6%3BSSa2P2O1keL%3BrtjZkt3ImND%3BDhw4lcmA8i5%3BAMs19im8mm7%3BTNTPcRPC3jV%3BWWaSbjutZof%3BcspEoTIBnOB%3BQ1ntMoY7ZrP%3BjQ51vKvy1SN%3BKj0TobAENyg%3BKRf4sYxv9KG&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"ART MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AEVJnWv5UQ2I%3BaDFx7U0OSNp%3BuTAVBA24Qgg%3BVNvZaoEcS8M%3BdJpKA2CL66w%3BwUlUHsYzh80%3BmaTBR3htwav%3BN4skK4jJVnm%3BcMpe2pMLJed%3BmJ3Af4Qg0wV%3BxFsrvhyu0Wx%3BCVIR5mDSrr0%3BqO3FSAwqg15%3BE8J56tfMIEa%3BBiqkhMdFIwy%3BfVpRSB8jy9Q%3BudXxeZhT8Fd%3BE20mRpvl5jK%3Bgcg9I4dagWN%3BfBJzc5QIP1b%3BgDuNCzc5liq%3BngCJ4UZOCme%3BEtg6BPVX548%3BiTJ2VvKOWHG%3BrJB5XXrF5zx%3BFRMmrIYSRfz%3BPhUxFwPj2US%3BKtMzH6OTxXL%3Bu0W1SpovSd3%3Bxz9C4uZwMuB%3BLqdahCtUzSX%3Bqb3YzC5X9Lo%3BOU60086uSKx%3Bs2d4Hk231P9%3BmnbibCKaDNb%3BlEdQdPdK5KL&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"ART MSF_tb screening\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AaDFx7U0OSNp&dimension=sbKiaUuaHpX%3AmyDWsEb0XMg%3BnsnGDTrtxbw&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"HTS MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AsxXB2RokZrt%3BhxYcq0LyXh6%3Bi3I5wU8vm0U%3BwSLnU5ihgb3%3BVz0ZjXCnFtX%3BK7Bkwdae7X1%3BRBxwgKGZYpv%3BjNodLWC4U4d%3Bq6bey1tg06I%3BAZSZngrMzj6%3BpS0Cjik4WEH%3BBrVqJd9MHSA%3BXKu24OQK64R%3BpgiqhOhD95N%3BYL87jqnIzQA%3BmN5TqnUQRgq%3BEvB0bzvxMq0%3BgWVJbVYOT1A%3Bd8lMQuQpLPe%3BT6f8BA7M9Q0%3BSVpx1fVD3bh%3BpJH2bCApdTe%3BuGUbRjQvCeN%3BE3bZgIIG5qQ%3Bd8pnVkpyGlU%3BDn4PJOJJASf%3BQV3wq0WsLXe%3Bs9ksVidbnRG%3BOFj0H56KbKp%3Bh9SMVFhNbBN%3BrJD9ER08iT4%3BJLOnLNuLOva%3BZztEVzPBwwl%3BX6wyczqYmJN%3Bvhhrj8rTq83%3ByR5JEOs2t7q%3BCnSrjlY5Siw%3BUMPLBlGYjWM%3BiE5kXuUJoMC%3BuMqKjodBP76%3Bu9gp0VFbnHh%3BzJuaAQbUlq8%3BQXNyy0dbIpd%3BomaL0XteWO8%3BKtzvesDYABJ%3BHdTQzlvMtjU%3Bqznyc2H90Ay%3Bdtri8UEwZFV%3BFB1EZfVSmYi%3BXzghRlcLMqB%3BOk6fJzfTk75%3BomujB6405jI%3BenPRkAVrHKi%3BE6wddhqJVIN%3BjWajcYCyiDE%3BLSQuUgoTH7o%3Bilp3JWW1qt5%3BURgQ4d3y8WF%3Bxc40kwzTBVG%3BmCD2Qhbd6CY%3BnQtTVOdEMqV%3BKQAEkHXQe7N%3BxBr9Sgyk4cO%3BlI7YzdC7wEd%3BegRRIwWxnJs%3BPPxR0HhCKQR%3BkmBNFDE8duJ%3BGTUzO3HGLWA%3Bh8HFl5EeHHl%3BuXwAyGT9eqW%3BDahOUj6bRk0%3BT8G2KNNZ4eI%3BD7ygy6yCHFs%3BuSQJcqAEvHg%3BU74jSwLCoA1%3BZheiLjTrqRZ%3BjlFslOk3bkU%3BOxBKckVqp29%3BJWHc7D4J132%3Bq1XlBEcB1PE%3BNb95zNUKf29%3BevlfYhoKrjI%3BU8xSE6OneYl%3BF2JEmiJt3Yl%3BPZWrrb7VyCj%3BXxpFcHK1S89%3BsICfdv3or5G%3Bg5HvgkCKSSU%3Bh7XmbTNyTUi%3BUi7DiLwSgqm%3BHIHQHXPOGKl%3Bl3aXhanFimZ%3BSl6d3hqzq2C%3BpIsmPa1GjFs%3BOwrvPMKq0pQ%3BV7hcDYvuPMY%3BDWb8URoPRym%3BL7l30ySaQDy%3BnYrdLtwDlV0%3BifE9LKaLqUm%3BuMkZMIHVVjV%3BcCLFgRUkIww%3BHUWYU2ruloN%3BoXsckqTpzhN%3Bm4CzDuc50Jn%3BLPyxdv2eBEj%3BZLARI5LYBOL%3BPYL5GdQGPfI%3BmQZ4z94jzak%3BRkwT0w0mPNj%3BEC5iN37lZ61%3BS0QI1IcESjq%3BnR3ZklnEuBy%3BgxZKoTwyLnn%3BIp75Jb7o8Au%3BVPMZR303TWP%3BjqP0tN3v5hJ%3BuoBeVy413Mj%3BPn1GooQL0I4%3BEh4GHGcZV1U%3BJr0gixBBrvT&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"HTS MSF_hivst_approach\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AT8G2KNNZ4eI&dimension=tBdRxXi3Dxr%3AALL_ITEMS&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"HTS MSF_hivst_response_classification\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AU74jSwLCoA1&dimension=srck01HTxTQ%3ADvPd0vf2shT%3Bf1mGCK98z8a%3Brui70AoUB3b&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"NSP MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AxesSKTdzhPF%3BuIx4sChOeMC%3BkJSLUKrBKez%3BJylie7CPg63%3BTV5DhhOgF7s%3BL0X8cbiEfrC%3BoSDqDrfRpb3%3BIQYpNyC6lF2%3BlOVVI8B4Ag6%3BRxQv56EIuWs%3BqyV24hEIgM5%3BObJbRGQ3QPI%3BptgY5CK3GUc%3BC16TIH6Zxju%3BKY2gb90cvTu%3BO3g2Lq9fpUU%3Bkk3hEztWa48%3BxvfqoSSOIOL%3BcLSlAzBug6Y%3BayTk1t8sjFN%3BjY2SLdSlMug%3Bv3sfwf9O1R9%3BxrHzg7SORIt&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"PMTCT MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ABWLsXE490Yw%3BAtzuY8wFIaP%3BmjoPYWLowE6%3BhWkEco9hG0R%3BgybVHn9Y3SQ%3BkNEHSaIxOja%3BSWsoIgeQBKd%3Bym1WjkXu8ol%3BHDVcSJrN68V%3BIY3zDXL1t0b%3BCrv4RYmAJot%3Bn1MZAkrNWlM%3BGDFB54Uuepj%3BPaXizDbvXcE%3BhnqKzrB2hX0%3BZv0Go6hoDxZ%3BZOzgBnzWLOK%3Bbj8jc0HujI2%3BVlhKdJD8Mav%3BqO3KHhkVM38%3BkSHVwcO9iYZ%3BWnEhg2SiMjF%3BFR9ibOgyNKg%3BbyiZy4Xo7Rx%3BvpEeS23uOzB%3BzoSht7Xk3OI%3BUMFtzIDX9nE%3BxkQqd3C5vd8%3BCAO8uuth3q6%3BRATzsmd7JfL%3BDPFGLfkzZTF%3BZZEXn1RzLwL%3BuMATgKm1ZEV%3ByShXhGc00TY%3Bdc0p7yc1jPy%3BJsyAmKQMqK1%3BlIJwQ20CgPE%3BbxeHOqH0s2V%3BOum5ofYWexC%3BadqiOXDSRbU%3BHFq8NihMhgw%3BcibdW4TLOJ5%3BMJHhWCCOy1q%3BPQHBZmMVWE3%3Bw9NSJbXp5Ub%3BCyrYJsUOe7Q%3BER9cFdvluIM%3BUP3mRp6Zr69%3Bgl5kyYu85zX%3BrIY8zpZJxtv%3BaPtwtDwhOeL%3BuQEZL5j8ZHS%3BSpuoRhODIuZ%3Bvu5TP1CuesM%3BeZ4kUaPlQWC%3BSVDAcLT6IKS%3BFLt9JLhBWlK%3Bt9NJ4JhsXVl%3BnOpah0JpIzI%3BDuFJekp1ymh%3BTJ5BREHjZnu%3BWzAmqotjxV7%3BwRRoicp2S4Y%3Bzq6Tvgk5GFl%3BLMrI0jXhjP4%3BTDLVNVgHUvf%3BakVDx9ew0y8%3ByDAbvAlPR69%3Bi6rCuewXarq%3BzKYuhIKhMKM%3BGQ4kUNGMf7i%3Bv2e5LaziiBr%3BsLWmlnDQzgt%3BrKzvhBgkpe5%3BpyUW87YFbY5%3BssvxYtnGXpp%3BlY6wzD8718l%3BeLZuFwiv4rQ%3BDRFLRwv7f8F%3BLgbHzzQILZY%3BWt8jhQxqq9L%3BTdqRbqoS3Uj%3BcfUpkarx8og%3BWbRBSkKaTE8%3BEvZz6jNSRMX%3BYGZr2K5Y0Yq%3BJGj4bfhtzCk%3BkKSgWbeTAL1%3Bo9zPtZI4c9T%3BcmkwuM6ZOaN%3BcGPBuUrZ5Oi%3BN4WysYNBRFk%3Bd0izXgJhn2P%3BxUYwPZH7ulJ%3BykZcKOVoJeH%3Bj3ycCFq6vzR%3BK2lEmtE4xjz%3Bw4jlyeHkVTD%3BDbj5r3zevDF%3BivG6D3HaMKs%3BCOsmPB8utmg%3BuQKHVsCIm4y%3BZYmUM2TtV80%3BYfvO0pN0SVl%3BwbplLMxCVSo%3BEJ31P0DyQaY&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ArJFps9PGgYI%3BpFrm4E6yE0i%3Bwld8ChYjUUS%3Bhnqs8zD2RBz%3BFdogfvZ9Es5%3BUWnjd2hDMpZ%3BmM3TZYEkMaF%3BK93mvkTXpbl%3BtIZvjax5TD5%3BN05zqacXFsD%3BcVHdvMKuwse%3BBFSM6D4KWg4%3ByHBgGkS0dPr%3BEw3ZRxdYY7g%3BihRnS748lOC%3BlIu2vmR2zHU%3BfbxvYGgVsrK%3BTdATue0b5th%3BFBBKTzFqBVR%3BF27CfSgCmSk%3BdecdNlpZy4B%3BRVuw3Ny3ysw%3BhN5ZT3zziqA%3BKngVqiOqAdp%3Bdfznt6rhrYg%3BbxK7Uh32HMK%3BduzVXts1QUh%3BXpDOj1a7ZdC%3BogXBJLCw1Qe%3BAKQTKPoUHt6%3BrClFr1FdYVY%3BdTWbSB6HZg6%3BGZo5a5CwzV7%3BdIElcrfEgSB%3BP8oCCg2mUcG%3BZc7dmnNEQwj%3BmWQsKiSyv7J%3BQVOL72RTOZR%3Bri9iXOK3wxX%3Bpqp8Tyvsdc1%3BNat3LtmEWXD%3BPm78aQ5UVh8%3BWaI8nE16Ab0%3BfHlNG1CMqYX%3BGwxEq7jrcSc%3BiqqfsLcdWiK%3BeF7Yi0cLTXP%3BVnDrAREzUE2%3BSSxprjJB8vd%3BL5pAPbPCrNF%3BPrdKtyHsOE8%3BLNQtCiSCfnC%3Bb3JIlAZUjNJ%3BeK3YlBsHGkB%3BTz9WrAjxVY9%3BMkl91koS5cn%3BdAQlguHfLF8%3BBdgtqOw1P33%3BhZzpfxOQo4b%3BJBoik13RWdP%3BhAVQ3sTq3nJ%3BGKiJWrIeEJu%3BqqFvQly7I9h%3BJtOlLSk4yTF%3BUfMiT3LdXYc%3BdLj7PgakBi5%3BUaOdcjrcI59%3BssQZNWweFrL%3BhHkzZLsAqmI%3BkYAhnVk8fYp%3BkTIGrSkqbrG%3Bl4ZD3aaxH7j%3BWAZm2HXm3xI%3BSECmJH5Lfer%3BKHnHX7Rb29d%3BVE0Z777wXB2%3Bzgqte2mbKxT%3BDbavrmvoWPG%3BJgDiY0dv2RX%3BS8WFXWTFvai%3BBBwzjs2JQ1Z%3BxRJrWUdpAxm%3BYS8QAyBakNp%3BJfPSsLKaeDV%3BkmsvoBtZ4oa%3BOzGjpuSQHV9%3BVmFeyHAUguh%3BUNoJvdMUZHp%3BfeKbAOjRqQT&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_access_type_mhs\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3APrdKtyHsOE8&dimension=p0cjhizcn4a%3AowMnEudwpzU%3BoeF9HvF2R9X&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_access_type_msh_diagnose\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ASSxprjJB8vd&dimension=p0cjhizcn4a%3AowMnEudwpzU%3BoeF9HvF2R9X&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_access_type_msh_support\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3Al4ZD3aaxH7j&dimension=p0cjhizcn4a%3AowMnEudwpzU%3BoeF9HvF2R9X&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_PrEP_eligible_for_pk_at_risk\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AJgDiY0dv2RX&dimension=oDMnfmxGwgK%3AmoMYeaLyS23%3Bpej3KLkwxLD%3BXHJmw3SqFA3%3BhJnA2pWsV1M%3BX5siefU1Ouk%3BTTSbymL6EhP%3Bgw134Hv72Ea%3BBTZ4X4h6Gj1&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_PrEP_received_for_pk_at_risk\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AVE0Z777wXB2&dimension=oDMnfmxGwgK%3AmoMYeaLyS23%3Bpej3KLkwxLD%3BXHJmw3SqFA3%3BhJnA2pWsV1M%3BX5siefU1Ouk%3BTTSbymL6EhP%3Bgw134Hv72Ea%3BBTZ4X4h6Gj1&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_PrEP_returned_with_retesting_negetive_for_pk_at_risk\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3Azgqte2mbKxT&dimension=oDMnfmxGwgK%3AmoMYeaLyS23%3Bpej3KLkwxLD%3BXHJmw3SqFA3%3BhJnA2pWsV1M%3BX5siefU1Ouk%3BTTSbymL6EhP%3Bgw134Hv72Ea%3BBTZ4X4h6Gj1&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_PrEP_returned_with_retesting_positive_for_pk_at_risk\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3ADbavrmvoWPG&dimension=oDMnfmxGwgK%3AmoMYeaLyS23%3Bpej3KLkwxLD%3BXHJmw3SqFA3%3BhJnA2pWsV1M%3BX5siefU1Ouk%3BTTSbymL6EhP%3Bgw134Hv72Ea%3BBTZ4X4h6Gj1&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"KP Prev MSF_PrEP_discountined_for_pk_at_risk\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AKHnHX7Rb29d&dimension=oDMnfmxGwgK%3AmoMYeaLyS23%3Bpej3KLkwxLD%3BXHJmw3SqFA3%3BhJnA2pWsV1M%3BX5siefU1Ouk%3BTTSbymL6EhP%3Bgw134Hv72Ea%3BBTZ4X4h6Gj1&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"PMTCT MSF_sdp\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AN4WysYNBRFk&dimension=brKpOJgkKa0%3AOLcx26MiJia%3BQ9RcEpV6443%3BEGHRBByvqFu&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"PMTCT MSF_sdp_pos\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AykZcKOVoJeH&dimension=brKpOJgkKa0%3AOLcx26MiJia%3BQ9RcEpV6443%3BEGHRBByvqFu&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"PMTCT MSF_sd<72_in-outside\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3Av2e5LaziiBr&dimension=FtBUOVZVrC6%3AE8fr3yVA0mn%3BS0QLh0UvPbm&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\",\n",
    "    \"PMTCT MSF_sd>72_in-outside\": \"https://ihvn.dhistance.com/api/analytics.json?dimension=dx%3AGQ4kUNGMf7i&dimension=FtBUOVZVrC6%3AE8fr3yVA0mn%3BS0QLh0UvPbm&dimension=pe%3A202501%3B202502%3B202503%3B202504&dimension=ou%3Aum5TFmcsSi8%3BLEVEL-UIlRiekzsf6&showHierarchy=true&hierarchyMeta=true&includeMetadataDetails=true&includeNumDen=true&skipRounding=false&completedOnly=false&outputIdScheme=UID\"\n",
    "}   \n",
    "\n",
    "def fetch_and_process_DHIS2_data(username, password, start_period, end_period, named_urls=named_urls):\n",
    "    \"\"\"\n",
    "    Fetch and process DHIS2 data from named URLs with a specified period range, returning a dictionary of processed DataFrames.\n",
    "    Ensures all requested data elements or dimension values appear as columns, even if they have no data. For Report Rate URLs, \n",
    "    uses metadata names for dx columns; for others, maps data element IDs to descriptions with fallback to metadata names or dimension names.\n",
    "    \n",
    "    Args:\n",
    "        username (str): DHIS2 username for authentication\n",
    "        password (str): DHIS2 password for authentication\n",
    "        start_period (str): Start period in YYYYMM format (e.g., '202501')\n",
    "        end_period (str): End period in YYYYMM format (e.g., '202503')\n",
    "        named_urls (dict, optional): Dictionary with names as keys and DHIS2 API URLs as values\n",
    "                                    Defaults to the predefined named_urls dictionary\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with URL names as keys and processed DataFrames as values\n",
    "    \"\"\"\n",
    "    # -- Step 1: Initialize separator and output widget\n",
    "    separator_line = '-' * 43  # Create a line of 43 dashes for formatting console output\n",
    "    success_output = widgets.Output()  # Initialize Jupyter widget to display progress and success messages\n",
    "    display(success_output)  # Display the widget in Jupyter notebook for real-time updates\n",
    "\n",
    "    # -- Step 2: Extract unique data element IDs (dx) from URLs\n",
    "    all_dx_ids = set()  # Initialize empty set to store unique data element IDs\n",
    "    try:  # Handle potential errors during URL parsing\n",
    "        for url in named_urls.values():  # Iterate through all URLs in the dictionary\n",
    "            dx_matches = re.findall(r'dx%3A([^&]+)', url)  # Extract dx (data element) parameters using regex\n",
    "            for match in dx_matches:  # Process each dx parameter found\n",
    "                ids = [id.split('.')[0] for id in match.split('%3B')]  # Split IDs and remove .REPORTING_RATE suffix\n",
    "                all_dx_ids.update(ids)  # Add unique IDs to the set\n",
    "    except Exception as e:  # Catch any parsing errors\n",
    "        print(f\"{separator_line}\\n⦸ Error: Failed to extract data element IDs from URLs: {str(e)}\\n{separator_line}\")\n",
    "        return {}  # Return empty dict if extraction fails\n",
    "\n",
    "    # -- Step 3: Fetch data element descriptions from DHIS2 API\n",
    "    base_url = 'https://ihvn.dhistance.com/api/dataElements'  # Base URL for DHIS2 data elements endpoint\n",
    "    dx_filter = f\"id:in:[{','.join(all_dx_ids)}]\"  # Create filter for specific data element IDs\n",
    "    params = {  # Define query parameters for API request\n",
    "        'fields': 'id,name,description',  # Request ID, name, and description fields\n",
    "        'filter': dx_filter,  # Filter to only include specified data element IDs\n",
    "        'paging': 'false'  # Disable pagination to retrieve all results in one request\n",
    "    }\n",
    "    max_retries = 3  # Maximum number of retry attempts for API requests\n",
    "    retry_delay = 5  # Delay in seconds between retry attempts\n",
    "    dataelement_to_description = {}  # Dictionary to store data element ID-to-description mappings\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):  # Attempt API call up to max_retries times\n",
    "        try:\n",
    "            socket.create_connection((\"8.8.8.8\", 53), timeout=5)  # Test internet connectivity using Google's DNS\n",
    "            response = requests.get(\n",
    "                base_url,\n",
    "                auth=HTTPBasicAuth(username, password),  # Authenticate with provided credentials\n",
    "                params=params,\n",
    "                timeout=30  # Set timeout to 30 seconds\n",
    "            )\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            data_elements = response.json().get('dataElements', [])  # Extract data elements from response\n",
    "            with success_output:  # Update Jupyter widget with success message\n",
    "                print(f\"Fetched {len(data_elements)} data elements.\")\n",
    "            dataelement_to_description = {\n",
    "                de['id']: de.get('description', de['name']) for de in data_elements  # Map IDs to descriptions or names\n",
    "            }\n",
    "            break  # Exit retry loop on success\n",
    "        except HTTPError as e:  # Handle HTTP errors (e.g., 401, 404)\n",
    "            print(f\"\\n⦸ HTTP Error (Attempt {attempt}/{max_retries}): {str(e)}\")\n",
    "            if response.status_code == 401:  # Check for unauthorized access\n",
    "                print(f\"⦸ Error: Invalid DHIS2 login credentials.\")\n",
    "                return {}  # Return empty dict for invalid credentials\n",
    "            if attempt == max_retries:  # Check if max retries reached\n",
    "                print(f\"⦸ Error: Max retries reached. Unable to fetch data elements.\")\n",
    "                return {}  # Return empty dict after max retries\n",
    "            time.sleep(retry_delay)  # Wait before retrying\n",
    "        except (ConnectionError, socket.gaierror) as e:  # Handle network connectivity issues\n",
    "            print(f\"\\n⦸ Network Error (Attempt {attempt}/{max_retries}): Unable to connect. Please check your internet connection.\")\n",
    "            if attempt == max_retries:  # Check if max retries reached\n",
    "                print(f\"⦸ Error: Max retries reached. Please verify your network connection.\")\n",
    "                return {}  # Return empty dict after max retries\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)  # Wait before retrying\n",
    "        except RequestException as e:  # Handle other request-related errors\n",
    "            print(f\"\\n⦸ Request Error (Attempt {attempt}/{max_retries}): Failed to fetch data elements: {str(e)}.\")\n",
    "            if attempt == max_retries:  # Check if max retries reached\n",
    "                print(f\"⦸ Error: Max retries reached. Unable to fetch data elements.\")\n",
    "                return {}  # Return empty dict after max retries\n",
    "            time.sleep(retry_delay)  # Wait before retrying\n",
    "\n",
    "    # -- Step 4: Validate and parse period inputs\n",
    "    try:  # Validate start_period and end_period formats\n",
    "        for period in [start_period, end_period]:  # Check both periods\n",
    "            if not (isinstance(period, str) and len(period) == 6 and period.isdigit() and 1 <= int(period[4:]) <= 12):\n",
    "                raise ValueError(\"Invalid period format. Use YYYYMM (e.g., '202501').\")  # Ensure YYYYMM format and valid month\n",
    "        start_year = int(start_period[:4])  # Extract year from start period\n",
    "        start_month = int(start_period[4:])  # Extract month from start period\n",
    "        end_year = int(end_period[:4])  # Extract year from end period\n",
    "        end_month = int(end_period[4:])  # Extract month from end period\n",
    "    except ValueError as e:  # Handle invalid period format\n",
    "        print(f\"\\n⦸ Error: {str(e)}.\")\n",
    "        return {}  # Return empty dict if period validation fails\n",
    "\n",
    "    # -- Step 5: Print processing start message\n",
    "    with success_output:  # Display processing message in Jupyter widget\n",
    "        print(f\"Data processing...\\n{separator_line}\")\n",
    "\n",
    "    # -- Step 6: Generate list of periods between start and end\n",
    "    periods = []  # Initialize list to store period strings\n",
    "    current_year, current_month = start_year, start_month  # Start from provided year and month\n",
    "    while (current_year < end_year) or (current_year == end_year and current_month <= end_month):  # Loop until end period\n",
    "        periods.append(f\"{current_year}{current_month:02d}\")  # Add period in YYYYMM format\n",
    "        current_month += 1  # Increment month\n",
    "        if current_month > 12:  # If month exceeds 12, reset to 1 and increment year\n",
    "            current_month = 1\n",
    "            current_year += 1\n",
    "\n",
    "    # -- Step 7: Encode periods for URL\n",
    "    period_string = \"%3B\".join(periods)  # Join periods with URL-encoded semicolon (%3B)\n",
    "    period_param = f\"dimension=pe%3A{period_string}\"  # Create period dimension parameter for API URLs\n",
    "\n",
    "    # -- Step 8: Initialize data storage\n",
    "    processed_data = {}  # Dictionary to store processed DataFrames for each URL\n",
    "    success_count = 0  # Counter for successfully processed URLs\n",
    "    total_urls = len(named_urls)  # Total number of URLs to process\n",
    "\n",
    "    # -- Step 9: Define cluster mapping for LGAs\n",
    "    cluster = {\n",
    "        \"an Aguata\": \"Aguata\",  # Map Anambra LGAs to their respective clusters\n",
    "        \"an Anaocha\": \"Aguata\",\n",
    "        \"an Orumba North\": \"Aguata\",\n",
    "        \"an Orumba South\": \"Aguata\",\n",
    "        \"an Awka North\": \"Awka\",\n",
    "        \"an Awka South\": \"Awka\",\n",
    "        \"an Dunukofia\": \"Awka\",\n",
    "        \"an Idemili North\": \"Awka\",\n",
    "        \"an Idemili South\": \"Awka\",\n",
    "        \"an Njikoka\": \"Awka\",\n",
    "        \"an Ekwusigo\": \"Nnewi\",\n",
    "        \"an Ihiala\": \"Nnewi\",\n",
    "        \"an Nnewi North\": \"Nnewi\",\n",
    "        \"an Nnewi South\": \"Nnewi\",\n",
    "        \"an Anambra East\": \"Omambala\",\n",
    "        \"an Anambra West\": \"Omambala\",\n",
    "        \"an Ayamelum\": \"Omambala\",\n",
    "        \"an Oyi\": \"Omambala\",\n",
    "        \"an Ogbaru\": \"Onitsha\",\n",
    "        \"an Onitsha North\": \"Onitsha\",\n",
    "        \"an Onitsha South\": \"Onitsha\"\n",
    "    }  # Maps LGA names to cluster groups for reporting\n",
    "\n",
    "    # -- Step 10: Process each named URL\n",
    "    for url_name, url in named_urls.items():  # Iterate through each named URL\n",
    "        try:\n",
    "            # -- Update URL with new period range\n",
    "            if \"dimension=pe%3A\" in url:  # Check if period dimension exists in URL\n",
    "                start_idx = url.find(\"dimension=pe%3A\")  # Find start of period parameter\n",
    "                end_idx = url.find(\"&\", start_idx) if url.find(\"&\", start_idx) != -1 else len(url)  # Find end of parameter\n",
    "                url = url[:start_idx] + period_param + url[end_idx:]  # Replace period parameter\n",
    "            else:  # If no period dimension, append it\n",
    "                url = url + \"&\" + period_param if \"?\" in url else url + \"?\" + period_param  # Add period parameter\n",
    "\n",
    "            # -- Fetch data from DHIS2 API\n",
    "            response = requests.get(url, auth=HTTPBasicAuth(username, password))  # Make API request with authentication\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            data = response.json()  # Parse JSON response\n",
    "\n",
    "            # -- Extract table structure from response\n",
    "            headers = [header['name'] for header in data.get('headers', [])]  # Extract column headers from response\n",
    "            df = pd.DataFrame(data.get('rows', []), columns=headers)  # Create DataFrame from rows\n",
    "            df = df.rename(columns={'dx': 'dataElement', 'ou': 'orgUnit', 'pe': 'period'})  # Rename columns for consistency\n",
    "\n",
    "            # -- Extract metadata from response\n",
    "            meta = data.get('metaData', {})  # Get metadata dictionary\n",
    "            ou_hierarchy = meta.get('ouHierarchy', {})  # Get organizational unit hierarchy\n",
    "            items = meta.get('items', {}).copy()  # Copy items metadata to avoid modifying original\n",
    "\n",
    "            # -- Extract requested data elements from URL\n",
    "            dx_matches = re.findall(r'dx%3A([^&]+)', url)  # Extract dx parameters using regex\n",
    "            requested_dx_ids = []  # Initialize list for requested data element IDs\n",
    "            if dx_matches:  # If dx parameters found\n",
    "                requested_dx_ids = [id.split('.')[0] for id in dx_matches[0].split('%3B')]  # Clean IDs by removing suffixes\n",
    "\n",
    "            # -- Handle special dimension URLs (e.g., TB screening, HIV self-testing)\n",
    "            dimension_id = None  # Initialize dimension ID for specific URLs\n",
    "            if url_name == 'ART MSF_tb screening':  # Set dimension for TB screening\n",
    "                dimension_id = 'sbKiaUuaHpX'\n",
    "            elif url_name == 'HTS MSF_hivst_approach':  # Set dimension for HIV self-testing approach\n",
    "                dimension_id = 'tBdRxXi3Dxr'\n",
    "            elif url_name in ['PMTCT MSF_sdp', 'PMTCT MSF_sdp_pos']:  # Set dimension for PMTCT service delivery points\n",
    "                dimension_id = 'brKpOJgkKa0'\n",
    "            elif url_name in ['PMTCT MSF_sd<72_in-outside', 'PMTCT MSF_sd>72_in-outside']:  # Set dimension for PMTCT timing\n",
    "                dimension_id = 'FtBUOVZVrC6'\n",
    "            elif url_name == 'HTS MSF_hivst_response_classification':  # Set dimension for HIV self-testing response\n",
    "                dimension_id = 'srck01HTxTQ'\n",
    "            elif url_name in ['KP Prev MSF_access_type_mhs', 'KP Prev MSF_access_type_msh_diagnose', 'KP Prev MSF_access_type_msh_support']:\n",
    "                dimension_id = 'p0cjhizcn4a'\n",
    "            elif url_name in [\n",
    "                'KP Prev MSF_PrEP_eligible_for_pk_at_risk', 'KP Prev MSF_PrEP_received_for_pk_at_risk', 'KP Prev MSF_PrEP_discountined_for_pk_at_risk',\n",
    "                'KP Prev MSF_PrEP_returned_with_retesting_negetive_for_pk_at_risk', 'KP Prev MSF_PrEP_returned_with_retesting_positive_for_pk_at_risk'\n",
    "                ]:\n",
    "                dimension_id = 'oDMnfmxGwgK'\n",
    "            if dimension_id:  # If a special dimension is specified\n",
    "                dimension_values = set(df[dimension_id].unique())  # Get unique dimension values from DataFrame\n",
    "                missing_dimensions = [dv for dv in dimension_values if dv not in items]  # Identify missing dimension metadata\n",
    "                if missing_dimensions:  # If dimensions are missing from metadata\n",
    "                    dimension_url = 'https://ihvn.dhistance.com/api/categoryOptions'  # URL for category options endpoint\n",
    "                    dimension_filter = f\"id:in:[{','.join(missing_dimensions)}]\"  # Filter for missing dimension IDs\n",
    "                    dimension_params = {'fields': 'id,name', 'filter': dimension_filter, 'paging': 'false'}  # Query parameters\n",
    "                    try:\n",
    "                        dimension_response = requests.get(dimension_url, auth=HTTPBasicAuth(username, password), params=dimension_params)\n",
    "                        dimension_response.raise_for_status()  # Raise exception for HTTP errors\n",
    "                        dimensions = dimension_response.json().get('categoryOptions', [])  # Extract category options\n",
    "                        for dim in dimensions:  # Update items with dimension names\n",
    "                            items[dim['id']] = {'name': dim['name']}\n",
    "                    except RequestException as e:  # Handle errors in fetching dimension metadata\n",
    "                        print(f\"⦸ Warning: Failed to fetch dimension names for {url_name}: {str(e)}\")\n",
    "\n",
    "            # -- Create organizational unit mappings\n",
    "            if url_name == \"Report Rate LGA\":  # For LGA-level reports, map org units to themselves\n",
    "                orgunit_to_level = {ou: ou for ou in df['orgUnit'].unique()}\n",
    "            else:  # For other reports, map org units to their parent level in hierarchy\n",
    "                orgunit_to_level = {\n",
    "                    ou: ou_hierarchy.get(ou, '').split('/')[1] if '/' in ou_hierarchy.get(ou, '') else ou\n",
    "                    for ou in df['orgUnit'].unique()\n",
    "                }\n",
    "\n",
    "            # -- Create name mappings for organizational units and data elements\n",
    "            level_to_name = {  # Map organizational unit levels to their names\n",
    "                org_id: items[org_id]['name']\n",
    "                for org_id in set(orgunit_to_level.values()) if org_id in items\n",
    "            }\n",
    "            orgunit_to_name = {  # Map org unit IDs to their names\n",
    "                ou: items[ou]['name']\n",
    "                for ou in df['orgUnit'].unique() if ou in items\n",
    "            }\n",
    "            dataelement_to_name = {  # Map data element IDs to their names from metadata\n",
    "                de: items[de]['name']\n",
    "                for de in requested_dx_ids if de in items\n",
    "            }\n",
    "\n",
    "            # -- Combine mappings: Prefer dataelement_to_description, fall back to dataelement_to_name\n",
    "            combined_dataelement_mapping = {}  # Initialize mapping for data element column names\n",
    "            for de in requested_dx_ids:  # Iterate over requested data elements\n",
    "                if de in dataelement_to_description:  # Prefer description from data elements API\n",
    "                    combined_dataelement_mapping[de] = dataelement_to_description[de]\n",
    "                elif de in dataelement_to_name:  # Fallback to name from metadata\n",
    "                    combined_dataelement_mapping[de] = dataelement_to_name[de]\n",
    "                else:  # If no mapping found, use raw ID\n",
    "                    combined_dataelement_mapping[de] = de\n",
    "\n",
    "            # -- Pivot DataFrame based on URL type\n",
    "            if dimension_id:  # For URLs with special dimensions, pivot on dimension_id\n",
    "                if dimension_id not in df.columns:  # Check if dimension exists in DataFrame\n",
    "                    print(f\"⦸ Warning: Dimension {dimension_id} missing for {url_name}.\")\n",
    "                    continue  # Skip to next URL if dimension is missing\n",
    "                dimension_matches = re.findall(rf'{dimension_id}%3A([^&]+)', url)  # Extract dimension values from URL\n",
    "                requested_dimension_ids = []  # Initialize list for requested dimension IDs\n",
    "                if dimension_matches:  # If dimension values found\n",
    "                    requested_dimension_ids = dimension_matches[0].split('%3B')  # Split into list\n",
    "                pivoted_df = df.pivot(\n",
    "                    index=['period', 'orgUnit'],  # Pivot on period and orgUnit\n",
    "                    columns=dimension_id,  # Use dimension as columns\n",
    "                    values='value'  # Use value column for pivot values\n",
    "                ).reset_index()\n",
    "                for dim_id in requested_dimension_ids:  # Ensure all requested dimension values are columns\n",
    "                    if dim_id not in pivoted_df.columns:\n",
    "                        pivoted_df[dim_id] = 0  # Add missing dimension columns with zero values\n",
    "            else:  # For standard URLs, pivot on dataElement\n",
    "                pivoted_df = df.pivot(\n",
    "                    index=['period', 'orgUnit'],  # Pivot on period and orgUnit\n",
    "                    columns='dataElement',  # Use dataElement as columns\n",
    "                    values='value'  # Use value column for pivot values\n",
    "                ).reset_index()\n",
    "                for dx_id in requested_dx_ids:  # Ensure all requested data elements are columns\n",
    "                    if dx_id not in pivoted_df.columns:\n",
    "                        pivoted_df[dx_id] = 0  # Add missing data element columns with zero values\n",
    "            pivoted_df.columns.name = None  # Remove column name index for cleaner output\n",
    "\n",
    "            # -- Format period column to 'Mon-YY'\n",
    "            pivoted_df['period'] = pd.to_datetime(pivoted_df['period'], format='%Y%m').dt.strftime('%b-%y')  # Convert YYYYMM to Mon-YY\n",
    "\n",
    "            # -- Add organizational hierarchy information\n",
    "            pivoted_df['orgunitlevel'] = pivoted_df['orgUnit'].map(orgunit_to_level)  # Add parent org unit level\n",
    "            pivoted_df['LGA'] = pivoted_df['orgunitlevel'].map(level_to_name)  # Map parent level to LGA name\n",
    "            pivoted_df['Cluster'] = pivoted_df['LGA'].map(cluster)  # Map LGA to cluster\n",
    "            pivoted_df['orgUnit'] = pivoted_df['orgUnit'].map(orgunit_to_name)  # Map orgUnit to facility name\n",
    "\n",
    "            # -- Rename columns for readability\n",
    "            if url_name in ['Report Rate Facility', 'Report Rate LGA']:  # For reporting rate URLs\n",
    "                rename_dict = {\n",
    "                    **{col: dataelement_to_name.get(col, col) for col in pivoted_df.columns if col in dataelement_to_name},  # Use metadata names\n",
    "                    'period': 'ReportPeriod',  # Rename period column\n",
    "                    'orgUnit': 'FacilityName'  # Rename orgUnit column\n",
    "                }\n",
    "            elif dimension_id:  # For URLs with special dimensions\n",
    "                rename_dict = {\n",
    "                    **{col: items.get(col, {}).get('name', col) for col in pivoted_df.columns if col in items},  # Use dimension names\n",
    "                    'period': 'ReportPeriod',  # Rename period column\n",
    "                    'orgUnit': 'FacilityName'  # Rename orgUnit column\n",
    "                }\n",
    "            else:  # For standard URLs\n",
    "                rename_dict = {\n",
    "                    **{col: combined_dataelement_mapping.get(col, col) for col in pivoted_df.columns if col in combined_dataelement_mapping},  # Use combined mappings\n",
    "                    'period': 'ReportPeriod',  # Rename period column\n",
    "                    'orgUnit': 'FacilityName'  # Rename orgUnit column\n",
    "                }\n",
    "            pivoted_df.rename(columns=rename_dict, inplace=True)  # Apply column renaming\n",
    "\n",
    "            # -- Shorten FacilityName for display\n",
    "            pivoted_df['FacilityName'] = pivoted_df['FacilityName'].apply(\n",
    "                lambda x: x[:34] + '...' if isinstance(x, str) and len(x) > 33 else x  # Truncate names longer than 33 characters\n",
    "            )\n",
    "\n",
    "            # -- Handle NaN values based on URL type\n",
    "            if url_name in ['Report Rate Facility', 'Report Rate LGA']:  # For reporting rates\n",
    "                pivoted_df.fillna('', inplace=True)  # Replace NaN with empty strings\n",
    "            else:  # For other data\n",
    "                pivoted_df.fillna(0, inplace=True)  # Replace NaN with zeros\n",
    "\n",
    "            # -- Store processed DataFrame\n",
    "            pivoted_df = pivoted_df.reset_index(drop=True)  # Reset index for clean DataFrame\n",
    "            processed_data[url_name] = pivoted_df  # Store DataFrame in result dictionary\n",
    "            success_count += 1  # Increment success counter\n",
    "\n",
    "            # -- Update success message in Jupyter widget\n",
    "            with success_output:\n",
    "                clear_output(wait=True)  # Clear previous output\n",
    "                print(\n",
    "                    f\"Fetched {len(data_elements)} data elements\\n\"\n",
    "                    f\"Data processing...\\n{separator_line}\\n\"\n",
    "                    f\"Retrieving: {url_name}\\n\"\n",
    "                    f\"Retrieved : {success_count}/{total_urls} data files\"  # Show progress\n",
    "                )\n",
    "\n",
    "        except RequestException as e:  # Handle API request errors\n",
    "            print(f\"\\n⦸ Error: Failed to fetch data for '{url_name}': {str(e)}.\")\n",
    "            continue  # Skip to next URL\n",
    "        except Exception as e:  # Handle unexpected errors\n",
    "            print(f\"\\n⦸ Error: Unexpected issue processing '{url_name}': {str(e)}.\")\n",
    "            continue  # Skip to next URL\n",
    "\n",
    "    # -- Step 11: Display processing summary\n",
    "    report_period_display = (\n",
    "        f\"✔️ Data fetched successfully! ({success_count}/{total_urls})\\n{separator_line}\"  # Summary message\n",
    "    )\n",
    "    if processed_data:  # If at least one DataFrame was processed\n",
    "        print(report_period_display)\n",
    "        with success_output:\n",
    "            clear_output()  # Clear Jupyter widget\n",
    "    else:  # If no data was processed\n",
    "        print(f\"\\n⦸ Failed:\\nReport extracts: (0/{total_urls})\\nInvalid DHIS2 login credentials or no data retrieved.\\n{separator_line}\")\n",
    "        with success_output:\n",
    "            clear_output()  # Clear Jupyter widget\n",
    "\n",
    "    return processed_data  # Return dictionary of processed DataFrames\n",
    "# End of the function ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac2cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - GET DATA\n",
    "# -----------------------------------------------------------------------------------------\n",
    "from datetime import datetime                               # Library for date/time operations, used for period formatting\n",
    "\n",
    "def fetch_dhis2_data_interactive_jupyter_mode():\n",
    "    \"\"\"\n",
    "    Interactive function to collect period inputs with DatePicker (MM-YY display) and fetch/process DHIS2 data using static credentials.\n",
    "    Args:\n",
    "        None\n",
    "    Returns:\n",
    "        dict: DHIS2_data fetched from the DHIS2 server (accessible globally after submission)\n",
    "    \"\"\"\n",
    "    # -- GLOBALS\n",
    "    global DHIS2_data, load_dhis2_config                    # Declare global variables for data and config function\n",
    "\n",
    "    # -- Step 1: Define constants and output widget\n",
    "    separator_line = '-' * 43                              # Define separator line for output formatting\n",
    "    output = widgets.Output()                              # Create output widget for Jupyter UI display\n",
    "\n",
    "    # -- Step 2: Static credentials for DHIS2 login\n",
    "    username = \"Promise_Uzondu\"                            # Set static username for DHIS2 login\n",
    "    password = \"P@ssword118\"                               # Set static password for DHIS2 login\n",
    "\n",
    "    # -- Step 3: Create calendar widgets for period selection\n",
    "    start_period_picker = widgets.DatePicker(              # Create DatePicker for start period\n",
    "        description=\"Start Period:\",                       # Label for start period picker\n",
    "        value=datetime.now().replace(day=1),               # Default to first day of current month\n",
    "        layout={'width': '300px'}                          # Set picker width to 300px\n",
    "    )\n",
    "    end_period_picker = widgets.DatePicker(                # Create DatePicker for end period\n",
    "        description=\"End Period:\",                         # Label for end period picker\n",
    "        value=datetime.now().replace(day=1),               # Default to first day of current month\n",
    "        layout={'width': '300px'}                          # Set picker width to 300px\n",
    "    )\n",
    "    submit_periods = widgets.Button(description=\"Submit\")   # Create submit button for period selection\n",
    "    periods_box = widgets.VBox([                           # Create vertical box for period widgets\n",
    "        start_period_picker,                               # Include start period picker\n",
    "        end_period_picker,                                 # Include end period picker\n",
    "        submit_periods                                     # Include submit button\n",
    "    ])\n",
    "\n",
    "    # -- Step 4: Store collected period inputs\n",
    "    periods = [None, None]                                 # Initialize list to store periods in YYYYMM\n",
    "\n",
    "    # -- Step 5: Define formatting functions for display\n",
    "    def format_credentials(username, password):             # Define function to format credentials\n",
    "        \"\"\"\n",
    "        Format login credentials with masked password.\n",
    "        Args:\n",
    "            username (str): DHIS2 username\n",
    "            password (str): DHIS2 password\n",
    "        Returns:\n",
    "            str: Formatted string with masked password\n",
    "        \"\"\"\n",
    "        username_line = f\"{'Username: ':<{43 - len(username)}}{username}\"  # Format username line\n",
    "        password_line = f\"{'Passkey: ':<{43 - len(password)}}{'*' * len(password)}\"  # Format masked password line\n",
    "        return f\"{username_line}\\n{password_line}\"         # Return formatted credentials string\n",
    "\n",
    "    def format_report_period(start_period, end_period):     # Define function to format periods\n",
    "        \"\"\"\n",
    "        Format report periods in Mon-YYYY format (e.g., Feb-2025).\n",
    "        Args:\n",
    "            start_period (str): Start period in YYYYMM\n",
    "            end_period (str): End period in YYYYMM\n",
    "        Returns:\n",
    "            str: Formatted period string\n",
    "        \"\"\"\n",
    "        start_date = datetime.strptime(start_period, \"%Y%m\")  # Parse start period to datetime\n",
    "        end_date = datetime.strptime(end_period, \"%Y%m\")   # Parse end period to datetime\n",
    "        start_mon_yyyy = start_date.strftime(\"%b-%Y\")      # Format start as Mon-YYYY\n",
    "        end_mon_yyyy = end_date.strftime(\"%b-%Y\")          # Format end as Mon-YYYY\n",
    "        start_period_line = f\"{'Period Start Date: ':<{43 - len(start_mon_yyyy)}}{start_mon_yyyy}\"  # Format start period line\n",
    "        end_period_line = f\"{'Period End Date: ':<{43 - len(end_mon_yyyy)}}{end_mon_yyyy}\"  # Format end period line\n",
    "        return f\"{start_period_line}\\n{end_period_line}\"   # Return formatted period string\n",
    "\n",
    "    def display_information(credentials_display, report_display):  # Define function to display info\n",
    "        \"\"\"\n",
    "        Display formatted credentials and periods.\n",
    "        Args:\n",
    "            credentials_display (str): Formatted credentials string\n",
    "            report_display (str): Formatted period string\n",
    "        \"\"\"\n",
    "        with output:                                       # Use output widget for display\n",
    "            clear_output()                                 # Clear previous output\n",
    "            print(\"IHVN DHIS2 login credentials:\")         # Print credentials header\n",
    "            print(separator_line)                          # Print separator line\n",
    "            print(credentials_display)                     # Print formatted credentials\n",
    "            print(separator_line)                          # Print separator line\n",
    "            print()                                        # Print blank line\n",
    "            print('Selected report periods:')              # Print periods header\n",
    "            print(separator_line)                          # Print separator line\n",
    "            print(report_display)                          # Print formatted periods\n",
    "            print(separator_line)                          # Print separator line\n",
    "            print()                                        # Print blank line\n",
    "\n",
    "    # -- Step 6: Define period submission handler\n",
    "    def on_submit_periods(b):                              # Define handler for submit button\n",
    "        \"\"\"\n",
    "        Handle period submission and fetch data.\n",
    "        Args:\n",
    "            b: Button click event (ignored)\n",
    "        \"\"\"\n",
    "        global DHIS2_data                                  # Access global DHIS2_data\n",
    "        if start_period_picker.value and end_period_picker.value:  # Check if periods are selected\n",
    "            periods[0] = start_period_picker.value.strftime(\"%Y%m\")  # Convert start to YYYYMM\n",
    "            periods[1] = end_period_picker.value.strftime(\"%Y%m\")  # Convert end to YYYYMM\n",
    "        else:                                              # Handle missing period selection\n",
    "            with output:                                   # Use output widget\n",
    "                clear_output()                             # Clear previous output\n",
    "                print(\"Error: Please select both start and end periods.\")  # Print error message\n",
    "                display(periods_box)                       # Redisplay period selection box\n",
    "            return                                         # Exit handler\n",
    "        if int(periods[1]) < int(periods[0]):              # Validate end period not before start\n",
    "            with output:                                   # Use output widget\n",
    "                clear_output()                             # Clear previous output\n",
    "                print(\"Error: End period cannot be before start period.\")  # Print error message\n",
    "                display(periods_box)                       # Redisplay period selection box\n",
    "            return                                         # Exit handler\n",
    "        credentials_display = format_credentials(username, password)  # Format credentials\n",
    "        report_display = format_report_period(periods[0], periods[1])  # Format periods\n",
    "        display_information(credentials_display, report_display)  # Display formatted info\n",
    "        with output:                                       # Use output widget for data fetch\n",
    "            DHIS2_data = fetch_and_process_DHIS2_data(username, password, periods[0], periods[1])  # Fetch DHIS2 data\n",
    "            if \"Report Rate LGA\" in DHIS2_data and \"LGA\" in DHIS2_data[\"Report Rate LGA\"].columns:  # Check for LGA data\n",
    "                available_lgas = sorted(DHIS2_data[\"Report Rate LGA\"][\"LGA\"].dropna().unique())  # Get unique LGAs\n",
    "                lga_filter_widget = widgets.SelectMultiple(options=available_lgas, rows=6)  # Create LGA filter widget\n",
    "                apply_filter_button = widgets.Button(description=\"Apply Filter\")  # Create filter apply button\n",
    "                def on_apply_filter_clicked(b):                # Define handler for filter button\n",
    "                    \"\"\"\n",
    "                    Handle LGA filter application.\n",
    "                    Args:\n",
    "                        b: Button click event (ignored)\n",
    "                    \"\"\"\n",
    "                    selected_lgas = list(lga_filter_widget.value)  # Get selected LGAs\n",
    "                    with output:                               # Use output widget\n",
    "                        if not selected_lgas:                  # If no LGAs selected\n",
    "                            load_dhis2_config()                # Load config for all data\n",
    "                            print(\"✔️ State level data ready\")  # Print success message\n",
    "                        else:                                  # If LGAs selected\n",
    "                            for key, df in DHIS2_data.items():  # Iterate DHIS2_data\n",
    "                                if isinstance(df, pd.DataFrame) and \"LGA\" in df.columns:  # Check for LGA column\n",
    "                                    DHIS2_data[key] = df[df[\"LGA\"].isin(selected_lgas)].copy()  # Filter by LGAs\n",
    "                            load_dhis2_config()                # Load config for filtered data\n",
    "                            print(f\"✔️ LGA level data ready for {selected_lgas}\")  # Print success message\n",
    "                apply_filter_button.on_click(on_apply_filter_clicked)  # Link filter button to handler\n",
    "                print(f\"\\nSelect report level - LGA\")      # Print LGA filter header\n",
    "                print(separator_line)                      # Print separator line\n",
    "                display(widgets.VBox([lga_filter_widget, apply_filter_button]))  # Display LGA filter widgets\n",
    "                print(separator_line)                      # Print separator line\n",
    "\n",
    "    # -- Step 7: Link submit button to handler\n",
    "    submit_periods.on_click(on_submit_periods)             # Link submit button to period handler\n",
    "\n",
    "    # -- Step 8: Display the initial interface\n",
    "    with output:                                           # Use output widget for initial display\n",
    "        print(\"IHVN DHIS2 login credentials:\")             # Print credentials header\n",
    "        print(separator_line)                              # Print separator line\n",
    "        print(format_credentials(username, password))      # Print formatted credentials\n",
    "        print(separator_line)                              # Print separator line\n",
    "        print()                                            # Print blank line\n",
    "        print('Select report periods:')                    # Print periods header\n",
    "        print(separator_line)                              # Print separator line\n",
    "        display(periods_box)                               # Display period selection box\n",
    "    display(output)                                        # Display output widget\n",
    "# End of the function ---------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### - VARIBLES AND FUNCTIONS - for web\n",
    "import os\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import dataframe_image as dfi\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, Alignment\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "import numpy as np\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import io\n",
    "import gc\n",
    "import os  # For path joining, kept for compatibility with path construction\n",
    "import zipfile                      # Library for creating ZIP archives\n",
    "\n",
    "def load_dhis2_config(base_prefix=\"reports\"):\n",
    "    \"\"\"\n",
    "    Load DHIS2 configuration, functions, and data for reporting, storing files in report_archive for ZIP.\n",
    "    Optimized for low memory usage. Uses a configurable base prefix for path construction.\n",
    "    Args:\n",
    "        base_prefix (str): Base prefix for report_archive keys (default: 'reports').\n",
    "    Returns:\n",
    "        dict: report_archive containing file paths and contents, or None on error.\n",
    "    \"\"\"\n",
    "    separator_line = '-' * 43\n",
    "\n",
    "    try:\n",
    "        # -- Step 1: Declare global variables and functions\n",
    "        global report_name, report_name_rate, report_name_outlier, report_name_period\n",
    "        global report_name_period_name, report_period_name_folder, sub_folder_image_file, sub_folder_doc_file\n",
    "        global sub_folder2_image_file_report_rate, sub_folder2_image_file_msf_outlier\n",
    "        global doc_file_report_rate_xlsx, doc_file_msf_outlier_docx, doc_file_msf_outlier_xlsx\n",
    "        global highlight_red_list, MSF_hierarchy\n",
    "        global outlier_red_report_rate, outlier_green_report_rate, outlier_red, outlier_yellow\n",
    "        global outlier_red_LT0, outlier_yellow_LT0, outlier_red_GT0, outlier_yellow_GT0\n",
    "        global export_df_to_doc_image_excel, filter_gap_and_check_empty_df, prepare_and_convert_df\n",
    "        global wrap_column_headers, wrap_column_headers2, widget_display_df\n",
    "        global Pre_HTS_MSF_positive, Pre_MSF_positives_all\n",
    "        global report_archive\n",
    "\n",
    "        # -- Step 2: Initialize report_archive\n",
    "        report_archive = {}\n",
    "\n",
    "        # -- Step 3: Create report name, dynamic period, and joined report period name\n",
    "        try:\n",
    "            global DHIS2_data\n",
    "            if 'Report Rate Facility' not in DHIS2_data:\n",
    "                raise KeyError(\"Report Rate Facility not found in DHIS2_data\")\n",
    "            report_name = \"anso msf report\"\n",
    "            report_name_rate = \"anso msf report rate\"\n",
    "            report_name_outlier = \"anso msf outlier\"\n",
    "            report_name_period = DHIS2_data[\"Report Rate Facility\"].ReportPeriod.iloc[0]\n",
    "            report_name_period_name = f\"{report_name_period} {report_name}\"\n",
    "        except (KeyError, AttributeError, IndexError) as e:\n",
    "            print(f\"⦸ Error: Failed to access DHIS2_data or ReportPeriod: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # -- Step 4: Define folder structure for report_archive keys\n",
    "        report_period_name_folder = f\"{base_prefix}/{report_name_period_name}\"\n",
    "        sub_folder_image_file = f\"{report_period_name_folder}/image file\"\n",
    "        sub_folder_doc_file = f\"{report_period_name_folder}/document file\"\n",
    "        sub_folder2_image_file_report_rate = f\"{sub_folder_image_file}/{report_name_rate}\"\n",
    "        sub_folder2_image_file_msf_outlier = f\"{sub_folder_image_file}/{report_name_outlier}\"\n",
    "        doc_file_report_rate_xlsx = f\"{sub_folder_doc_file}/{report_name_period} {report_name_rate}.xlsx\"\n",
    "        doc_file_msf_outlier_docx = f\"{sub_folder_doc_file}/{report_name_period_name}.docx\"\n",
    "        doc_file_msf_outlier_xlsx = f\"{sub_folder_doc_file}/{report_name_period_name}.xlsx\"\n",
    "\n",
    "        # -- Step 5: Define highlight_red_list\n",
    "        highlight_red_list = [\n",
    "            'Community', 'Walk-In', 'Community & Walk-In', 'subset of 4',\n",
    "            'Self, Spouse, Sexual Partner, Children, Social Network, Others',\n",
    "            'FSW, MSM, PWID, TG, Others', 'Testing frequency', 'Outreach',\n",
    "            'Outreach-Pregnant', 'Outreach-Others', 'Excluding community testing',\n",
    "            'Excluding previously known', 'IPV', 'ANC', 'L&D', '<72hrs PP',\n",
    "            '<72 hrs', '>72 hrs - < 6 months', '>6 - 12 months',\n",
    "            'ANC, L&D, <72hrs Post Partum', 'Facility', 'Outside Facility',\n",
    "            'Within and outside the facility', 'within 72 hrs of birth',\n",
    "            'between >72 hrs - <2 months of birth', 'All regimens', 'Regimen Lines',\n",
    "            'MMD', 'DSD', 'excludes ART transfer-in', 'ART Addendum-2'\n",
    "        ]\n",
    "\n",
    "        # -- Step 6: Define MSF hierarchy\n",
    "        MSF_hierarchy = ['ReportPeriod', 'Cluster', 'LGA', 'FacilityName']\n",
    "\n",
    "        # -- Step 7: Define wrap_column_headers function\n",
    "        def wrap_column_headers(df, max_width=20):\n",
    "            try:\n",
    "                wrapped_columns = []\n",
    "                for col in df.columns:\n",
    "                    if len(str(col)) > max_width:\n",
    "                        wrapped = '\\n'.join(textwrap.wrap(str(col), max_width, break_long_words=True))\n",
    "                        wrapped_columns.append(wrapped)\n",
    "                    else:\n",
    "                        wrapped_columns.append(col)\n",
    "                df.columns = wrapped_columns\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in wrap_column_headers: {str(e)}\")\n",
    "                return df\n",
    "\n",
    "        # -- Step 8: Define wrap_column_headers2 function\n",
    "        def wrap_column_headers2(columns, max_width=20):\n",
    "            try:\n",
    "                wrapped_columns = []\n",
    "                for col in columns:\n",
    "                    if len(str(col)) > max_width:\n",
    "                        wrapped = '\\n'.join(textwrap.wrap(str(col), max_width, break_long_words=True))\n",
    "                        wrapped_columns.append(wrapped)\n",
    "                    else:\n",
    "                        wrapped_columns.append(col)\n",
    "                return wrapped_columns\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in wrap_column_headers2: {str(e)}\")\n",
    "                return columns\n",
    "\n",
    "        # -- Step 9: Define outlier_red_report_rate function\n",
    "        def outlier_red_report_rate(val):\n",
    "            try:\n",
    "                condition = (\n",
    "                    ((isinstance(val, (int, float)) and val < 100) or\n",
    "                     (isinstance(val, str) and val != '100' and val != '')) or\n",
    "                    (not (isinstance(val, (int, float)) and val < 100) and\n",
    "                     (isinstance(val, (int, float)) and val != 0))\n",
    "                )\n",
    "                if condition:\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_red_report_rate: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 10: Define outlier_green_report_rate function\n",
    "        def outlier_green_report_rate(val):\n",
    "            try:\n",
    "                if (isinstance(val, (int, float)) and val == 100) or (isinstance(val, str) and val == '100' and val != ''):\n",
    "                    return 'background-color: lightgreen; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_green_report_rate: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 11: Define outlier_red function\n",
    "        def outlier_red(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val != 0:\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_red: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 12: Define outlier_yellow function\n",
    "        def outlier_yellow(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val != 0:\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_yellow: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 13: Define outlier_red_LT0 function\n",
    "        def outlier_red_LT0(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val < 0:\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_red_LT0: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 14: Define outlier_yellow_LT0 function\n",
    "        def outlier_yellow_LT0(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val < 0:\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_yellow_LT0: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 15: Define outlier_red_GT0 function\n",
    "        def outlier_red_GT0(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val > 0:\n",
    "                    return 'background-color: lightcoral; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_red_GT0: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 16: Define outlier_yellow_GT0 function\n",
    "        def outlier_yellow_GT0(val):\n",
    "            try:\n",
    "                if isinstance(val, (int, float)) and val > 0:\n",
    "                    return 'background-color: #fff59d; font-weight: normal; border-bottom: 0.01px solid #f3f3f3;'\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in outlier_yellow_GT0: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 17: Define export_df_to_doc_image_excel function\n",
    "        def export_df_to_doc_image_excel(\n",
    "            report_name=None, df_style=None, img_file_name=None, img_file_path=None,\n",
    "            doc_description=None, doc_indicators_to_italicize=None, doc_indicators_to_underline=None,\n",
    "            doc_file_path=doc_file_msf_outlier_docx, xlm_file_path=None, xlm_sheet_name=None,\n",
    "            highlight_red_list=highlight_red_list\n",
    "        ):\n",
    "            try:\n",
    "                image_path = None\n",
    "\n",
    "                # -- Step 17.1: Process image export\n",
    "                if all([df_style is not None, img_file_name is not None, img_file_path is not None]):\n",
    "                    try:\n",
    "                        styled_df = df_style.set_properties(**{'text-align': 'right', 'font-size': '10pt'})\n",
    "                        image_buffer = io.BytesIO()\n",
    "                        dfi.export(styled_df, image_buffer, table_conversion='matplotlib',\n",
    "                                  max_rows=-1, max_cols=-1, fontsize=10, dpi=150)\n",
    "                        image_buffer.seek(0)\n",
    "                        image_path = f\"{img_file_path}/{img_file_name}\"\n",
    "                        report_archive[image_path] = image_buffer.getvalue()\n",
    "                        image_buffer.close()\n",
    "                        del styled_df\n",
    "                        gc.collect()\n",
    "                    except Exception as e:\n",
    "                        print(f\"⦸ Error: Failed to export image for {img_file_name}: {str(e)}\")\n",
    "                        return None\n",
    "\n",
    "                # -- Step 17.2: Process Excel export\n",
    "                if all([df_style is not None, xlm_file_path is not None, xlm_sheet_name is not None]):\n",
    "                    try:\n",
    "                        xlm_sheet_name = xlm_sheet_name[:31]\n",
    "                        excel_buffer = io.BytesIO()\n",
    "                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:\n",
    "                            df_style.to_excel(writer, sheet_name=xlm_sheet_name, index=False)\n",
    "                        excel_buffer.seek(0)\n",
    "                        wb = load_workbook(excel_buffer)\n",
    "                        ws = wb[xlm_sheet_name]\n",
    "                        for cell in ws[1]:\n",
    "                            if cell.value and isinstance(cell.value, str):\n",
    "                                protected_map = {}\n",
    "                                for phrase in highlight_red_list or []:\n",
    "                                    token = f\"@@PROTECT_{abs(hash(phrase))}@@\"\n",
    "                                    protected_map[token] = phrase\n",
    "                                    cell.value = cell.value.replace(phrase, token)\n",
    "                                cell.value = re.sub(r\"<.*?>\", \"\", cell.value)\n",
    "                                for token, phrase in protected_map.items():\n",
    "                                    cell.value = cell.value.replace(token, phrase)\n",
    "                                cell.value = cell.value.strip()\n",
    "                        font_style = Font(name='Calibri', size=8)\n",
    "                        header_font = Font(name='Calibri', size=8, bold=True)\n",
    "                        header_alignment = Alignment(horizontal=\"left\", vertical=\"bottom\", wrap_text=True)\n",
    "                        for row in ws.iter_rows():\n",
    "                            for cell in row:\n",
    "                                cell.font = font_style\n",
    "                        for cell in ws[1]:\n",
    "                            cell.alignment = header_alignment\n",
    "                            cell.font = header_font\n",
    "                        for col in ws.iter_cols(min_col=1, max_col=4):\n",
    "                            max_length = max((len(str(cell.value)) if cell.value else 0) for cell in col)\n",
    "                            ws.column_dimensions[col[0].column_letter].width = max_length\n",
    "                        ws.auto_filter.ref = ws.dimensions\n",
    "                        excel_output_buffer = io.BytesIO()\n",
    "                        wb.save(excel_output_buffer)\n",
    "                        excel_output_buffer.seek(0)\n",
    "                        report_archive[xlm_file_path] = excel_output_buffer.getvalue()\n",
    "                        excel_buffer.close()\n",
    "                        excel_output_buffer.close()\n",
    "                        del wb, ws\n",
    "                        gc.collect()\n",
    "                    except Exception as e:\n",
    "                        print(f\"⦸ Error: Failed to export Excel for {xlm_sheet_name}: {str(e)}\")\n",
    "                        return None\n",
    "\n",
    "                # -- Step 17.3: Create or append to Word document\n",
    "                if all([doc_file_path is not None, image_path is not None, doc_indicators_to_italicize is not None, doc_indicators_to_underline is not None]):\n",
    "                    try:\n",
    "                        doc = Document()\n",
    "                        style = doc.styles['Normal']\n",
    "                        style.font.name = 'Calibri'\n",
    "                        style.font.size = Pt(9.5)\n",
    "                        for section in doc.sections:\n",
    "                            section.left_margin = Inches(0.5)\n",
    "                            section.right_margin = Inches(0.5)\n",
    "                            section.top_margin = Inches(1)\n",
    "                            section.bottom_margin = Inches(1)\n",
    "                        if doc_description:\n",
    "                            title_paragraph = doc.add_heading(report_name, level=2)\n",
    "                            title_run = title_paragraph.runs[0]\n",
    "                            title_run.font.size = Pt(10)\n",
    "                            title_run.font.color.rgb = RGBColor(0, 0, 0)\n",
    "                            paragraph = doc.add_paragraph()\n",
    "                            paragraph.paragraph_format.space_after = Pt(0)\n",
    "                            phrases_to_bold = [\n",
    "                                \"REPORT ONLY 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY HEI ARVs FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY EID SAMPLE COLLECTION FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"REPORT ONLY EID PCR RESULTS FOR 2025 LIVE BIRTHS BY PPW\",\n",
    "                                \"Report Name:\", \"should not be greater than\",\n",
    "                                \"should not be lesser than\", \"should not be equal to\",\n",
    "                                \"should be greater than\", \"should be lesser than\",\n",
    "                                \"should be equal to\", \"plus\", \"Note\", \"OR\"\n",
    "                            ]\n",
    "                            all_phrases = phrases_to_bold + (doc_indicators_to_italicize or []) + (doc_indicators_to_underline or [])\n",
    "                            pattern = r'|'.join(re.escape(phrase) for phrase in all_phrases)\n",
    "                            matches = list(re.finditer(pattern, doc_description))\n",
    "                            last_index = 0\n",
    "                            for match in matches:\n",
    "                                start, end = match.start(), match.end()\n",
    "                                paragraph.add_run(doc_description[last_index:start])\n",
    "                                run = paragraph.add_run(doc_description[start:end])\n",
    "                                if match.group(0) in phrases_to_bold:\n",
    "                                    run.bold = True\n",
    "                                if match.group(0) in doc_indicators_to_italicize:\n",
    "                                    run.italic = True\n",
    "                                if match.group(0) in doc_indicators_to_underline:\n",
    "                                    run.underline = True\n",
    "                                last_index = end\n",
    "                            paragraph.add_run(doc_description[last_index:])\n",
    "                        image_buffer = io.BytesIO(report_archive[image_path])\n",
    "                        doc.add_picture(image_buffer, width=Inches(7))\n",
    "                        image_buffer.close()\n",
    "                        section = doc.sections[-1]\n",
    "                        footer = section.footer.paragraphs[0]\n",
    "                        footer.text = \"This is an auto-generated report. Ensure all data is reviewed before any update is made.\"\n",
    "                        footer.runs[0].font.size = Pt(7.5)\n",
    "                        footer.runs[0].font.color.rgb = RGBColor(100, 100, 100)\n",
    "                        doc_buffer = io.BytesIO()\n",
    "                        doc.save(doc_buffer)\n",
    "                        doc_buffer.seek(0)\n",
    "                        report_archive[doc_file_path] = doc_buffer.getvalue()\n",
    "                        doc_buffer.close()\n",
    "                        del doc\n",
    "                        gc.collect()\n",
    "                    except Exception as e:\n",
    "                        print(f\"⦸ Error: Failed to create Word document at {doc_file_path}: {str(e)}\")\n",
    "                        return None\n",
    "\n",
    "                # -- Step 17.4: Generate and print success messages\n",
    "                if all([report_name, img_file_name, img_file_path, xlm_file_path, xlm_sheet_name]):\n",
    "                    try:\n",
    "                        img_file_path_name = img_file_path\n",
    "                        xlm_file_path_name = xlm_file_path\n",
    "                        image_success_print = rf\"IMG: '{img_file_name}' in {img_file_path_name}\"\n",
    "                        excel_success_print = rf\"XLS: '{xlm_sheet_name}' in {xlm_file_path_name}\"\n",
    "                        messages = [image_success_print, excel_success_print]\n",
    "                        if doc_description:\n",
    "                            doc_file_path_name = doc_file_path\n",
    "                            doc_success_print = rf\"DOC: '{report_name}' in {doc_file_path_name}\"\n",
    "                            messages.append(doc_success_print)\n",
    "                        separator_length = max(len(msg) for msg in messages)\n",
    "                        print(f\"✔️ {report_name}\")\n",
    "                        print('-' * separator_length)\n",
    "                        print('\\n'.join(messages))\n",
    "                        print('-' * separator_length)\n",
    "                    except Exception as e:\n",
    "                        print(f\"⦸ Error: Failed to print success messages: {str(e)}\")\n",
    "                        return image_path if image_path else None\n",
    "\n",
    "                return image_path if image_path else None\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed in export_df_to_doc_image_excel: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 18: Define prepare_and_convert_df function\n",
    "        def prepare_and_convert_df(DHIS2_data_key=None, hierarchy_columns=None, data_columns=None):\n",
    "            try:\n",
    "                if DHIS2_data_key not in DHIS2_data:\n",
    "                    print(f\"⦸ Error: '{DHIS2_data_key}' not found in DHIS2_data\")\n",
    "                    return None\n",
    "                df_raw = DHIS2_data[DHIS2_data_key]\n",
    "                if hierarchy_columns is None:\n",
    "                    hierarchy_columns = []\n",
    "                available_columns = [col for col in data_columns if col in df_raw.columns]\n",
    "                missing_columns = [col for col in data_columns if col not in df_raw.columns]\n",
    "                for col in missing_columns:\n",
    "                    print(f\"⦸ Warning: Column '{col}' not found in '{DHIS2_data_key}'\")\n",
    "                if not available_columns:\n",
    "                    print(f\"⦸ Warning: None of the requested columns found in '{DHIS2_data_key}'. Missing: {missing_columns}\")\n",
    "                df = df_raw[hierarchy_columns + available_columns].copy()\n",
    "                df.sort_values(by=hierarchy_columns, inplace=True, ignore_index=True)\n",
    "                for col in available_columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "                for col in data_columns:\n",
    "                    if col not in df.columns:\n",
    "                        df[col] = 0\n",
    "                df = df[hierarchy_columns + data_columns]\n",
    "                del df_raw\n",
    "                gc.collect()\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed to prepare DataFrame for '{DHIS2_data_key}': {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 19: Define filter_gap_and_check_empty_df function\n",
    "        def filter_gap_and_check_empty_df(\n",
    "            df=None, msg=None, opNonZero=None, opNeg=None, opPos=None,\n",
    "            opNonPos=None, opNonNeg=None, opZero=None, opLT100=None\n",
    "        ):\n",
    "            try:\n",
    "                if df is None or df.empty:\n",
    "                    print(f\"⦸ Error: Input DataFrame is None or empty\")\n",
    "                    return None\n",
    "                if not msg:\n",
    "                    print(f\"⦸ Error: No gap message provided for empty result\")\n",
    "                    return None\n",
    "                operator_map = {\n",
    "                    'opNonZero': lambda x: x != 0,\n",
    "                    'opNeg': lambda x: x < 0,\n",
    "                    'opPos': lambda x: x > 0,\n",
    "                    'opZero': lambda x: x == 0,\n",
    "                    'opLT100': lambda x: x < 100\n",
    "                }\n",
    "                conditions = []\n",
    "                for arg, cols in {\n",
    "                    'opNonZero': opNonZero, 'opNeg': opNeg, 'opPos': opPos,\n",
    "                    'opNonPos': opNonPos, 'opNonNeg': opNonNeg, 'opZero': opZero, 'opLT100': opLT100\n",
    "                }.items():\n",
    "                    if cols:\n",
    "                        for col in cols:\n",
    "                            if col not in df.columns:\n",
    "                                print(f\"⦸ Error: Column '{col}' not found in DataFrame\")\n",
    "                                return None\n",
    "                            numeric_series = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "                            conditions.append(operator_map[arg](numeric_series))\n",
    "                if not conditions:\n",
    "                    print(f\"⦸ Warning: No filtering conditions provided, returning original DataFrame\")\n",
    "                    return df\n",
    "                combined_condition = pd.DataFrame(conditions).T.any(axis=1)\n",
    "                df_filtered = df[combined_condition]\n",
    "                if df_filtered.empty:\n",
    "                    print(\"✋🏿Checked:\")\n",
    "                    print(\"-\" * len(msg))\n",
    "                    print(msg)\n",
    "                    print(\"-\" * len(msg))\n",
    "                    return None\n",
    "                return df_filtered\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed to filter DataFrame: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 20: Define widget_display_df function\n",
    "        def widget_display_df(styler, widget=None):\n",
    "            try:\n",
    "                base_styles = [\n",
    "                    {'selector': 'table', 'props': [('background-color', 'white'), ('border-collapse', 'collapse')]},\n",
    "                    {'selector': 'th', 'props': [('background-color', '#f0f0f0'), ('text-align', 'right'), ('padding', '5px')]},\n",
    "                    {'selector': 'td', 'props': [('text-align', 'right'), ('padding', '5px')]},\n",
    "                    {'selector': 'tr:hover', 'props': [('background-color', '#e0f7fa')]},\n",
    "                    {'selector': 'tr:hover td', 'props': [('font-weight', 'bold')]}\n",
    "                ]\n",
    "                gap_col_styles = []\n",
    "                for idx, col in enumerate(styler.columns):\n",
    "                    if \"gap\" in col.lower():\n",
    "                        gap_col_styles.append({'selector': f'th.col{idx}', 'props': [('background-color', '#ffe6e6')]})\n",
    "                table_styles = base_styles + gap_col_styles\n",
    "                styled = styler.set_table_styles(table_styles)\n",
    "                html_output = f\"\"\"\n",
    "                <div style=\"overflow-x: auto; border: 1px solid #ccc; padding: 5px; max-width: 100%;\">\n",
    "                    {styled.to_html()}\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                if widget is None:\n",
    "                    widget = widgets.Output()\n",
    "                elif not isinstance(widget, widgets.Output):\n",
    "                    raise TypeError(\"⦸ Error: 'widget' must be an ipywidgets.Output object.\")\n",
    "                with widget:\n",
    "                    display(HTML(html_output))\n",
    "                display(widget)\n",
    "                return widget\n",
    "            except Exception as e:\n",
    "                print(f\"⦸ Error: Failed to display DataFrame in widget: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "        # -- Step 21: Constants Initialization for Positive Data Processing\n",
    "        HTS_cols = {\n",
    "            \"positive\": [\n",
    "                \"Number of people who tested HIV positive and received results (Inpatient)\",\n",
    "                \"Number of people who tested HIV positive and received results (Outpatient)\",\n",
    "                \"Number of people who tested HIV positive and received results (Standalone)\",\n",
    "                \"Number of people who tested HIV positive and received results  (Community)\"\n",
    "            ],\n",
    "            \"known_positive\": [\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Inpatient)\",\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Outpatient)\",\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Standalone)\",\n",
    "                \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\"\n",
    "            ]\n",
    "        }\n",
    "        AGYW_cols = [\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\"\n",
    "        ]\n",
    "        PMTCT_col = [\"Number of pregnant women tested HIV positive\"]\n",
    "        KP_cols = [\n",
    "            \"HTS-3a Number of MSM that have received an HIV test during the reporting period in KP-specific programs and received HIV Positive results\",\n",
    "            \"HTS-3b Number of TG that have received an HIV test during the reporting period in KP-specific programs and HIV positive results\",\n",
    "            \"HTS-3c Number of sex workers that have received an HIV test during the reporting period in KP-specific programs and received HIV-positive results\",\n",
    "            \"HTS-3d Number of people who inject drugs (PWID) that have received an HIV test during the reporting period in KP-specific programs and received HIV positive results\",\n",
    "            \"HTS-3e Number of other vulnerable populations (OVP) that have received an HIV test during the reporting period and received HIV-positive results\",\n",
    "            \"HTS-3f Number of people in prisons and other closed settings that have received an HIV test during the reporting period and received HIV-positive results\"\n",
    "        ]\n",
    "\n",
    "        # -- Step 22: Prepare and process HTS data\n",
    "        try:\n",
    "            Pre_HTS_MSF_positive = prepare_and_convert_df(\"HTS MSF\", MSF_hierarchy, HTS_cols[\"positive\"] + HTS_cols[\"known_positive\"])\n",
    "            if Pre_HTS_MSF_positive is None:\n",
    "                print(f\"⦸ Error: Failed to prepare HTS MSF data\")\n",
    "                return None\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - positive\"] = Pre_HTS_MSF_positive[HTS_cols[\"positive\"]].sum(axis=1)\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"] = Pre_HTS_MSF_positive[HTS_cols[\"known_positive\"]].sum(axis=1)\n",
    "            Pre_HTS_MSF_positive[\"HTS total tested - new positive (excluding previously known)\"] = np.where(\n",
    "                Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"] > 0,\n",
    "                Pre_HTS_MSF_positive[\"HTS total tested - positive\"] - Pre_HTS_MSF_positive[\"HTS total tested - previously known positive\"],\n",
    "                Pre_HTS_MSF_positive[\"HTS total tested - positive\"]\n",
    "            )\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error: Failed to process HTS MSF data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # -- Step 23: Prepare AGYW data\n",
    "        try:\n",
    "            Pre_AGYW_MSF_positive = prepare_and_convert_df(\"AGYW MSF\", MSF_hierarchy, AGYW_cols)\n",
    "            if Pre_AGYW_MSF_positive is None:\n",
    "                print(f\"⦸ Error: Failed to prepare AGYW MSF data\")\n",
    "                return None\n",
    "            Pre_AGYW_MSF_positive[\"AGYW total tested - new positive\"] = Pre_AGYW_MSF_positive[AGYW_cols].sum(axis=1)\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error: Failed to process AGYW MSF data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # -- Step 24: Prepare PMTCT data\n",
    "        try:\n",
    "            Pre_PMTCT_MSF_positive = prepare_and_convert_df(\"PMTCT MSF\", MSF_hierarchy, PMTCT_col)\n",
    "            if Pre_PMTCT_MSF_positive is None:\n",
    "                print(f\"⦸ Error: Failed to prepare PMTCT MSF data\")\n",
    "                return None\n",
    "            Pre_PMTCT_MSF_positive.rename(columns={PMTCT_col[0]: \"PMTCT total tested - new positive\"}, inplace=True)\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error: Failed to process PMTCT MSF data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # -- Step 25: Prepare KP data\n",
    "        try:\n",
    "            Pre_KP_MSF_positive = prepare_and_convert_df(\"KP Prev MSF\", MSF_hierarchy, KP_cols)\n",
    "            if Pre_KP_MSF_positive is None:\n",
    "                print(f\"⦸ Error: Failed to prepare KP Prev MSF data\")\n",
    "                return None\n",
    "            Pre_KP_MSF_positive[\"KP_Prev total tested - new positive\"] = Pre_KP_MSF_positive[KP_cols].sum(axis=1)\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error: Failed to process KP Prev MSF data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        # -- Step 26: Merge all DataFrames sequentially\n",
    "        try:\n",
    "            base_cols = [\"ReportPeriod\", \"Cluster\", \"LGA\", \"FacilityName\"]\n",
    "            if \"Report Rate Facility\" not in DHIS2_data:\n",
    "                print(f\"⦸ Error: 'Report Rate Facility' not found in DHIS2_data\")\n",
    "                return None\n",
    "            Pre_MSF_positives_all = DHIS2_data[\"Report Rate Facility\"][base_cols].copy()\n",
    "            for df in [\n",
    "                Pre_HTS_MSF_positive[base_cols + [\"HTS total tested - new positive (excluding previously known)\"]],\n",
    "                Pre_AGYW_MSF_positive[base_cols + [\"AGYW total tested - new positive\"]],\n",
    "                Pre_PMTCT_MSF_positive[base_cols + [\"PMTCT total tested - new positive\"]],\n",
    "                Pre_KP_MSF_positive[base_cols + [\"KP_Prev total tested - new positive\"]]\n",
    "            ]:\n",
    "                Pre_MSF_positives_all = Pre_MSF_positives_all.merge(df, on=base_cols, how=\"left\")\n",
    "                gc.collect()\n",
    "            for col in [\n",
    "                \"HTS total tested - new positive (excluding previously known)\",\n",
    "                \"AGYW total tested - new positive\",\n",
    "                \"PMTCT total tested - new positive\",\n",
    "                \"KP_Prev total tested - new positive\"\n",
    "            ]:\n",
    "                Pre_MSF_positives_all[col] = pd.to_numeric(Pre_MSF_positives_all[col], errors='coerce').fillna(0).astype(int)\n",
    "            Pre_MSF_positives_all[\"Total new positive\"] = Pre_MSF_positives_all[[\n",
    "                \"HTS total tested - new positive (excluding previously known)\",\n",
    "                \"AGYW total tested - new positive\",\n",
    "                \"PMTCT total tested - new positive\",\n",
    "                \"KP_Prev total tested - new positive\"\n",
    "            ]].sum(axis=1)\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            print(f\"⦸ Error: Failed to merge DataFrames: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        print(f\"✔️ Configuration, functions, and data loaded successfully\")\n",
    "        return report_archive\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⦸ Error: Failed to load DHIS2 configuration: {str(e)}\")\n",
    "        return None                         # Return archive\n",
    "\n",
    "def create_report_zip(zip_name=\"ANSO MSF Report.zip\"):\n",
    "    \"\"\"\n",
    "    Creates a ZIP archive from report_archive and returns a FileLink for Jupyter\n",
    "    or a BytesIO buffer for web apps.\n",
    "    Args:\n",
    "        zip_name (str): Name of the ZIP file\n",
    "    Returns:\n",
    "        FileLink or io.BytesIO: Download link for Jupyter or buffer for web\n",
    "    \"\"\"\n",
    "    global report_archive                           # Access report_archive\n",
    "    try:                                            # Handle ZIP creation\n",
    "        zip_buffer = io.BytesIO()                   # Create ZIP buffer\n",
    "        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:  # Open ZIP\n",
    "            for file_path, file_content in report_archive.items():  # Iterate archive\n",
    "                zip_file.writestr(file_path, file_content)  # Write to ZIP\n",
    "        zip_buffer.seek(0)                          # Reset buffer\n",
    "\n",
    "        # Save ZIP for FileLink in Jupyter\n",
    "        with open(zip_name, 'wb') as f:             # Write ZIP to disk\n",
    "            f.write(zip_buffer.getvalue())          # Save ZIP content\n",
    "        #print(f\"ZIP file saved as {zip_name}\")      # Confirm save\n",
    "\n",
    "        # Return FileLink for Jupyter\n",
    "        return FileLink(zip_name, result_html_prefix=\"Download \")  # Return link\n",
    "    except Exception as e:                          # Catch ZIP errors\n",
    "        print(f\"Error creating ZIP file: {str(e)}\")  # Print error\n",
    "        return None                                 # Return None on error\n",
    "# End of the function ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a2a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## - MSF REPORTING RATE\n",
    "### - Reporting rate gap for LGAs\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process LGA report rate gap\n",
    "def process_lga_report_rate_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    # -- Function description: Process LGA report rate gap, exporting results as image and Excel files.\n",
    "    # -- Caches the styled DataFrame and its shape for faster display in subsequent calls.\n",
    "    # -- Reprocesses if the DataFrame shape changes.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): # -- If True, displays the styled DataFrame for LGAs with gaps.\n",
    "            # -- Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        MSF_report_rate_columns = [  # -- List of human-readable column names for MSF report rates\n",
    "            'AGYW Monthly Summary Form - Reporting rate',  # Report rate for Adolescent Girls and Young Women\n",
    "            'ART MSF - Reporting rate', # Report rate for Antiretroviral Therapy\n",
    "            'Care & Support MSF - Reporting rate', # Report rate for Care & Support\n",
    "            'HTS Summary Form - Reporting rate', # Report rate for HIV Testing Services\n",
    "            'NSP Summary Form - Reporting rate', # Report rate for Needle and Syringe Program\n",
    "            'PMTCT MSF - Reporting rate', # Report rate for Prevention of Mother-to-Child Transmission\n",
    "            'Prevention Summary Form - Reporting rate' # Report rate for Prevention Summary\n",
    "        ]  # -- Defines columns to process for report rate gaps\n",
    "        msf_naming = [  # -- List of DHIS2 data element IDs corresponding to report rate columns\n",
    "            'Z7E9RxXmwxG.REPORTING_RATE', \n",
    "            'VmGwLcfPS2N.REPORTING_RATE',\n",
    "            'YFnIy7lATQL.REPORTING_RATE',\n",
    "            'NkuV7xoThHV.REPORTING_RATE',\n",
    "            'HwfLR3npibF.REPORTING_RATE',\n",
    "            'vN9rk5ChByM.REPORTING_RATE',\n",
    "            'oxUN7AXSF8r.REPORTING_RATE'\n",
    "        ]  # -- Maps to MSF_report_rate_columns for data retrieval\n",
    "        report_name = \"ANSO MSF Report Rate Gap\"  # -- Name of the report for file naming and display\n",
    "        MSF_report_rate_msg = f\"No {report_name}\"  # -- Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # -- Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # -- Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # -- Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_Report_Rate_LGA = prepare_and_convert_df(  # -- Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='Report Rate LGA',  # -- Specify key to fetch LGA-level report rate data\n",
    "            hierarchy_columns=MSF_hierarchy,  # -- Use predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=msf_naming  # -- Include specified data element IDs for report rates\n",
    "        )  # -- Returns processed DataFrame or None if failed\n",
    "        if df_Report_Rate_LGA is None:  # -- Check if data preparation failed or returned empty\n",
    "            return  # -- Exit function if no valid data is retrieved\n",
    "        \n",
    "        # -- Drop the 'FacilityName' column if it exists\n",
    "        df_Report_Rate_LGA = df_Report_Rate_LGA.drop(columns='FacilityName')  # -- Remove FacilityName as focus is on LGA-level data\n",
    "\n",
    "        df_Report_Rate_LGA = df_Report_Rate_LGA.rename(  # -- Rename columns for readability\n",
    "            columns=dict(zip(msf_naming, MSF_report_rate_columns))  # -- Map DHIS2 IDs to human-readable names\n",
    "        )  # -- Updates DataFrame with descriptive column names\n",
    "        \n",
    "        wrap_column_headers(df_Report_Rate_LGA)  # -- Apply wrapping to column headers (assumed function for formatting)\n",
    "        MSF_report_rate_columns2 = wrap_column_headers2(MSF_report_rate_columns)  # -- Wrap report rate column names for display\n",
    "\n",
    "        # -- Step 3: Set export variables\n",
    "        report_month = df_Report_Rate_LGA['ReportPeriod'].iloc[0]  # -- Extract first report period (e.g., 'Jan-25') for file naming\n",
    "        report_sheet_name = \"All LGAs\"  # -- Define name for Excel sheet\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # -- Create image file name using report month and name\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrame\n",
    "        if display_output:  # -- Check if user requested to display output\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if a cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_lga_report_rate_gap, 'cached_shape', None)  # -- Retrieve cached DataFrame shape\n",
    "                current_shape = df_Report_Rate_LGA.shape  # -- Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # -- If shapes match, use cached version\n",
    "                    display = process_lga_report_rate_gap.cached_style  # -- Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # -- Print display name with separators\n",
    "                    widget_display_df(display)  # -- Display cached styled DataFrame (assumed Jupyter widget function)\n",
    "                    return  # -- Exit function to avoid reprocessing\n",
    "\n",
    "        # -- Step 5: Filter for gaps\n",
    "        df_Report_Rate_LGA_gap = filter_gap_and_check_empty_df(  # -- Filter DataFrame for rows with report rate gaps\n",
    "            df=df_Report_Rate_LGA,  # -- Input DataFrame to filter\n",
    "            msg=MSF_report_rate_msg,  # -- Message to display if no gaps are found\n",
    "            opNonZero=MSF_report_rate_columns2,  # -- Columns to check for non-zero values\n",
    "            opNeg=None,  # -- No negative value filter applied\n",
    "            opPos=None,  # -- No positive value filter applied\n",
    "            opZero=None,  # -- No zero value filter applied\n",
    "            opLT100=MSF_report_rate_columns2  # -- Filter for report rates less than 100\n",
    "        )  # -- Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_Report_Rate_LGA_gap is None:  # -- Check if filtering returned no gaps\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if cache exists\n",
    "                del process_lga_report_rate_gap.cached_style  # -- Clear cached styled DataFrame\n",
    "            if hasattr(process_lga_report_rate_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "                del process_lga_report_rate_gap.cached_shape  # -- Clear cached DataFrame shape\n",
    "            return  # -- Exit function if no gaps found\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_Report_Rate_LGA_style = (  # -- Apply styling to filtered DataFrame\n",
    "            df_Report_Rate_LGA_gap.style  # -- Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # -- Hide row index for cleaner display\n",
    "            .map(outlier_red_report_rate, subset=MSF_report_rate_columns2)  # -- Highlight outliers in red for report rate columns (assumed function)\n",
    "            .map(outlier_green_report_rate)  # -- Apply green outlier styling (assumed function, applied globally)\n",
    "        )  # -- Creates styled DataFrame for display and export\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_lga_report_rate_gap.cached_style = df_Report_Rate_LGA_style  # -- Store styled DataFrame in function attribute\n",
    "        process_lga_report_rate_gap.cached_shape = df_Report_Rate_LGA.shape  # -- Store original DataFrame shape for future checks\n",
    "\n",
    "        # -- Step 8: Export results\n",
    "        if not display_output:  # -- Check if export is required (no display requested)\n",
    "            export_df_to_doc_image_excel(  # -- Export styled DataFrame to image and Excel files\n",
    "                report_name=report_name,  # -- Pass report name for file naming\n",
    "                df_style=df_Report_Rate_LGA_style,  # -- Pass styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # -- Pass image file name\n",
    "                img_file_path=sub_folder2_image_file_report_rate,  # -- Pass path for image file (assumed defined elsewhere)\n",
    "                doc_description=None,  # -- No document description provided\n",
    "                doc_indicators_to_italicize=None,  # -- No indicators to italicize\n",
    "                doc_indicators_to_underline=None,  # -- No indicators to underline\n",
    "                xlm_file_path=doc_file_report_rate_xlsx,  # -- Pass path for Excel file (assumed defined elsewhere)\n",
    "                xlm_sheet_name=report_sheet_name  # -- Pass Excel sheet name\n",
    "            )  # -- Exports results to specified formats\n",
    "\n",
    "        # -- Step 9: Optionally display styled DataFrame\n",
    "        if display_output:  # -- Check if display is requested\n",
    "            print(print_display_name)  # -- Print display header\n",
    "            widget_display_df(df_Report_Rate_LGA_style)  # -- Display styled DataFrame using assumed widget function\n",
    "\n",
    "    except Exception as e:  # -- Catch any unexpected errors during processing\n",
    "        print(f\"⦸ Error processing LGA report rate gap: {str(e)}\")  # -- Print error message\n",
    "        if hasattr(process_lga_report_rate_gap, 'cached_style'):  # -- Check if cache exists\n",
    "            del process_lga_report_rate_gap.cached_style  # -- Clear cached styled DataFrame\n",
    "        if hasattr(process_lga_report_rate_gap, 'cached_shape'):  # -- Check if cached shape exists\n",
    "            del process_lga_report_rate_gap.cached_shape  # -- Clear cached DataFrame shape\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - Reporting rate gap for facilities\n",
    "# ----------------------------------------------------------------------------------------- \n",
    "# Define the main function to process facility report rate gap\n",
    "def process_facility_report_rate_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    # Function description: Process facility report rate gaps for each LGA, exporting results as images and Excel files.\n",
    "    # Caches styled DataFrames for each LGA and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): # If True, displays the styled DataFrame images for each LGA with gaps.\n",
    "            # Defaults to None (will treat as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: Initialize constants\n",
    "        MSF_report_rate_columns = [  # List of human-readable column names for MSF report rates\n",
    "            'AGYW Monthly Summary Form - Reporting rate',  # Report rate for Adolescent Girls and Young Women\n",
    "            'ART MSF - Reporting rate',  # Report rate for Antiretroviral Therapy\n",
    "            'Care & Support MSF - Reporting rate',  # Report rate for Care & Support\n",
    "            'HTS Summary Form - Reporting rate',  # Report rate for HIV Testing Services\n",
    "            'NSP Summary Form - Reporting rate',  # Report rate for Needle and Syringe Program\n",
    "            'PMTCT MSF - Reporting rate',  # Report rate for Prevention of Mother-to-Child Transmission\n",
    "            'Prevention Summary Form - Reporting rate'  # Report rate for Prevention Summary\n",
    "        ]  # Defines columns to process for report rate gaps\n",
    "        msf_naming = [  # List of DHIS2 data element IDs corresponding to report rate columns\n",
    "            'Z7E9RxXmwxG.REPORTING_RATE', \n",
    "            'VmGwLcfPS2N.REPORTING_RATE',\n",
    "            'YFnIy7lATQL.REPORTING_RATE',\n",
    "            'NkuV7xoThHV.REPORTING_RATE',\n",
    "            'HwfLR3npibF.REPORTING_RATE',\n",
    "            'vN9rk5ChByM.REPORTING_RATE',\n",
    "            'oxUN7AXSF8r.REPORTING_RATE'\n",
    "        ]  # Maps to MSF_report_rate_columns for data retrieval\n",
    "\n",
    "        # Step 2: Prepare data\n",
    "        df_Report_Rate_Facility = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"Report Rate Facility\",  # Specify key to fetch facility-level report rate data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Use predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=msf_naming  # Include specified data element IDs for report rates\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_Report_Rate_Facility is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data is retrieved\n",
    "        \n",
    "        df_Report_Rate_Facility = df_Report_Rate_Facility.rename(  # Rename columns for readability\n",
    "            columns=dict(zip(msf_naming, MSF_report_rate_columns))  # Map DHIS2 IDs to human-readable names\n",
    "        )  # Updates DataFrame with descriptive column names\n",
    "        \n",
    "        wrap_column_headers(df_Report_Rate_Facility)  # Apply wrapping to column headers (assumed function for formatting)\n",
    "        MSF_report_rate_columns2 = wrap_column_headers2(MSF_report_rate_columns)  # Wrap report rate column names for display\n",
    "\n",
    "        # Step 3: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if user requested to display output\n",
    "            if hasattr(process_facility_report_rate_gap, 'cached_styles'):  # Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_facility_report_rate_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_Report_Rate_Facility.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # If shapes match, use cached versions\n",
    "                    for lga, style in process_facility_report_rate_gap.cached_styles.items():  # Iterate over cached styles per LGA\n",
    "                        LGA_name = lga.replace(\"an \", \"\").replace(\" \", \"_\")  # Replace 'an' in LGA name with nothing for cleaner display\n",
    "                        report_name = f\"{LGA_name} Facilities Report Rate Gap\"  # Define report name for current LGA\n",
    "                        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length\n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display header\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame for LGA (assumed Jupyter display function)\n",
    "                    return  # Exit function to avoid reprocessing\n",
    "\n",
    "        # Step 4: Initialize cache\n",
    "        if not hasattr(process_facility_report_rate_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_facility_report_rate_gap.cached_styles = {}  # Initialize dictionary to store styled DataFrames per LGA\n",
    "\n",
    "        # Step 5: Identify unique LGAs\n",
    "        lga_list = pd.Series(df_Report_Rate_Facility['LGA'].unique())  # Extract unique LGA names as a pandas Series\n",
    "\n",
    "        # Step 6: Process each LGA for report rate gaps\n",
    "        for current_lga in lga_list:  # Iterate over each unique LGA\n",
    "            # Step 6.1: Filter DataFrame for current LGA\n",
    "            lga_filtered = df_Report_Rate_Facility[df_Report_Rate_Facility['LGA'] == current_lga]  # Filter DataFrame to current LGA\n",
    "\n",
    "            LGA_name = current_lga.replace(\"an \", \"\").replace(\" \", \"_\")  # Replace 'an' in LGA name with nothing for cleaner display\n",
    "            report_name = f\"{LGA_name} Facilities Report Rate Gap\"  # Define report name for current LGA\n",
    "            MSF_report_rate_msg = f\"No {report_name}\"  # Define message for no gaps in current LGA\n",
    "            display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length\n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            # Step 6.2: Apply filtering for gaps\n",
    "            lga_filtered_gap = filter_gap_and_check_empty_df(  # Filter LGA-specific subset for report rate gaps\n",
    "                df=lga_filtered,  # Input LGA-filtered DataFrame\n",
    "                msg=MSF_report_rate_msg,  # Message to display if no gaps are found\n",
    "                opNonZero=MSF_report_rate_columns2,  # Columns to check for non-zero values\n",
    "                opNeg=None,  # No negative value filter applied\n",
    "                opPos=None,  # No positive value filter applied\n",
    "                opZero=None,  # No zero value filter applied\n",
    "                opLT100=MSF_report_rate_columns2  # Filter for report rates less than 100\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if lga_filtered_gap is None:  # Check if no gaps found for this LGA\n",
    "                if current_lga in process_facility_report_rate_gap.cached_styles:  # Check if LGA is in cache\n",
    "                    del process_facility_report_rate_gap.cached_styles[current_lga]  # Remove LGA from cache\n",
    "                continue  # Skip to next LGA\n",
    "\n",
    "            # Step 6.3: Style the DataFrame\n",
    "            lga_filtered_style = (  # Apply styling to filtered LGA DataFrame\n",
    "                lga_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_red_report_rate, subset=MSF_report_rate_columns2)  # Highlight outliers in red for report rate columns (assumed function)\n",
    "                .map(outlier_green_report_rate)  # Apply green outlier styling (assumed function, applied globally)\n",
    "            )  # Creates styled DataFrame for display and export\n",
    "\n",
    "            # Step 6.4: Cache the styled DataFrame for this LGA\n",
    "            process_facility_report_rate_gap.cached_styles[current_lga] = lga_filtered_style  # Store styled DataFrame in cache\n",
    "\n",
    "            # Step 6.5: Define export variables\n",
    "            report_image_name = f\"{LGA_name}.png\"  # Define image file name using LGA name\n",
    "            report_sheet_name = f\"{LGA_name}\"  # Define Excel sheet name using LGA name\n",
    "\n",
    "            # Step 6.6: Export results\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export LGA-specific DataFrame to image and Excel\n",
    "                    report_name=report_name,  # Pass report name for file naming\n",
    "                    df_style=lga_filtered_style,  # Pass styled LGA DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Pass image file name\n",
    "                    img_file_path=sub_folder2_image_file_report_rate,  # Pass path for image file (assumed defined elsewhere)\n",
    "                    doc_description=None,  # No document description provided\n",
    "                    doc_indicators_to_italicize=None,  # No indicators to italicize\n",
    "                    doc_indicators_to_underline=None,  # No indicators to underline\n",
    "                    xlm_file_path=doc_file_report_rate_xlsx,  # Pass path for Excel file (assumed defined elsewhere)\n",
    "                    xlm_sheet_name=report_sheet_name  # Pass Excel sheet name\n",
    "                )  # Exports results to specified formats\n",
    "    \n",
    "            # Step 6.7: Optionally display styled DataFrame\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display header\n",
    "                widget_display_df(lga_filtered_style)  # Display styled DataFrame using assumed widget function \n",
    "                print()   \n",
    "\n",
    "        # Step 7: Cache overall unfiltered DataFrame shape\n",
    "        process_facility_report_rate_gap.cached_shape = df_Report_Rate_Facility.shape  # Store original DataFrame shape for future checks\n",
    "\n",
    "    except Exception as e:  # Catch any unexpected errors during processing\n",
    "        print(f\"⦸ Error processing facility report rate gaps: {str(e)}\")  # Print error message\n",
    "        if hasattr(process_facility_report_rate_gap, 'cached_styles'):  # Check if cache exists\n",
    "            process_facility_report_rate_gap.cached_styles.clear()  # Clear cached styles dictionary\n",
    "        if hasattr(process_facility_report_rate_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "            del process_facility_report_rate_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit function on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## - AGYW MSF\n",
    "### - AGYW HTS gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process AGYW HTS gap\n",
    "def process_AGYW_HTS_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW HTS gap for each LGA, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for LGAs with gaps.\n",
    "            Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_HTS_columns = [  # List of human-readable column names for AGYW HTS metrics in desired order\n",
    "            \"Number of AGYW reached with HIV Prevention Program - defined package of service during the reporting period (Community)\",  # Community-based prevention reach\n",
    "            \"Number of AGYW reached with HIV Prevention Program - defined package of service during the reporting (Walk-In)\",  # Walk-in prevention reach\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Community)\",  # Community-based testing\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Walk-In)\"  # Walk-in testing\n",
    "        ]  # Defines columns to process for HTS gaps\n",
    "        name = \"AGYW HTS Gap\"  # General name for the report\n",
    "        AGYW_HTS_gap_columns = ['AGYW HTS gap']  # Name for the calculated gap column\n",
    "        report_name = f\"{name}3\"  # Report name with suffix for uniqueness\n",
    "        AGYW_HTS_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_HTS = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='AGYW MSF',  # Specify key to fetch AGYW MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Use predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=AGYW_HTS_columns  # Include specified AGYW HTS columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_AGYW_HTS is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data is retrieved\n",
    "\n",
    "        wrap_column_headers(df_AGYW_HTS)  # Apply wrapping to DataFrame column headers (assumed function for formatting)\n",
    "        AGYW_HTS_columns2 = wrap_column_headers2(AGYW_HTS_columns)  # Wrap AGYW HTS column names for display\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if user requested to display output\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_style'):  # Check if a cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_HTS_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_AGYW_HTS.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # If shapes match, use cached version\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    display = process_AGYW_HTS_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed Jupyter widget function)\n",
    "                    return  # Exit function to avoid reprocessing\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Total AGYW reached with HIV Prevention\n",
    "        df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"] = (  # Calculate total reached\n",
    "            df_AGYW_HTS[AGYW_HTS_columns2[0]] + df_AGYW_HTS[AGYW_HTS_columns2[1]]  # Sum Community and Walk-In prevention reach\n",
    "        )  # Adds new column with total prevention reach\n",
    "        # -- Step 4.2: Total AGYW received HIV test & know status\n",
    "        df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] = (  # Calculate total tested\n",
    "            df_AGYW_HTS[AGYW_HTS_columns2[2]] + df_AGYW_HTS[AGYW_HTS_columns2[3]]  # Sum Community and Walk-In testing\n",
    "        )  # Adds new column with total tested and status-known\n",
    "        # -- Step 4.3: AGYW HTS gap\n",
    "        df_AGYW_HTS[AGYW_HTS_gap_columns[0]] = np.where(  # Calculate gap (assumes numpy as np)\n",
    "            df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] > df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"],  # Condition: tested exceeds reached\n",
    "            df_AGYW_HTS[\"Total AGYW received HIV test & know status\"] - df_AGYW_HTS[\"Total AGYW reached with HIV Prevention\"],  # Calculate positive gap\n",
    "            0  # Set to 0 if no gap (tested <= reached)\n",
    "        )  # Adds gap column with calculated values\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_HTS)  # Reapply wrapping to DataFrame headers after adding new columns\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_HTS_gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_AGYW_HTS_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_AGYW_HTS,  # Input DataFrame with calculated gaps\n",
    "            msg=AGYW_HTS_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero values in gap column\n",
    "            opNeg=None,  # No negative value filter applied\n",
    "            opPos=None,  # No positive value filter applied\n",
    "            opZero=None,  # No zero value filter applied\n",
    "            opLT100=None  # No less-than-100 filter applied\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_AGYW_HTS_gap is None:  # Check if filtering returned no gaps\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_style'):  # Check if cache exists\n",
    "                del process_AGYW_HTS_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_AGYW_HTS_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "                del process_AGYW_HTS_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps found\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_AGYW_HTS_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_AGYW_HTS_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight outliers in gap column in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display and export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_AGYW_HTS_gap.cached_style = df_AGYW_HTS_gap_style  # Store styled DataFrame in function attribute\n",
    "        process_AGYW_HTS_gap.cached_shape = df_AGYW_HTS.shape  # Store original DataFrame shape for future checks\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_AGYW_HTS['ReportPeriod'].iloc[0]  # Extract first report period (e.g., 'Jan-25') for file naming\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name using report month and name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined elsewhere)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name using report name\n",
    "\n",
    "        # -- Step 10: Create description for Word document\n",
    "        if (df_AGYW_HTS[AGYW_HTS_gap_columns[0]] != 0).any():  # Check if any non-zero gaps exist\n",
    "            report_description = (  # Define description for Word document\n",
    "                f\"Report Name: {gap_columns_wrap[0]}\"  # Include gap column name\n",
    "                f\"\\n{AGYW_HTS_columns[2]}\\nplus {AGYW_HTS_columns[3]}\"  # Describe testing metrics\n",
    "                f\"\\nshould not be greater than\"  # Explain expected relationship\n",
    "                f\"\\n{AGYW_HTS_columns[0]}\\nplus {AGYW_HTS_columns[1]}\"  # Describe prevention metrics\n",
    "            )  # Creates multi-line description for clarity\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word formats\n",
    "                report_name=report_name,  # Pass report name for file naming\n",
    "                df_style=df_AGYW_HTS_gap_style,  # Pass styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Pass image file name\n",
    "                img_file_path=report_image_path,  # Pass image file path\n",
    "                doc_file_path=doc_file_msf_outlier_docx,  # Pass Word document path (assumed defined elsewhere)\n",
    "                doc_description=report_description,  # Pass Word document description\n",
    "                doc_indicators_to_italicize=AGYW_HTS_columns,  # Italicize AGYW HTS column names in Word doc\n",
    "                doc_indicators_to_underline=AGYW_HTS_gap_columns,  # Underline gap column name in Word doc\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Pass Excel file path (assumed defined elsewhere)\n",
    "                xlm_sheet_name=report_sheet_name  # Pass Excel sheet name\n",
    "            )  # Exports results to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_AGYW_HTS_gap_style)  # Display styled DataFrame using assumed widget function\n",
    "\n",
    "    except Exception as e:  # Catch any unexpected errors during processing\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error message with report name\n",
    "        if hasattr(process_AGYW_HTS_gap, 'cached_style'):  # Check if cache exists\n",
    "            del process_AGYW_HTS_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_AGYW_HTS_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "            del process_AGYW_HTS_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit function on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - AGYW Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process AGYW Positive gap\n",
    "def process_AGYW_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gaps.\n",
    "            Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_Positive_columns = [  # List of human-readable column names for AGYW Positive metrics in desired order\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Community)\",  # Community-based testing\n",
    "            \"Number of AGYW that received an HIV test during the reporting period and know their status (Walk-In)\",  # Walk-in testing\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",  # Community-based positive cases\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\"  # Walk-in positive cases\n",
    "        ]  # Defines columns to process for positive gaps\n",
    "        name = \"AGYW Positive Gap\"  # General name for the report\n",
    "        AGYW_Positive_gap_columns = [\"AGYW tested positive gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}4\"  # Report name with suffix for uniqueness\n",
    "        AGYW_Positive_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_Positive = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='AGYW MSF',  # Specify key to fetch AGYW MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Use predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=AGYW_Positive_columns  # Include specified AGYW Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_AGYW_Positive is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data is retrieved\n",
    "\n",
    "        wrap_column_headers(df_AGYW_Positive)  # Apply wrapping to DataFrame column headers (assumed function for formatting)\n",
    "        AGYW_Positive_columns2 = wrap_column_headers2(AGYW_Positive_columns)  # Wrap AGYW Positive column names for display\n",
    "\n",
    "        # -- Step 3: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if user requested to display output\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # Check if a cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_AGYW_Positive.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # If shapes match, use cached version\n",
    "                    display = process_AGYW_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed Jupyter widget function)\n",
    "                    return  # Exit function to avoid reprocessing\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Total AGYW tested\n",
    "        df_AGYW_Positive[\"Total AGYW tested\"] = (  # Calculate total tested\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[0]] +  # Add Community tested\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[1]]  # Add Walk-In tested\n",
    "        )  # Adds new column with total tested\n",
    "        # -- Step 4.2: Total AGYW tested positive\n",
    "        df_AGYW_Positive[\"Total AGYW tested positive\"] = (  # Calculate total tested positive\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[2]] +  # Add Community positive\n",
    "            df_AGYW_Positive[AGYW_Positive_columns2[3]]  # Add Walk-In positive\n",
    "        )  # Adds new column with total positive cases\n",
    "        # -- Step 4.3: AGYW tested Positive gap\n",
    "        df_AGYW_Positive[AGYW_Positive_gap_columns[0]] = np.where(  # Calculate gap (assumes numpy as np)\n",
    "            df_AGYW_Positive[\"Total AGYW tested positive\"] > df_AGYW_Positive[\"Total AGYW tested\"],  # Condition: positive cases exceed tested\n",
    "            df_AGYW_Positive[\"Total AGYW tested positive\"] - df_AGYW_Positive[\"Total AGYW tested\"],  # Calculate positive gap\n",
    "            0  # Set to 0 if no gap (positive <= tested)\n",
    "        )  # Adds gap column with calculated values\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_Positive)  # Reapply wrapping to DataFrame headers after adding new columns\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_Positive_gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_AGYW_Positive_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_AGYW_Positive,  # Input DataFrame with calculated gaps\n",
    "            msg=AGYW_Positive_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero values in gap column\n",
    "            opNeg=None,  # No negative value filter applied\n",
    "            opPos=None,  # No positive value filter applied\n",
    "            opZero=None,  # No zero value filter applied\n",
    "            opLT100=None  # No less-than-100 filter applied\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        \n",
    "        if df_AGYW_Positive_gap is None:  # Check if filtering returned no gaps\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # Check if cache exists\n",
    "                del process_AGYW_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_AGYW_Positive_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "                del process_AGYW_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps found\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_AGYW_Positive_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_AGYW_Positive_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight outliers in gap column in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display and export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_AGYW_Positive_gap.cached_style = df_AGYW_Positive_gap_style  # Store styled DataFrame in function attribute\n",
    "        process_AGYW_Positive_gap.cached_shape = df_AGYW_Positive.shape  # Store original DataFrame shape for future checks\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_AGYW_Positive_gap['ReportPeriod'].iloc[0]  # Extract first report period from filtered DataFrame (e.g., 'Jan-25')\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name using report month and name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined elsewhere)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name using report name\n",
    "\n",
    "        # -- Step 10: Create description for Word document\n",
    "        if (df_AGYW_Positive_gap[gap_columns_wrap[0]] != 0).any():  # Check if any non-zero gaps exist\n",
    "            report_description = (  # Define description for Word document\n",
    "                f\"Report Name: {gap_columns_wrap[0]}\"  # Include gap column name\n",
    "                f\"\\n{AGYW_Positive_columns[2]}\\nplus {AGYW_Positive_columns[3]}\"  # Describe positive case metrics\n",
    "                f\"\\nshould not be greater than\"  # Explain expected relationship\n",
    "                f\"\\n{AGYW_Positive_columns[0]}\\nplus {AGYW_Positive_columns[1]}\"  # Describe tested metrics\n",
    "            )  # Creates multi-line description for clarity\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word formats\n",
    "                report_name=report_name,  # Pass report name for file naming\n",
    "                df_style=df_AGYW_Positive_gap_style,  # Pass styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Pass image file name\n",
    "                img_file_path=report_image_path,  # Pass image file path\n",
    "                doc_file_path=doc_file_msf_outlier_docx,  # Pass Word document path (assumed defined elsewhere)\n",
    "                doc_description=report_description,  # Pass Word document description\n",
    "                doc_indicators_to_italicize=AGYW_Positive_columns,  # Italicize AGYW Positive column names in Word doc\n",
    "                doc_indicators_to_underline=AGYW_Positive_gap_columns,  # Underline gap column name in Word doc\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Pass Excel file path (assumed defined elsewhere)\n",
    "                xlm_sheet_name=report_sheet_name  # Pass Excel sheet name\n",
    "            )  # Exports results to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_AGYW_Positive_gap_style)  # Display styled DataFrame using assumed widget function\n",
    "\n",
    "    except Exception as e:  # Catch any unexpected errors during processing\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error message with report name\n",
    "        if hasattr(process_AGYW_Positive_gap, 'cached_style'):  # Check if cache exists\n",
    "            del process_AGYW_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_AGYW_Positive_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "            del process_AGYW_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit function on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - AGYW Positive Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process AGYW Positive Linkage gap\n",
    "def process_AGYW_Positive_Linkage_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_Positive_Linkage_columns = [  # List of column names for AGYW Positive Linkage metrics\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Community)\",  # Community-based positive cases\n",
    "            \"Number of AGYW who tested HIV Positive during the reporting period (Walk-In)\",  # Walk-In positive cases\n",
    "            \"Total number of AGYW who tested HIV Positive and are successfully linked to treatment during the reporting period (Community & Walk-In)\",  # Total linked to treatment\n",
    "            \"Linked/Referred for treatment to GF supported site (subset of 4)\",  # Linked to GF-supported sites\n",
    "            \"Linked/Referred for treatment to non-GF supported site (subset of 4)\",  # Linked to non-GF-supported sites\n",
    "            \"Number of AGYW newly started on ART during the reporting period\"  # Newly started on ART\n",
    "        ]  # Defines columns for linkage gap analysis\n",
    "        name = \"AGYW Positive Linkage Gap\"  # Base name for the report\n",
    "        AGYW_Positive_Linkage_gap_columns = [  # Names for calculated gap columns\n",
    "            \"AGYW positive linked to treatment gap\",  # Gap for linkage to treatment\n",
    "            \"AGYW positive linkage to GF/non-GF supported site gap\",  # Gap for GF/non-GF site linkage\n",
    "            \"AGYW newly started on ART gap\"  # Gap for ART initiation\n",
    "        ]  # Defines gap column names\n",
    "        report_name = f\"{name}5\"  # Report name with suffix for uniqueness\n",
    "        AGYW_Positive_Linkage_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_Positive_Linkage = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='AGYW MSF',  # Key to fetch AGYW MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=AGYW_Positive_Linkage_columns  # Include AGYW Positive Linkage columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_AGYW_Positive_Linkage is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_Positive_Linkage)  # Format DataFrame column headers (assumed function)\n",
    "        AGYW_Positive_Linkage_columns2 = wrap_column_headers2(AGYW_Positive_Linkage_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: Total AGYW Tested Positive\n",
    "        df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] = (  # Calculate total tested positive\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[0]] +  # Add Community positive cases\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[1]]  # Add Walk-In positive cases\n",
    "        )  # Adds column for total positive cases\n",
    "        # -- Step 3.2: AGYW positive linked to treatment gap\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[0]] = np.where(  # Calculate linkage gap (requires numpy as np)\n",
    "            df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # Check if total positive differs from linked\n",
    "            df_AGYW_Positive_Linkage[\"Total AGYW Tested Positive\"] - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # Compute gap (positive - linked)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for treatment linkage\n",
    "        # -- Step 3.3: AGYW positive linkage to GF/non-GF supported site gap\n",
    "        total_linked_to_sites = (  # Calculate total linked to GF and non-GF sites\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[3]] +  # Add GF-supported site linkages\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[4]]  # Add non-GF-supported site linkages\n",
    "        )  # Temporary variable for total site linkages\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[1]] = np.where(  # Calculate site linkage gap\n",
    "            total_linked_to_sites != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # Check if site linkages differ from total linked\n",
    "            total_linked_to_sites - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]],  # Compute gap (site linkages - total linked)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for GF/non-GF site linkage\n",
    "        # -- Step 3.4: AGYW newly started on ART gap\n",
    "        df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_gap_columns[2]] = np.where(  # Calculate ART initiation gap\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]] != df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[5]],  # Check if total linked differs from ART started\n",
    "            df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[2]] - df_AGYW_Positive_Linkage[AGYW_Positive_Linkage_columns2[5]],  # Compute gap (linked - ART started)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for ART initiation\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_Positive_Linkage_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_AGYW_Positive_Linkage.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_AGYW_Positive_Linkage_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_Positive_Linkage)  # Reapply header wrapping after adding columns\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_Positive_Linkage_gap_columns)  # Wrap gap column names\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_AGYW_Positive_Linkage_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "            df=df_AGYW_Positive_Linkage,  # Input DataFrame with gaps\n",
    "            msg=AGYW_Positive_Linkage_msg,  # Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_AGYW_Positive_Linkage_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_AGYW_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_AGYW_Positive_Linkage_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_AGYW_Positive_Linkage_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_AGYW_Positive_Linkage_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_AGYW_Positive_Linkage_gap.cached_style = df_AGYW_Positive_Linkage_gap_style  # Store styled DataFrame\n",
    "        process_AGYW_Positive_Linkage_gap.cached_shape = df_AGYW_Positive_Linkage.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_AGYW_Positive_Linkage_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Set Excel sheet name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # List to collect Word document descriptions\n",
    "        # -- Step 10.1: Description for AGYW Positive Linkage gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero linkage gap\n",
    "            report_description.append(  # Add linkage gap description\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[0]}\"  # Gap column name\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[0]}\\nplus {AGYW_Positive_Linkage_columns[1]}\"  # Positive case metrics\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns2[2]}\"  # Expected equality\n",
    "                f\"\\nNote: Where this AGYW linkage gap is true, please ignore the outlier.\"  # Outlier note\n",
    "            )  # Append linkage gap description\n",
    "        # -- Step 10.2: Description for AGYW Positive Linkage to GF/non-GF supported site gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero site linkage gap\n",
    "            report_description.append(  # Add site linkage gap description\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[1]}\"  # Gap column name\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[3]}\\nplus {AGYW_Positive_Linkage_columns[4]}\"  # Site linkage metrics\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns2[2]}\"  # Expected equality\n",
    "            )  # Append site linkage gap description\n",
    "        # -- Step 10.3: Description for AGYW newly started on ART gap\n",
    "        if (df_AGYW_Positive_Linkage_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero ART gap\n",
    "            report_description.append(  # Add ART gap description\n",
    "                f\"Report Name: {AGYW_Positive_Linkage_gap_columns[2]}\"  # Gap column name\n",
    "                f\"\\n{AGYW_Positive_Linkage_columns[5]}\"  # ART initiation metric\n",
    "                f\"\\nshould be equal to {AGYW_Positive_Linkage_columns[2]}\"  # Expected equality\n",
    "            )  # Append ART gap description\n",
    "        # -- Step 10.4: Join all descriptions\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Combine descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_AGYW_Positive_Linkage_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_file_path=doc_file_msf_outlier_docx,  # Word document path (assumed defined)\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=AGYW_Positive_Linkage_columns,  # Italicize linkage columns\n",
    "                doc_indicators_to_underline=AGYW_Positive_Linkage_gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)   # Print display name with separators\n",
    "            widget_display_df(df_AGYW_Positive_Linkage_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_AGYW_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_AGYW_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_AGYW_Positive_Linkage_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - AGYW TB Screening gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process AGYW TB Screening gap\n",
    "def process_AGYW_TB_Screening_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process AGYW TB Screening gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        AGYW_TB_Screening_columns = [  # List of column names for AGYW TB Screening metrics\n",
    "            \"Number of AGYW newly started on ART during the reporting period\",  # AGYW newly started on ART\n",
    "            \"Number of AGYW screened for TB amongst those newly started on ART during the reporting period\"  # AGYW screened for TB\n",
    "        ]  # Defines columns for TB screening gap analysis\n",
    "        name = \"AGYW TB Screening Gap\"  # Base name for the report\n",
    "        AGYW_TB_Screening_gap_columns = [\"AGYW TB screening gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}6\"  # Report name with suffix for uniqueness\n",
    "        AGYW_TB_Screening_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_AGYW_TB_Screening = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='AGYW MSF',  # Key to fetch AGYW MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=AGYW_TB_Screening_columns  # Include AGYW TB Screening columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_AGYW_TB_Screening is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        wrap_column_headers(df_AGYW_TB_Screening)  # Format DataFrame column headers (assumed function)\n",
    "        AGYW_TB_Screening_columns2 = wrap_column_headers2(AGYW_TB_Screening_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: AGYW TB Screening gap\n",
    "        df_AGYW_TB_Screening[AGYW_TB_Screening_gap_columns[0]] = np.where(  # Calculate TB screening gap (requires numpy as np)\n",
    "            df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[1]] != df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[0]],  # Check if screened differs from started on ART\n",
    "            df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[1]] - df_AGYW_TB_Screening[AGYW_TB_Screening_columns2[0]],  # Compute gap (screened - started)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for TB screening\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_AGYW_TB_Screening_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_AGYW_TB_Screening.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_AGYW_TB_Screening_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_AGYW_TB_Screening)  # Reapply header wrapping after adding gap column\n",
    "        gap_columns_wrap = wrap_column_headers2(AGYW_TB_Screening_gap_columns)  # Wrap gap column name\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_AGYW_TB_Screening_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "            df=df_AGYW_TB_Screening,  # Input DataFrame with gap\n",
    "            msg=AGYW_TB_Screening_msg,  # Message if no gaps found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_AGYW_TB_Screening_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_AGYW_TB_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_AGYW_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_AGYW_TB_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_AGYW_TB_Screening_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_AGYW_TB_Screening_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_AGYW_TB_Screening_gap.cached_style = df_AGYW_TB_Screening_gap_style  # Store styled DataFrame\n",
    "        process_AGYW_TB_Screening_gap.cached_shape = df_AGYW_TB_Screening.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_AGYW_TB_Screening_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Set Excel sheet name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        # -- Step 10.1: Add description for AGYW TB Screening gap\n",
    "        if (df_AGYW_TB_Screening_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero TB screening gap\n",
    "            report_description = (  # Create description for TB screening gap\n",
    "                f\"Report Name: {AGYW_TB_Screening_gap_columns[0]}\"  # Gap column name\n",
    "                f\"\\n{AGYW_TB_Screening_columns[1]}\\nshould be equal to {AGYW_TB_Screening_columns[0]}\"  # Expected equality\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_AGYW_TB_Screening_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_file_path=doc_file_msf_outlier_docx,  # Word document path (assumed defined)\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=AGYW_TB_Screening_columns,  # Italicize TB screening columns\n",
    "                doc_indicators_to_underline=AGYW_TB_Screening_gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_AGYW_TB_Screening_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_AGYW_TB_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_AGYW_TB_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_AGYW_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_AGYW_TB_Screening_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## - ART MSF\n",
    "### - ART Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART positive and enrollment gap\n",
    "def process_ART_PosEnrolment_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART Positive and Enrolment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_PosEnrolment_columns = [  # List of column names for ART positive and enrollment metrics\n",
    "            \"ART 1: Number of HIV positive persons newly enrolled in clinical care during the month\",  # Newly enrolled in care\n",
    "            \"ART 2: Number of people living with HIV newly started on ART during the month (excludes ART transfer-in)\"  # Newly started on ART\n",
    "        ]  # Defines columns for ART gap analysis\n",
    "        ART_PosEnrolment_columns_desrpt = ART_PosEnrolment_columns + [\"Total Tested Positive\"]  # Extended list including total positive for descriptions\n",
    "        name = \"ART Positive-Enrolment Gap\"  # Base name for the report\n",
    "        ART_PosEnrolment_gap_columns = [\"ART enrolment gap\", \"ART linkage gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}7\"  # Report name with suffix for uniqueness\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_PosEnrolment = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key='ART MSF',  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_PosEnrolment_columns  # Include ART positive and enrollment columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "\n",
    "        # -- Step 3: Merge with external DataFrame\n",
    "        df_ART_PosEnrolment = Pre_MSF_positives_all.merge(  # Merge with external positives data (assumed defined elsewhere)\n",
    "            df_ART_PosEnrolment,  # Target DataFrame for merging\n",
    "            on=MSF_hierarchy,  # Columns to merge on\n",
    "            how=\"left\"  # Keep all rows from df_ART_PosEnrolment\n",
    "        )  # Merges to include total positive data\n",
    "        df_ART_PosEnrolment = df_ART_PosEnrolment.fillna(0)  # Fill NaN values with 0\n",
    "        float_columns = df_ART_PosEnrolment.select_dtypes(include=['float64', 'float32']).columns  # Identify float-type columns\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_ART_PosEnrolment[col] = df_ART_PosEnrolment[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        wrap_column_headers(df_ART_PosEnrolment)  # Format DataFrame column headers (assumed function)\n",
    "        ART_PosEnrolment_columns2 = wrap_column_headers2(ART_PosEnrolment_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: ART enrolment gap\n",
    "        df_ART_PosEnrolment[ART_PosEnrolment_gap_columns[0]] = np.where(  # Calculate enrolment gap (requires numpy as np)\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]] != df_ART_PosEnrolment[\"Total new positive\"],  # Check if enrolled differs from total positive\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]] - df_ART_PosEnrolment[\"Total new positive\"],  # Compute gap (enrolled - total positive)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for enrolment\n",
    "        # -- Step 4.2: ART linkage gap\n",
    "        df_ART_PosEnrolment[ART_PosEnrolment_gap_columns[1]] = np.where(  # Calculate linkage gap\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[1]] != df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]],  # Check if started on ART differs from enrolled\n",
    "            df_ART_PosEnrolment[ART_PosEnrolment_columns2[1]] - df_ART_PosEnrolment[ART_PosEnrolment_columns2[0]],  # Compute gap (started - enrolled)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for linkage\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # Check if cached styles exist\n",
    "                cached_shape = getattr(process_ART_PosEnrolment_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_PosEnrolment.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_ART_PosEnrolment_gap.cached_styles.items():  # Iterate over cached styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display styled DataFrame (assumed widget function)tyle)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Initialize cache\n",
    "        if not hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_ART_PosEnrolment_gap.cached_styles = {}  # Initialize empty dictionary for cached styles\n",
    "\n",
    "        # -- Step 7: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_ART_PosEnrolment['Cluster'].unique())  # Extract unique cluster values (requires pandas as pd)\n",
    "\n",
    "        # -- Step 8: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_ART_PosEnrolment[df_ART_PosEnrolment['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            ART_PosEnrolment_msg = f\"No {current_cluster} {report_name}\"  # Define message for no gaps in cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "                df=cluster_filtered,  # Input cluster-filtered DataFrame\n",
    "                msg=ART_PosEnrolment_msg,  # Message if no gaps found\n",
    "                opNonZero=ART_PosEnrolment_gap_columns,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found for cluster\n",
    "                if current_cluster in process_ART_PosEnrolment_gap.cached_styles:  # Check if cluster in cache\n",
    "                    del process_ART_PosEnrolment_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered cluster DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_red, subset=ART_PosEnrolment_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_ART_PosEnrolment_gap.cached_styles[current_cluster] = cluster_filtered_style  # Cache styled DataFrame for cluster\n",
    "\n",
    "            # -- Step 8.1: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name\n",
    "            #report_image_path = rf\"{sub_folder2_image_file_msf_outlier}\\{report_image_name}\"  # Define image file path (commented out)\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define cluster-specific Excel sheet name\n",
    "\n",
    "            # -- Step 9: Create descriptions for Word document\n",
    "            report_description = []  # Initialize list for Word document descriptions\n",
    "            if (cluster_filtered_gap[ART_PosEnrolment_gap_columns[0]] != 0).any():  # Check for non-zero enrolment gap\n",
    "                report_description.append(  # Add enrolment gap description\n",
    "                    f\"Report Name: {ART_PosEnrolment_gap_columns[0]}\\n\"  # Gap column name\n",
    "                    f\"{ART_PosEnrolment_columns_desrpt[0]}\\nshould be equal to {ART_PosEnrolment_columns_desrpt[2]}\\n\"  # Expected equality\n",
    "                    f\"Note: Where this ART enrolment gap is true, please ignore the outlier.\"  # Outlier note\n",
    "                )  # Append enrolment gap description\n",
    "            if (cluster_filtered_gap[ART_PosEnrolment_gap_columns[1]] != 0).any():  # Check for non-zero linkage gap\n",
    "                report_description.append(  # Add linkage gap description\n",
    "                    f\"Report Name: {ART_PosEnrolment_gap_columns[1]}\\n\"  # Gap column name\n",
    "                    f\"{ART_PosEnrolment_columns_desrpt[1]}\\nshould be equal to {ART_PosEnrolment_columns_desrpt[0]}\\n\"  # Expected equality\n",
    "                    f\"Note: Where this ART linkage gap is true, please ignore the outlier.\"  # Outlier note\n",
    "                )  # Append linkage gap description\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Combine descriptions with double newlines\n",
    "\n",
    "            # -- Step 10: Export results\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=ART_PosEnrolment_columns_desrpt,  # Italicize ART columns for description\n",
    "                    doc_indicators_to_underline=ART_PosEnrolment_gap_columns,  # Underline gap columns\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 11: Cache overall unfiltered DataFrame shape\n",
    "        process_ART_PosEnrolment_gap.cached_shape = df_ART_PosEnrolment.shape  # Store original DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_PosEnrolment_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_PosEnrolment_gap.cached_styles.clear()  # Clear cached styles\n",
    "        if hasattr(process_ART_PosEnrolment_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_PosEnrolment_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ART Regimen Line, MMD and DSD gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART regimen line, MMD and DSD gap\n",
    "def process_ART_RegimentLine_MMD_DSD_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART Regimen line, MMD and DSD gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_RegimenLine_MMD_DSD_columns = [  # List of column names for ART regimen, MMD, and DSD metrics\n",
    "            \"ART 3: Number of people living with HIV who are currently receiving ART during the month (All regimens)\",  # Total ART recipients\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens): By Regimen Line\",  # ART by regimen line\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens) - Multi-Month Dispensing\",  # ART with MMD\n",
    "            \"Number of people living with HIV who are currently receiving ART during the month (All regimens) - DSD Model\"  # ART with DSD\n",
    "        ]  # Defines columns for ART gap analysis\n",
    "        name = \"ART Regimen-Line MMD DSD Gap\"  # Base name for the report\n",
    "        ART_RegimenLine_MMD_DSD_gap_columns = [\"ART Regimen Line gap\", \"ART MMD gap\", \"ART DSD gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}8\"  # Report name with suffix for uniqueness\n",
    "        ART_RegimenLine_MMD_DSD_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_RegimenLine_MMD_DSD = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"ART MSF\",  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_RegimenLine_MMD_DSD_columns  # Include ART regimen, MMD, and DSD columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_RegimenLine_MMD_DSD is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        wrap_column_headers(df_ART_RegimenLine_MMD_DSD)  # Format DataFrame column headers (assumed function)\n",
    "        ART_RegimenLine_MMD_DSD_columns2 = wrap_column_headers2(ART_RegimenLine_MMD_DSD_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: ART regimen line gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[0]] = np.where(  # Calculate regimen line gap (requires numpy as np)\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] != df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[1]],  # Check if total ART differs from regimen line\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[1]],  # Compute gap (total - regimen line)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for regimen line\n",
    "        # -- Step 3.2: ART MMD gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[1]] = np.where(  # Calculate MMD gap\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] < df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[2]],  # Check if total ART is less than MMD\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[2]],  # Compute gap (total - MMD)\n",
    "            0  # Set to 0 if no gap (total not less than MMD)\n",
    "        )  # Adds gap column for MMD\n",
    "        # -- Step 3.3: ART DSD gap\n",
    "        df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_gap_columns[2]] = np.where(  # Calculate DSD gap\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] < df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[3]],  # Check if total ART is less than DSD\n",
    "            df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[0]] - df_ART_RegimenLine_MMD_DSD[ART_RegimenLine_MMD_DSD_columns2[3]],  # Compute gap (total - DSD)\n",
    "            0  # Set to 0 if no gap (total not less than DSD)\n",
    "        )  # Adds gap column for DSD\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_style'):  # Check if cached style exists\n",
    "                cached_shape = getattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_RegimenLine_MMD_DSD.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ART_RegimentLine_MMD_DSD_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_RegimenLine_MMD_DSD_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "                df=df_ART_RegimenLine_MMD_DSD,  # Input DataFrame with gaps\n",
    "                msg=ART_RegimenLine_MMD_DSD_msg,  # Message if no gaps found\n",
    "                opNonZero=ART_RegimenLine_MMD_DSD_gap_columns,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_ART_RegimenLine_MMD_DSD_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ART_RegimentLine_MMD_DSD_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ART_RegimentLine_MMD_DSD_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_ART_RegimenLine_MMD_DSD_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_ART_RegimenLine_MMD_DSD_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=ART_RegimenLine_MMD_DSD_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_RegimentLine_MMD_DSD_gap.cached_style = df_ART_RegimenLine_MMD_DSD_gap_style  # Store styled DataFrame\n",
    "        process_ART_RegimentLine_MMD_DSD_gap.cached_shape = df_ART_RegimenLine_MMD_DSD.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_ART_RegimenLine_MMD_DSD_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = f\"{report_name}\"  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for Word document descriptions\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[0]] != 0).any():  # Check for non-zero regimen line gap\n",
    "            report_description.append(  # Add regimen line gap description\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be equal to {ART_RegimenLine_MMD_DSD_columns[1]}\"  # Expected equality\n",
    "            )  # Append regimen line gap description\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[1]] != 0).any():  # Check for non-zero MMD gap\n",
    "            report_description.append(  # Add MMD gap description\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[1]}\\n\"  # Gap column name\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be greater than {ART_RegimenLine_MMD_DSD_columns[2]}\\n\"  # Expected relation\n",
    "            )  # Append MMD gap description\n",
    "        if (df_ART_RegimenLine_MMD_DSD_gap[ART_RegimenLine_MMD_DSD_gap_columns[2]] != 0).any():  # Check for non-zero DSD gap\n",
    "            report_description.append(  # Add DSD gap description\n",
    "                f\"Report Name: {ART_RegimenLine_MMD_DSD_gap_columns[2]}\\n\"  # Gap column name\n",
    "                f\"{ART_RegimenLine_MMD_DSD_columns[0]}\\nshould be greater than {ART_RegimenLine_MMD_DSD_columns[3]}\\n\"  # Expected relation\n",
    "            )  # Append DSD gap description\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Combine descriptions with double newlines\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_ART_RegimenLine_MMD_DSD_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=ART_RegimenLine_MMD_DSD_columns,  # Italicize ART columns\n",
    "                doc_indicators_to_underline=ART_RegimenLine_MMD_DSD_gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_ART_RegimenLine_MMD_DSD_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_RegimentLine_MMD_DSD_gap.cached_style.clear()  # Clear cached styles (note: should be cached_styles)\n",
    "        if hasattr(process_ART_RegimentLine_MMD_DSD_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_RegimentLine_MMD_DSD_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ART TB Screening gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART TB Screening gap\n",
    "def process_ART_TB_Screening_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART Regimen line, MMD and DSD gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Screening_columns = [\"ART 2: Number of people living with HIV newly started on ART during the month (excludes ART transfer-in)\"]  # Column for newly started on ART\n",
    "        place_holder = [\"ART 10: Number of PLHIV on ART (Including PMTCT) who were Clinically Screened for TB in HIV Treatment Settings\"]  # Placeholder for TB screening column\n",
    "        ART_TB_Screening_columns_new_old = ['Newly on ART', 'Already on ART']  # Column names for new/old ART TB screening\n",
    "        ART_TB_Screening_columns_desrpt = [  # Extended list for Word document descriptions\n",
    "            ART_TB_Screening_columns[0],  # Newly started on ART\n",
    "            place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[0],  # TB screening for newly on ART\n",
    "            place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[1]  # TB screening for already on ART\n",
    "        ]  # Defines columns for description\n",
    "        name = \"ART Tx_New TB Screening Gap\"  # Base name for the report\n",
    "        ART_TB_Screening_gap_columns = ['ART Tx New TB screening gap']  # Name for the calculated gap column\n",
    "        report_name = f\"{name}9\"  # Report name with suffix for uniqueness\n",
    "        ART_RegimenLine_MMD_DSD_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Screening = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"ART MSF\",  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_TB_Screening_columns  # Include ART TB screening column\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_TB_Screening is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 2.1: Prepare TB screening data\n",
    "        df_ART_TB_Screening_new_old = prepare_and_convert_df(  # Fetch and prepare TB screening DataFrame\n",
    "            DHIS2_data_key=\"ART MSF_tb screening\",  # Key to fetch TB screening data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=ART_TB_Screening_columns_new_old  # Include new/old TB screening columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_TB_Screening_new_old is None:  # Check if TB screening data preparation failed\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Merge with external DataFrame\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.merge(  # Merge ART data with TB screening data\n",
    "            df_ART_TB_Screening_new_old,  # Target DataFrame for merging\n",
    "            on=MSF_hierarchy,  # Columns to merge on\n",
    "            how=\"left\"  # Keep all rows from df_ART_TB_Screening\n",
    "        )  # Combines ART and TB screening data\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.fillna(0)  # Fill NaN values with 0\n",
    "        float_columns = df_ART_TB_Screening.select_dtypes(include=['float64', 'float32']).columns  # Identify float-type columns\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_ART_TB_Screening[col] = df_ART_TB_Screening[col].astype(int)  # Convert float columns to integers\n",
    "        \n",
    "        # -- Step 3.1: Rename columns\n",
    "        df_ART_TB_Screening = df_ART_TB_Screening.rename(columns={  # Rename TB screening columns for clarity\n",
    "            'Newly on ART': place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[0],  # Rename new ART screening\n",
    "            'Already on ART': place_holder[0] + ' - ' + ART_TB_Screening_columns_new_old[1]  # Rename existing ART screening\n",
    "        })  # Updates column names in DataFrame\n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Screening)  # Format DataFrame column headers (assumed function)\n",
    "        ART_TB_Screening_columns2 = wrap_column_headers2(ART_TB_Screening_columns_desrpt)  # Wrap description column names for display\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        df_ART_TB_Screening[ART_TB_Screening_gap_columns[0]] = np.where(  # Calculate TB screening gap (requires numpy as np)\n",
    "            df_ART_TB_Screening[ART_TB_Screening_columns2[0]] != df_ART_TB_Screening[ART_TB_Screening_columns2[1]],  # Check if newly started differs from screened\n",
    "            df_ART_TB_Screening[ART_TB_Screening_columns2[0]] - df_ART_TB_Screening[ART_TB_Screening_columns2[1]],  # Compute gap (newly started - screened)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for TB screening\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_style'):  # Check if cached style exists\n",
    "                cached_shape = getattr(process_ART_TB_Screening_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_TB_Screening.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ART_TB_Screening_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "                    \n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_ART_TB_Screening_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "                df=df_ART_TB_Screening,  # Input DataFrame with gap\n",
    "                msg=ART_RegimenLine_MMD_DSD_msg,  # Message if no gaps found\n",
    "                opNonZero=ART_TB_Screening_gap_columns,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_ART_TB_Screening_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ART_TB_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ART_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ART_TB_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps                       \n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_ART_TB_Screening_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_ART_TB_Screening_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=ART_TB_Screening_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Screening_gap.cached_style = df_ART_TB_Screening_gap_style  # Store styled DataFrame\n",
    "        process_ART_TB_Screening_gap.cached_shape = df_ART_TB_Screening.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_ART_TB_Screening_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = f\"{report_name}\"  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_ART_TB_Screening_gap[ART_TB_Screening_gap_columns[0]] != 0).any():  # Check for non-zero TB screening gap\n",
    "            report_description = (  # Create description for TB screening gap\n",
    "                f\"Report Name: {ART_TB_Screening_gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{ART_TB_Screening_columns_desrpt[0]}\\nshould be equal to {ART_TB_Screening_columns_desrpt[1]}\"  # Expected equality\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_ART_TB_Screening_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=ART_TB_Screening_columns_desrpt,  # Italicize description columns\n",
    "                doc_indicators_to_underline=ART_TB_Screening_gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            widget_display_df(df_ART_TB_Screening_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "            \n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_TB_Screening_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_TB_Screening_gap.cached_style.clear()  # Clear cached styles (note: should be cached_styles)\n",
    "        if hasattr(process_ART_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_TB_Screening_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ART TB Presumptive Test gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART TB Presumptive Test gap\n",
    "def process_ART_TB_Presumptive_Test_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART Presumptive Test gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Presumptive_Test_columns = [  # List of column names for ART TB Presumptive Test metrics\n",
    "            \"ART 11: Number of PLHIV on ART with Presumptive TB during the month\",  # PLHIV with presumptive TB\n",
    "            \"ART 12: Number of PLHIV on ART with Presumptive TB and Tested for TB during the month\"  # PLHIV tested for TB\n",
    "        ]  # Defines columns for TB presumptive test gap analysis\n",
    "        name = \"ART TB Presumptive Test Gap\"  # Base name for the report\n",
    "        ART_TB_Presumptive_Test_gap_columns = [\"ART TB presumptive test gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}10\"  # Report name with suffix for uniqueness\n",
    "        ART_TB_Presumptive_Test_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Presumptive_Test = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"ART MSF\",  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_TB_Presumptive_Test_columns  # Include ART TB presumptive test columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_TB_Presumptive_Test is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Presumptive_Test)  # Format DataFrame column headers (assumed function)\n",
    "        ART_TB_Presumptive_Test_columns2 = wrap_column_headers2(ART_TB_Presumptive_Test_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: ART TB Presumptive Test gap\n",
    "        df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_gap_columns[0]] = np.where(  # Calculate TB presumptive test gap (requires numpy as np)\n",
    "            df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[0]] != df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[1]],  # Check if presumptive TB differs from tested\n",
    "            df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[0]] - df_ART_TB_Presumptive_Test[ART_TB_Presumptive_Test_columns2[1]],  # Compute gap (presumptive - tested)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for TB presumptive test\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_style'):  # Check if cached style exists\n",
    "                cached_shape = getattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape', None)  # Retrieve Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_TB_Presumptive_Test.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ART_TB_Presumptive_Test_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_TB_Presumptive_Test_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "            df=df_ART_TB_Presumptive_Test,  # Input DataFrame with gap\n",
    "            msg=ART_TB_Presumptive_Test_msg,  # Message if no gaps found\n",
    "            opNonZero=ART_TB_Presumptive_Test_gap_columns,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_ART_TB_Presumptive_Test_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ART_TB_Presumptive_Test_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ART_TB_Presumptive_Test_gap.cached_shape  # Clear cached shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_ART_TB_Presumptive_Test_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_ART_TB_Presumptive_Test_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=ART_TB_Presumptive_Test_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Presumptive_Test_gap.cached_style = df_ART_TB_Presumptive_Test_gap_style  # Store styled DataFrame\n",
    "        process_ART_TB_Presumptive_Test_gap.cached_shape = df_ART_TB_Presumptive_Test.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_ART_TB_Presumptive_Test_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = f\"{report_name}\"  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        if (df_ART_TB_Presumptive_Test_gap[ART_TB_Presumptive_Test_gap_columns[0]] != 0).any():  # Check for non-zero TB presumptive test gap\n",
    "            report_description = (  # Create description for TB presumptive Test gap\n",
    "                f\"Report Name: {ART_TB_Presumptive_Test_gap_columns[0]}\\n\"\n",
    "                f\"{ART_TB_Presumptive_Test_columns[0]}\\nshould be equal to {ART_TB_Presumptive_Test_columns[1]}\"\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_ART_TB_Presumptive_Test_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=ART_TB_Presumptive_Test_columns,  # Italicize TB presumptive test columns\n",
    "                doc_indicators_to_underline=ART_TB_Presumptive_Test_gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_ART_TB_Presumptive_Test_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "            \n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_TB_Presumptive_Test_gap.cached_style.clear()  # Clear cached styles (note: should be cached_styles)\n",
    "        if hasattr(process_ART_TB_Presumptive_Test_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_TB_Presumptive_Test_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ART TB Treatment Test gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART TB Treatment gap\n",
    "def process_ART_TB_Treatment_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART TB Treatment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_TB_Treatment_columns = [  # List of column names for ART TB Treatment metrics\n",
    "            \"ART 13: Number of of PLHIV on ART who have Active TB Disease\",  # PLHIV with active TB\n",
    "            \"ART 14: Number of PLHIV on ART with active TB disease who initiated TB treatment\"  # PLHIV initiated on TB treatment\n",
    "        ]  # Defines columns for TB treatment gap analysis\n",
    "        name = \"ART TB Treatment Gap\"  # Base name for the report\n",
    "        ART_TB_Treatment_gap_columns = [\"ART TB treatment gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}11\"  # Report name with suffix for uniqueness\n",
    "        ART_TB_Treatment_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_TB_Treatment = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"ART MSF\",  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_TB_Treatment_columns  # Include ART TB treatment columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_TB_Treatment is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        wrap_column_headers(df_ART_TB_Treatment)  # Format DataFrame column headers (assumed function)\n",
    "        ART_TB_Treatment_columns_wrap = wrap_column_headers2(ART_TB_Treatment_columns)  # Wrap column names for display\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: ART TB Treatment gap\n",
    "        df_ART_TB_Treatment[ART_TB_Treatment_gap_columns[0]] = np.where(  # Calculate TB treatment gap (requires numpy as np)\n",
    "            df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[0]] != df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[1]],  # Check if active TB differs from treated\n",
    "            df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[0]] - df_ART_TB_Treatment[ART_TB_Treatment_columns_wrap[1]],  # Compute gap (active TB - treated)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for TB treatment\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_style'):  # Check if cached style exists\n",
    "                cached_shape = getattr(process_ART_TB_Treatment_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_TB_Treatment.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ART_TB_Treatment_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_TB_Treatment_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "            df=df_ART_TB_Treatment,  # Input DataFrame with gap\n",
    "            msg=ART_TB_Treatment_msg,  # Message if no gaps found\n",
    "            opNonZero=ART_TB_Treatment_gap_columns,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_ART_TB_Treatment_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ART_TB_Treatment_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ART_TB_Treatment_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ART_TB_Treatment_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_ART_TB_Treatment_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_ART_TB_Treatment_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=ART_TB_Treatment_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_TB_Treatment_gap.cached_style = df_ART_TB_Treatment_gap_style  # Store styled DataFrame\n",
    "        process_ART_TB_Treatment_gap.cached_shape = df_ART_TB_Treatment.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_ART_TB_Treatment_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = f\"{report_name}\"  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        if (df_ART_TB_Treatment_gap[ART_TB_Treatment_gap_columns[0]] != 0).any():  # Check for non-zero TB treatment gap\n",
    "            report_description = (  # Create description for TB treatment gap\n",
    "                f\"Report Name: {ART_TB_Treatment_gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{ART_TB_Treatment_columns[1]}\\nshould be equal to {ART_TB_Treatment_columns[0]}\"  # Expected equality (note: order reversed in description)\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_ART_TB_Treatment_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=ART_TB_Treatment_columns,  # Italicize TB treatment columns\n",
    "                doc_indicators_to_underline=ART_TB_Treatment_gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_ART_TB_Treatment_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "            \n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_TB_Treatment_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_TB_Treatment_gap.cached_style.clear()  # Clear cached styles (note: should be cached_styles)\n",
    "        if hasattr(process_ART_TB_Treatment_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_TB_Treatment_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ART Viral Load Supression gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ART Viral Load Suppression gap\n",
    "def process_ART_Viral_Load_Suppression_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ART Viral Load Suppression gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        ART_Viral_Load_Suppression_columns = [  # List of column names for ART Viral Load Suppression metrics\n",
    "            \"ART 6: Number of PLHIV on ART for at least 6 months with a VL test result during the month: Routine\",  # Routine VL test results\n",
    "            \"Number of PLHIV on ART for at least 6 months with a VL test result during the month: Targeted\",  # Targeted VL test results\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month: Routine\",  # Routine VL suppression\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month: Targeted\"  # Targeted VL suppression\n",
    "        ]  # Defines columns for viral load suppression gap analysis\n",
    "        ART_Viral_Load_Suppression_columns_cal = [  # Calculated column names for aggregated metrics\n",
    "            \"ART 6: Number of PLHIV on ART for at least 6 months with a VL test result during the month - Routine and Targeted\",  # Total VL test results\n",
    "            \"ART 7: Number of PLHIV on ART (for at least 6 months) who have virologic suppression (<1000 copies/ml) during the month - Routine and Targeted\"  # Total VL suppression\n",
    "        ]  # Defines columns for calculated totals\n",
    "        name = \"ART Viral Load Suppression Gap\"  # Base name for the report\n",
    "        ART_Viral_Load_Suppression_gap_columns = [\"ART viral load suppression gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}12\"  # Report name with suffix for uniqueness\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_ART_Viral_Load_Suppression = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"ART MSF\",  # Key to fetch ART MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=ART_Viral_Load_Suppression_columns  # Include ART viral load suppression columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_ART_Viral_Load_Suppression is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: Calculate total viral load results received\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_cal[0]] = (  # Sum Routine and Targeted VL test results\n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[0]] + df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[1]]\n",
    "        )  # Adds column for total VL test results\n",
    "\n",
    "        # -- Step 3.2: Calculate total viral load results suppressed\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_cal[1]] = (  # Sum Routine and Targeted VL suppression\n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[2]] + df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns[3]]\n",
    "        )  # Adds column for total VL suppression\n",
    "\n",
    "        # -- Step 3.3: Drop the original Routine and Targeted columns\n",
    "        df_ART_Viral_Load_Suppression = df_ART_Viral_Load_Suppression.drop(  # Remove original columns to focus on aggregated metrics\n",
    "            columns=[\n",
    "                ART_Viral_Load_Suppression_columns[0],  # Routine VL test results\n",
    "                ART_Viral_Load_Suppression_columns[1],  # Targeted VL test results\n",
    "                ART_Viral_Load_Suppression_columns[2],  # Routine VL suppression\n",
    "                ART_Viral_Load_Suppression_columns[3]   # Targeted VL suppression\n",
    "            ]\n",
    "        )  # Updates DataFrame with only aggregated columns\n",
    "\n",
    "        wrap_column_headers(df_ART_Viral_Load_Suppression)  # Format DataFrame column headers (assumed function)\n",
    "        ART_Viral_Load_Suppression_columns_wrap = wrap_column_headers2(ART_Viral_Load_Suppression_columns_cal)  # Wrap calculated column names for display\n",
    "\n",
    "        # -- Step 3.4: Calculate viral load suppression gap\n",
    "        df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[1]] > df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[0]],  # Check if suppressed exceeds tested\n",
    "            df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[1]] - df_ART_Viral_Load_Suppression[ART_Viral_Load_Suppression_columns_wrap[0]],  # Compute gap (suppressed - tested)\n",
    "            0  # Set to 0 if no gap (suppressed not greater than tested)\n",
    "        )  # Adds gap column for viral load suppression\n",
    "\n",
    "        # -- Step 4: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_style'):  # Check if cached style exists\n",
    "                cached_shape = getattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_ART_Viral_Load_Suppression.shape  # Get current DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ART_Viral_Load_Suppression_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "                    \n",
    "        # -- Step 5: Filter and validate gaps\n",
    "        df_ART_Viral_Load_Suppression_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "            df=df_ART_Viral_Load_Suppression,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message if no gaps found\n",
    "            opNonZero=ART_Viral_Load_Suppression_gap_columns,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "        if df_ART_Viral_Load_Suppression_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ART_Viral_Load_Suppression_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ART_Viral_Load_Suppression_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 6: Style the DataFrame\n",
    "        df_ART_Viral_Load_Suppression_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_ART_Viral_Load_Suppression_gap.style  # Create style object\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=ART_Viral_Load_Suppression_gap_columns)  # Highlight gap column outliers in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 7: Cache styled DataFrame and shape\n",
    "        process_ART_Viral_Load_Suppression_gap.cached_style = df_ART_Viral_Load_Suppression_gap_style  # Store styled DataFrame\n",
    "        process_ART_Viral_Load_Suppression_gap.cached_shape = df_ART_Viral_Load_Suppression.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 8: Define export variables\n",
    "        report_month = df_ART_Viral_Load_Suppression_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = f\"{report_name}\"  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 9: Create descriptions for Word document\n",
    "        if (df_ART_Viral_Load_Suppression_gap[ART_Viral_Load_Suppression_gap_columns[0]] != 0).any():  # Check for non-zero viral load suppression gap\n",
    "            report_description = (  # Create description for viral load suppression gap\n",
    "                f\"Report Name: {ART_Viral_Load_Suppression_gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{ART_Viral_Load_Suppression_columns[2]}\\nplus{ART_Viral_Load_Suppression_columns[3]}\\n\"  # Routine + Targeted suppression\n",
    "                f\"should not be greater than {ART_Viral_Load_Suppression_columns[0]}\\nplus{ART_Viral_Load_Suppression_columns[1]}\"  # Routine + Targeted test results\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 10: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_ART_Viral_Load_Suppression_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=ART_Viral_Load_Suppression_columns,  # Italicize viral load suppression columns\n",
    "                doc_indicators_to_underline=ART_Viral_Load_Suppression_gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 11: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_ART_Viral_Load_Suppression_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "            \n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_ART_Viral_Load_Suppression_gap.cached_style.clear()  # Clear cached styles (note: should be cached_styles)\n",
    "        if hasattr(process_ART_Viral_Load_Suppression_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ART_Viral_Load_Suppression_gap.cached_shape  # Clear cached shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## - HTS MSF\n",
    "### - HTS New Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HTS New Positive gap\n",
    "def process_HTS_New_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS New Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_New_Positive_columns = [  # List of column names for HTS New Positive metrics\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient, Outpatient, Standalone)\",  # Total positive results (facility-based)\n",
    "            \"Number of people who tested HIV positive and received results  (Community)\",  # Total positive results (community-based)\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling (Inpatient, Outpatient, Standalone)\",  # Known positives (facility-based)\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\",  # Known positives (community-based)\n",
    "            \"HTS total tested - positive\",  # Total tested positive\n",
    "            \"HTS total tested - previously known positive\",  # Total previously known positives\n",
    "            \"HTS total tested - new positive (excluding previously known)\",  # New positives excluding known\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient)\",  # Inpatient positive results\n",
    "            \"Number of people who tested HIV positive and received results (Outpatient)\",  # Outpatient positive results\n",
    "            \"Number of people who tested HIV positive and received results (Standalone)\",  # Standalone positive results\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Inpatient)\",  # Inpatient known positives\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Outpatient)\",  # Outpatient known positives\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Standalone)\"  # Standalone known positives\n",
    "        ]  # Defines columns for HTS New Positive gap analysis\n",
    "\n",
    "        HTS_New_Positive_columns_order = [  # Desired order of columns for output\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient, Outpatient, Standalone)\",  # Facility-based positive results\n",
    "            \"Number of people who tested HIV positive and received results  (Community)\",  # Community-based positive results\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling (Inpatient, Outpatient, Standalone)\",  # Facility-based known positives\n",
    "            \"Total number of people tested HIV positive that were identified as known positive during post-test counselling.(Community)\",  # Community-based known positives\n",
    "            \"HTS total tested - positive\",  # Total tested positive\n",
    "            \"HTS total tested - previously known positive\",  # Total previously known positives\n",
    "            \"HTS total tested - new positive (excluding previously known)\"  # New positives excluding known\n",
    "        ]  # Specifies column order for DataFrame\n",
    "        Gap_title_special = [\"Community testing gap\"]  # Special title for community testing gap\n",
    "        name = \"HTS New Positive Gap\"  # Base name for the report\n",
    "        HTS_New_Positive_gap_columns = [\"HTS total tested - new positive (excluding previously known)\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}13\"  # Report name with suffix for uniqueness\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_New_Positive = Pre_HTS_MSF_positive.copy()  # Create a copy of the predefined HTS total positives DataFrame (assumed defined elsewhere)\n",
    "\n",
    "        # -- Step 3: Calculate total HTS New Positive results\n",
    "        df_HTS_New_Positive[HTS_New_Positive_columns[0]] = (  # Sum facility-based positive results (Inpatient, Outpatient, Standalone)\n",
    "            df_HTS_New_Positive.iloc[:, 4:7].sum(axis=1)  # Sum columns 4 to 6 (indices for Inpatient, Outpatient, Standalone positives)\n",
    "        )  # Adds column for total facility-based positive results\n",
    "\n",
    "        # -- Step 4: Calculate total HTS New Positive results previously known\n",
    "        df_HTS_New_Positive[HTS_New_Positive_columns[2]] = (  # Sum facility-based known positives (Inpatient, Outpatient, Standalone)\n",
    "            df_HTS_New_Positive.iloc[:, 8:11].sum(axis=1)  # Sum columns 8 to 10 (indices for Inpatient, Outpatient, Standalone known positives)\n",
    "        )  # Adds column for total facility-based known positives\n",
    "\n",
    "        # -- Step 5: Drop the original HTS SDP columns\n",
    "        df_HTS_New_Positive = df_HTS_New_Positive.drop(  # Remove specific service delivery point (SDP) columns to simplify DataFrame\n",
    "            columns=[\n",
    "                HTS_New_Positive_columns[7],  # Inpatient positive results\n",
    "                HTS_New_Positive_columns[8],  # Outpatient positive results\n",
    "                HTS_New_Positive_columns[9],  # Standalone positive results\n",
    "                HTS_New_Positive_columns[10],  # Inpatient known positives\n",
    "                HTS_New_Positive_columns[11],  # Outpatient known positives\n",
    "                HTS_New_Positive_columns[12]  # Standalone known positives\n",
    "            ]\n",
    "        )  # Updates DataFrame with only aggregated columns\n",
    "\n",
    "        # -- Step 6: Reorder the columns to match the desired order\n",
    "        df_HTS_New_Positive = df_HTS_New_Positive[MSF_hierarchy + HTS_New_Positive_columns_order]  # Reorder columns to include hierarchy and specified order (MSF_hierarchy assumed defined)\n",
    "\n",
    "        wrap_column_headers(df_HTS_New_Positive)  # Format DataFrame column headers for readability (assumed function)\n",
    "        HTS_New_Positive_columns_wrap = wrap_column_headers2(HTS_New_Positive_columns_order)  # Wrap ordered column names for display\n",
    "        HTS_New_Positive_gap_columns_wrap = wrap_column_headers2(HTS_New_Positive_gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 7: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_New_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HTS_New_Positive.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HTS_New_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)   \n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 8: Filter and validate gaps\n",
    "        df_HTS_New_Positive_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with gaps\n",
    "            df=df_HTS_New_Positive,  # Input DataFrame with calculated metrics\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=None,  # No non-zero value filter\n",
    "            opNeg=HTS_New_Positive_columns_wrap,  # Filter for negative values in specified columns\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        \n",
    "        if df_HTS_New_Positive_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HTS_New_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HTS_New_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HTS_New_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 9: Style the DataFrame\n",
    "        df_HTS_New_Positive_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HTS_New_Positive_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red_LT0, subset=HTS_New_Positive_columns_wrap)  # Highlight negative outliers in specified columns (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 10: Cache styled DataFrame and shape\n",
    "        process_HTS_New_Positive_gap.cached_style = df_HTS_New_Positive_style  # Store styled DataFrame\n",
    "        process_HTS_New_Positive_gap.cached_shape = df_HTS_New_Positive.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 11: Define export variables\n",
    "        report_month = df_HTS_New_Positive['ReportPeriod'].iloc[0]  # Extract report period from unfiltered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 12: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_HTS_New_Positive[HTS_New_Positive_gap_columns_wrap[0]] < 0).any():  # Check for negative new positive gaps\n",
    "            report_description.append(  # Add description for new positive gap\n",
    "                f\"Report Name: {HTS_New_Positive_gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{HTS_New_Positive_columns[6]}\\nshould not be less than 0\"  # New positives should be non-negative\n",
    "            )  # Append description to list\n",
    "        if (df_HTS_New_Positive[HTS_New_Positive_columns_wrap[1]] != 0).any() or (df_HTS_New_Positive[HTS_New_Positive_columns_wrap[3]] != 0).any():  # Check for non-zero community testing results\n",
    "            report_description.append(  # Add description for community testing gap\n",
    "                f\"Report Name: {Gap_title_special[0]}\\n\"  # Special community gap title\n",
    "                f\"{HTS_New_Positive_columns[1]}\\n\"  # Community positive results\n",
    "                f\"plus {HTS_New_Positive_columns[3]} should not be greater than 0\"  # Community known positives\n",
    "            )  # Append description to list\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 13: Export results\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HTS_New_Positive_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_file_path=doc_file_msf_outlier_docx,  # Word document path (assumed defined)\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=HTS_New_Positive_columns,  # Italicize HTS columns\n",
    "                doc_indicators_to_underline=HTS_New_Positive_gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 14: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_HTS_New_Positive_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HTS_New_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HTS_New_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HTS_New_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HTS_New_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HTS TB Screening gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HTS TB Screening gap\n",
    "def process_HTS_TB_Screening_gap(display_output=None): \n",
    "    \"\"\"\n",
    "    Process HTS TB Screening gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_TB_Screening_columns = [  # List of column names for HTS TB Screening metrics\n",
    "            \"Number of people who tested HIV negative and received their results. (Inpatient)\",  # HIV negative results (Inpatient)\n",
    "            \"Number of people who tested HIV negative and received their results. (Outpatient)\",  # HIV negative results (Outpatient)\n",
    "            \"Number of people who tested HIV negative and received their results. (Standalone)\",  # HIV negative results (Standalone)\n",
    "            \"Number of people who tested HIV negative and received their results. (Community)\",  # HIV negative results (Community)\n",
    "            \"Number of people who tested HIV positive and received results (Inpatient)\",  # HIV positive results (Inpatient)\n",
    "            \"Number of people who tested HIV positive and received results (Outpatient)\",  # HIV positive results (Outpatient)\n",
    "            \"Number of people who tested HIV positive and received results (Standalone)\",  # HIV positive results (Standalone)\n",
    "            \"Number of people who tested HIV positive and received results  (Community)\",  # HIV positive results (Community)\n",
    "            \"Number of HTS clients clinically screened for TB (Inpatient)\",  # TB screening (Inpatient)\n",
    "            \"Number of HTS clients clinically screened for TB (Outpatient)\",  # TB screening (Outpatient)\n",
    "            \"Number of HTS clients clinically screened for TB (Standalone)\",  # TB screening (Standalone)\n",
    "            \"Number of HTS clients clinically screened for TB (Community)\"  # TB screening (Community)\n",
    "        ]  # Defines columns for HTS TB Screening gap analysis\n",
    "        HTS_TB_Screening_columns_spec = [  # Specific columns for summary in report description\n",
    "            \"Number of people who tested HIV negative and received their results. (Inpatient, Outpatient, Standalone)\",  # Aggregated HIV negative results\n",
    "            \"Number of HTS clients clinically screened for TB (Inpatient, Outpatient, Standalone)\"  # Aggregated TB screening\n",
    "        ]  # Defines summary columns for documentation\n",
    "        name = \"HTS TB Screening Gap\"  # Base name for the report\n",
    "        Gap_columns = [\"HTS TB screening gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}14\"  # Report name with suffix for uniqueness\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_TB_Screening = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=HTS_TB_Screening_columns  # Include HTS TB Screening columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HTS_TB_Screening is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate derived metrics\n",
    "        # -- Step 3.1: Calculate total HTS testing\n",
    "        df_HTS_TB_Screening[\"HTS total tested\"] = (  # Sum total HIV tested (positive and negative across all settings)\n",
    "            df_HTS_TB_Screening.iloc[:, 4:12].sum(axis=1)  # Sum columns 4 to 11 (HIV positive and negative results)\n",
    "        )  # Adds column for total HTS tested individuals\n",
    "\n",
    "        # -- Step 3.2: Calculate total HTS TB screening\n",
    "        df_HTS_TB_Screening[\"HTS TB total screened\"] = (  # Sum total TB screenings across all settings\n",
    "            df_HTS_TB_Screening.iloc[:, 12:16].sum(axis=1)  # Sum columns 12 to 15 (TB screening columns)\n",
    "        )  # Adds column for total TB screened individuals\n",
    "\n",
    "        # -- Step 3.3: Calculate HTS TB Screening gap\n",
    "        df_HTS_TB_Screening[Gap_columns[0]] = np.where(  # Calculate TB screening gap (requires numpy as np)\n",
    "            df_HTS_TB_Screening[\"HTS total tested\"] != df_HTS_TB_Screening[\"HTS TB total screened\"],  # Check if tested differs from screened\n",
    "            df_HTS_TB_Screening[\"HTS TB total screened\"] - df_HTS_TB_Screening[\"HTS total tested\"],  # Compute gap (screened - tested)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for TB screening\n",
    "\n",
    "        # -- Step 4: Drop original columns\n",
    "        df_HTS_TB_Screening = df_HTS_TB_Screening.drop(  # Remove original detailed columns to focus on derived metrics\n",
    "            columns=HTS_TB_Screening_columns  # Drop all original HTS TB Screening columns\n",
    "        )  # Updates DataFrame with only hierarchy, totals, and gap columns\n",
    "\n",
    "        wrap_column_headers(df_HTS_TB_Screening)  # Format DataFrame column headers for readability (assumed function)\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_TB_Screening_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HTS_TB_Screening.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HTS_TB_Screening_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_HTS_TB_Screening_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HTS_TB_Screening,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=Gap_columns,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HTS_TB_Screening_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HTS_TB_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HTS_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HTS_TB_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_HTS_TB_Screening_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HTS_TB_Screening_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=Gap_columns)  # Highlight outliers in gap column (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_HTS_TB_Screening_gap.cached_style = df_HTS_TB_Screening_gap_style  # Store styled DataFrame\n",
    "        process_HTS_TB_Screening_gap.cached_shape = df_HTS_TB_Screening.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_HTS_TB_Screening_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_HTS_TB_Screening_gap[Gap_columns[0]] != 0).any():  # Check for non-zero TB screening gaps\n",
    "            report_description = (  # Create description for TB screening gap\n",
    "                f\"Report Name: {Gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{HTS_TB_Screening_columns_spec[1]}\\n\"  # Aggregated TB screening\n",
    "                f\"should be equal to {HTS_TB_Screening_columns_spec[0]}\"  # Aggregated HIV negative results\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HTS_TB_Screening_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=HTS_TB_Screening_columns_spec,  # Italicize specific summary columns\n",
    "                doc_indicators_to_underline=Gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)   # Print display name with separators\n",
    "            widget_display_df(df_HTS_TB_Screening_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HTS_TB_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HTS_TB_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HTS_TB_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HTS_TB_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HTS Positive Enrolment gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HTS Enrolment gap\n",
    "def process_HTS_Enrolment_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS Enrolment gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_Enrolment_columns = [  # List of column names for HTS Enrolment metrics\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Inpatient)\",  # Enrolled in HIV care (Inpatient)\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Outpatient)\",  # Enrolled in HIV care (Outpatient)\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Standalone)\",  # Enrolled in HIV care (Standalone)\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Community)\"  # Enrolled in HIV care (Community)\n",
    "        ]  # Defines columns for HTS Enrolment gap analysis\n",
    "        HTS_Enrolment_columns_spec = [  # Specific columns for summary in report description\n",
    "            \"Number of people tested HIV positive who are successfully enrolled in HIV Care (Inpatient, Outpatient, Standalone)\",  # Aggregated enrolment\n",
    "            \"HTS total tested - new positive (excluding previously known)\"  # New positives excluding known\n",
    "        ]  # Defines summary columns for documentation\n",
    "        columns_to_keep = MSF_hierarchy + [\"HTS total tested - new positive (excluding previously known)\"]  # Columns to retain from positives data\n",
    "        Pre_MSF_positives_subset = Pre_MSF_positives_all[columns_to_keep]  # Subset of predefined positives DataFrame (assumed defined elsewhere)\n",
    "        name = \"HTS Enrolment Gap\"  # Base name for the report\n",
    "        Gap_columns = [\"HTS enrolment gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}15\"  # Report name with suffix for uniqueness\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_Enrolment = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=HTS_Enrolment_columns  # Include HTS Enrolment columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HTS_Enrolment is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Merge with Pre_MSF_positives_all subset\n",
    "        df_HTS_Enrolment = Pre_MSF_positives_subset.merge(  # Merge enrolment data with positives subset\n",
    "            df_HTS_Enrolment,  # Target DataFrame for merge\n",
    "            on=MSF_hierarchy,  # Merge on hierarchy columns\n",
    "            how=\"left\"  # Keep all rows from Pre_MSF_positives_subset\n",
    "        )  # Updates DataFrame with merged data\n",
    "\n",
    "        # -- Step 4: Sort and clean data\n",
    "        df_HTS_Enrolment.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns and reset index\n",
    "        df_HTS_Enrolment = df_HTS_Enrolment.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_HTS_Enrolment.select_dtypes(include=['float64', 'float32']).columns  # Identify columns with float data types\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_HTS_Enrolment[col] = df_HTS_Enrolment[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        # -- Step 5: Calculate derived metrics\n",
    "        # -- Step 5.1: Calculate total enrolment\n",
    "        df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] = (  # Sum enrolment across all settings\n",
    "            df_HTS_Enrolment[HTS_Enrolment_columns].sum(axis=1)  # Sum specified enrolment columns\n",
    "        )  # Adds column for total enrolment\n",
    "\n",
    "        # -- Step 5.2: Calculate enrolment gap\n",
    "        df_HTS_Enrolment[Gap_columns[0]] = np.where(  # Calculate enrolment gap (requires numpy as np)\n",
    "            df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] != df_HTS_Enrolment[HTS_Enrolment_columns_spec[1]],  # Check if enrolled differs from new positives\n",
    "            df_HTS_Enrolment[HTS_Enrolment_columns_spec[0]] - df_HTS_Enrolment[HTS_Enrolment_columns_spec[1]],  # Compute gap (enrolled - new positives)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for enrolment\n",
    "\n",
    "        # -- Step 6: Drop original columns\n",
    "        df_HTS_Enrolment = df_HTS_Enrolment.drop(  # Remove original detailed enrolment columns\n",
    "            columns=HTS_Enrolment_columns  # Drop specified enrolment columns\n",
    "        )  # Updates DataFrame with hierarchy, totals, and gap columns\n",
    "\n",
    "        # -- Step 7: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_Enrolment)  # Format DataFrame column headers (assumed function)\n",
    "\n",
    "        # -- Step 8: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HTS_Enrolment_gap, 'cached_styles'):  # Check if cached styles dictionary exists\n",
    "                cached_shape = getattr(process_HTS_Enrolment_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HTS_Enrolment.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_HTS_Enrolment_gap.cached_styles.items():  # Iterate over cached styles by cluster\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed display function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 9: Initialize cache\n",
    "        if not hasattr(process_HTS_Enrolment_gap, 'cached_styles'):  # Check if cached styles dictionary is initialized\n",
    "            process_HTS_Enrolment_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 10: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_HTS_Enrolment['Cluster'].unique())  # Extract unique cluster values from DataFrame (requires pandas as pd)\n",
    "\n",
    "        # -- Step 11: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_HTS_Enrolment[df_HTS_Enrolment['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            HTS_Enrolment_msg = f\"No {current_cluster} {report_name}\"  # Define cluster-specific message for no gaps\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "                df=cluster_filtered,  # Input filtered cluster DataFrame\n",
    "                msg=HTS_Enrolment_msg,  # Message if no gaps found\n",
    "                opNonZero=Gap_columns,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found for cluster\n",
    "                if current_cluster in process_HTS_Enrolment_gap.cached_styles:  # Check if cluster is in cache\n",
    "                    del process_HTS_Enrolment_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered cluster DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_red, subset=Gap_columns)  # Highlight outliers in gap column (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_HTS_Enrolment_gap.cached_styles[current_cluster] = cluster_filtered_style  # Store styled DataFrame in cache by cluster\n",
    "\n",
    "            # -- Step 12: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered cluster DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month and cluster\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 13: Create descriptions\n",
    "            report_description = []  # Initialize empty list for descriptions\n",
    "            if (cluster_filtered_gap[Gap_columns[0]] != 0).any():  # Check for non-zero enrolment gaps\n",
    "                report_description.append(  # Add description for enrolment gap\n",
    "                    f\"Report Name: {Gap_columns[0]}\\n\"  # Gap column name\n",
    "                    f\"{HTS_Enrolment_columns_spec[1]}\\n\"  # New positives excluding known\n",
    "                    f\"should be equal to {HTS_Enrolment_columns_spec[0]}\"  # Aggregated enrolment\n",
    "                )  # Append description to list\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 14: Export results\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=HTS_Enrolment_columns_spec,  # Italicize specific summary columns\n",
    "                    doc_indicators_to_underline=Gap_columns,  # Underline gap column\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 15: Cache overall unfiltered DataFrame shape\n",
    "        process_HTS_Enrolment_gap.cached_shape = df_HTS_Enrolment.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HTS_Enrolment_gap, 'cached_styles'):  # Check for cached styles dictionary\n",
    "            process_HTS_Enrolment_gap.cached_styles.clear()  # Clear cached styles\n",
    "        if hasattr(process_HTS_Enrolment_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HTS_Enrolment_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HTS Couple Counselling gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HTS Couple Counselling gap\n",
    "def process_HTS_Couple_Counselling_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS Couple Counselling gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over data, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_Couple_Counselling_columns = [  # List of column names for HTS Couple Counselling metrics\n",
    "            \"No of couples counselled, tested for HIV and received result (Inpatient)\",  # Couples tested in Inpatient setting\n",
    "            \"No of couples counselled, tested for HIV and received result (Outpatient)\",  # Couples tested in Outpatient setting\n",
    "            \"No of couples counselled, tested for HIV and received result (Standalone)\",  # Couples tested in Standalone setting\n",
    "            \"No of couples counselled, tested for HIV and received result (Community)\",  # Couples tested in Community setting\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Inpatient)\",  # Discordant results in Inpatient setting\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Outpatient)\",  # Discordant results in Outpatient setting\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Standalone)\",  # Discordant results in Standalone setting\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Community)\"  # Discordant results in Community setting\n",
    "        ]  # Defines columns for HTS Couple Counselling gap analysis\n",
    "        HTS_Couple_Counselling_columns_spec = [  # Specific columns for summary in report description\n",
    "            \"No of couples counselled, tested for HIV and received result (Inpatient, Outpatient, Standalone)\",  # Aggregated couples tested\n",
    "            \"No of couples counselled, tested for HIV and received discordant result (Inpatient, Outpatient, Standalone)\"  # Aggregated discordant results\n",
    "        ]  # Defines summary columns for documentation\n",
    "        name = \"HTS Discordant Couple Test Gap\"  # Base name for the report\n",
    "        Gap_columns = [\"HTS Discordant Couple Test gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}16\"  # Report name with suffix for uniqueness\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display when no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_Couple_Counselling = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=HTS_Couple_Counselling_columns  # Include HTS Couple Counselling columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HTS_Couple_Counselling is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Sort and clean data\n",
    "        df_HTS_Couple_Counselling.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns and reset index\n",
    "        df_HTS_Couple_Counselling = df_HTS_Couple_Counselling.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_HTS_Couple_Counselling.select_dtypes(include=['float64', 'float32']).columns  # Identify columns with float data types\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_HTS_Couple_Counselling[col] = df_HTS_Couple_Counselling[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        # -- Step 4: Calculate derived metrics\n",
    "        # -- Step 4.1: Calculate total couples counselled and tested\n",
    "        df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]] = (  # Sum couples tested across specified settings\n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns[:4]].sum(axis=1)  # Sum first four columns (Inpatient, Outpatient, Standalone, Community)\n",
    "        )  # Adds column for total couples tested\n",
    "\n",
    "        # -- Step 4.2: Calculate total discordant results\n",
    "        df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]] = (  # Sum discordant results across specified settings\n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns[4:]].sum(axis=1)  # Sum last four columns (discordant results)\n",
    "        )  # Adds column for total discordant results\n",
    "\n",
    "        # -- Step 4.3: Calculate discordant couple test gap\n",
    "        df_HTS_Couple_Counselling[Gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]] > df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]],  # Check if discordant results exceed total tested\n",
    "            df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[0]] - df_HTS_Couple_Counselling[HTS_Couple_Counselling_columns_spec[1]],  # Compute gap (tested - discordant)\n",
    "            0  # Set to 0 if no gap (discordant <= tested)\n",
    "        )  # Adds gap column for discordant results\n",
    "\n",
    "        # -- Step 5: Drop original columns\n",
    "        df_HTS_Couple_Counselling = df_HTS_Couple_Counselling.drop(  # Remove original detailed columns\n",
    "            columns=HTS_Couple_Counselling_columns  # Drop specified counselling columns\n",
    "        )  # Updates DataFrame with hierarchy, totals, and gap columns\n",
    "\n",
    "        # -- Step 6: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_Couple_Counselling)  # Format DataFrame column headers (assumed function)\n",
    "        Gap_columns_wrap = wrap_column_headers2(Gap_columns)  # Format gap column headers (assumed function)\n",
    "\n",
    "        # -- Step 7: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HTS_Couple_Counselling_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HTS_Couple_Counselling.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(process_HTS_Couple_Counselling_gap.cached_style)  # Display cached styled DataFrame (assumed display function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 8: Filter and validate gaps\n",
    "        df_HTS_Couple_Counselling_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for non-zero gaps\n",
    "            df=df_HTS_Couple_Counselling,  # Input DataFrame\n",
    "            msg=No_gap_msg,  # Message if no gaps found\n",
    "            opNonZero=Gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HTS_Couple_Counselling_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # Check if cache exists\n",
    "                del process_HTS_Couple_Counselling_gap.cached_style  # Clear cached style\n",
    "            if hasattr(process_HTS_Couple_Counselling_gap, 'cached_shape'):  # Check if cached shape exists\n",
    "                del process_HTS_Couple_Counselling_gap.cached_shape  # Clear cached shape\n",
    "            return  # Exit function\n",
    "\n",
    "        # -- Step 9: Style the DataFrame\n",
    "        df_HTS_Couple_Counselling_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HTS_Couple_Counselling_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=Gap_columns)  # Highlight outliers in gap column (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 10: Cache styled DataFrame and shape\n",
    "        process_HTS_Couple_Counselling_gap.cached_style = df_HTS_Couple_Counselling_gap_style  # Store styled DataFrame in cache\n",
    "        process_HTS_Couple_Counselling_gap.cached_shape = df_HTS_Couple_Counselling.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 11: Define export variables\n",
    "        report_month = df_HTS_Couple_Counselling_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = sub_folder2_image_file_msf_outlier  # Image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name\n",
    "\n",
    "        # -- Step 12: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_HTS_Couple_Counselling_gap[Gap_columns[0]] != 0).any():  # Check for non-zero gaps\n",
    "            report_description.append(  # Add description for discordant couple test gap\n",
    "                f\"Report Name: {Gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{HTS_Couple_Counselling_columns_spec[1]}\\n\"  # Total discordant results\n",
    "                f\"should be less than or equal to {HTS_Couple_Counselling_columns_spec[0]}\"  # Total couples tested\n",
    "            )  # Append description to list\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 13: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name\n",
    "                df_style=df_HTS_Couple_Counselling_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=HTS_Couple_Counselling_columns_spec,  # Italicize specific summary columns\n",
    "                doc_indicators_to_underline=Gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 14: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_HTS_Couple_Counselling_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HTS_Couple_Counselling_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HTS_Couple_Counselling_gap.cached_style  # Clear cached style\n",
    "        if hasattr(process_HTS_Couple_Counselling_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HTS_Couple_Counselling_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HTS CD4 Test gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HTS CD4 gap\n",
    "def process_HTS_CD4_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HTS CD4 gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        HTS_CD4_columns = [  # List of column names for HTS CD4 metrics\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Inpatient)\",  # CD4 <200 (Inpatient)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Outpatient)\",  # CD4 <200 (Outpatient)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0 (Standalone)\",  # CD4 <200 (Standalone)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period\\xa0\\xa0(Community)\",  # CD4 <200 (Community)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Inpatient)\",  # CD4 >200 (Inpatient)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Outpatient)\",  # CD4 >200 (Outpatient)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Standalone)\",  # CD4 >200 (Standalone)\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period\\xa0\\xa0(Community)\"  # CD4 >200 (Community)\n",
    "        ]  # Defines columns for HTS CD4 gap analysis\n",
    "        HTS_CD4_columns_spec = [  # Specific columns for summary in report description\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 <200 cells/mm3 test during the reporting period  (Inpatient, Outpatient, Standalone)\",  # Aggregated CD4 <200\n",
    "            \"Number of newly diagnosed PLHIV who received CD4 >200 cells/mm3 test during the reporting period  (Inpatient, Outpatient, Standalone)\",  # Aggregated CD4 >200\n",
    "            \"HTS total tested - new positive (excluding previously known)\",  # New positives excluding known\n",
    "            \"Total Number of newly diagnosed PLHIV who received CD4 (<200 and >200) cells/mm3\"  # Total CD4 tested\n",
    "        ]  # Defines summary columns for documentation\n",
    "        columns_to_keep = MSF_hierarchy + [\"HTS total tested - new positive (excluding previously known)\"]  # Columns to retain from positives data\n",
    "        Pre_MSF_positives_subset = Pre_MSF_positives_all[columns_to_keep]  # Subset of predefined positives DataFrame (assumed defined elsewhere)\n",
    "        name = \"HTS CD4 Gap\"  # Base name for the report\n",
    "        Gap_columns = [\"HTS CD4 gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}17\"  # Report name with suffix for uniqueness\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HTS_CD4 = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF data\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=HTS_CD4_columns  # Include HTS CD4 columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HTS_CD4 is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Merge with Pre_MSF_positives_all subset\n",
    "        df_HTS_CD4 = Pre_MSF_positives_subset.merge(  # Merge CD4 data with positives subset\n",
    "            df_HTS_CD4,  # Target DataFrame for merge\n",
    "            on=MSF_hierarchy,  # Merge on hierarchy columns\n",
    "            how=\"left\"  # Keep all rows from Pre_MSF_positives_subset\n",
    "        )  # Updates DataFrame with merged data\n",
    "\n",
    "        # -- Step 4: Sort and clean data\n",
    "        df_HTS_CD4.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns and reset index\n",
    "        df_HTS_CD4 = df_HTS_CD4.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_HTS_CD4.select_dtypes(include=['float64', 'float32']).columns  # Identify columns with float data types\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_HTS_CD4[col] = df_HTS_CD4[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        # -- Step 5: Calculate derived metrics\n",
    "        # -- Step 5.1: Calculate total CD4 <200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[0]] = (  # Sum total CD4 <200 tests across facility settings\n",
    "            df_HTS_CD4.iloc[:, 5:9].sum(axis=1)  # Sum columns 5 to 8 (Inpatient, Outpatient, Standalone, Community for CD4 <200)\n",
    "        )  # Adds column for total CD4 <200 tests\n",
    "\n",
    "        # -- Step 5.2: Calculate total CD4 >200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[1]] = (  # Sum total CD4 >200 tests across facility settings\n",
    "            df_HTS_CD4.iloc[:, 9:13].sum(axis=1)  # Sum columns 9 to 12 (Inpatient, Outpatient, Standalone, Community for CD4 >200)\n",
    "        )  # Adds column for total CD4 >200 tests\n",
    "\n",
    "        # -- Step 5.3: Calculate total CD4 <200 and >200\n",
    "        df_HTS_CD4[HTS_CD4_columns_spec[3]] = (  # Sum total CD4 tests (both <200 and >200)\n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[0]] + df_HTS_CD4[HTS_CD4_columns_spec[1]]  # Add CD4 <200 and >200 totals\n",
    "        )  # Adds column for total CD4 tests\n",
    "\n",
    "        # -- Step 5.4: Calculate CD4 gap\n",
    "        df_HTS_CD4[Gap_columns[0]] = np.where(  # Calculate CD4 gap (requires numpy as np)\n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[2]] != df_HTS_CD4[HTS_CD4_columns_spec[3]],  # Check if new positives differ from total CD4 tested\n",
    "            df_HTS_CD4[HTS_CD4_columns_spec[2]] - df_HTS_CD4[HTS_CD4_columns_spec[3]],  # Compute gap (new positives - total CD4 tested)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for CD4 testing\n",
    "\n",
    "        # -- Step 6: Drop original columns\n",
    "        columns_to_drop = HTS_CD4_columns + [HTS_CD4_columns_spec[0], HTS_CD4_columns_spec[1]]  # Combine original and aggregated CD4 columns to drop\n",
    "        df_HTS_CD4 = df_HTS_CD4.drop(  # Remove specified columns to focus on key metrics\n",
    "            columns=columns_to_drop  # Drop original and intermediate CD4 columns\n",
    "        )  # Updates DataFrame with hierarchy, new positives, total CD4, and gap columns\n",
    "\n",
    "        # -- Step 7: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HTS_CD4)  # Format DataFrame column headers (assumed function)\n",
    "\n",
    "        # -- Step 8: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HTS_CD4_gap, 'cached_styles'):  # Check if cached styles dictionary exists\n",
    "                cached_shape = getattr(process_HTS_CD4_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HTS_CD4.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_HTS_CD4_gap.cached_styles.items():  # Iterate over cached styles by cluster\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 9: Initialize cache\n",
    "        if not hasattr(process_HTS_CD4_gap, 'cached_styles'):  # Check if cached styles dictionary is initialized\n",
    "            process_HTS_CD4_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 10: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_HTS_CD4['Cluster'].unique())  # Extract unique cluster values from DataFrame (requires pandas as pd)\n",
    "\n",
    "        # -- Step 11: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_HTS_CD4[df_HTS_CD4['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            HTS_CD4_msg = f\"No {current_cluster} {report_name}\"  # Define cluster-specific message for no gaps\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter for rows with non-zero gaps\n",
    "                df=cluster_filtered,  # Input filtered cluster DataFrame\n",
    "                msg=HTS_CD4_msg,  # Message if no gaps found\n",
    "                opNonZero=Gap_columns,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found for cluster\n",
    "                if current_cluster in process_HTS_CD4_gap.cached_styles:  # Check if cluster is in cache\n",
    "                    del process_HTS_CD4_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered cluster DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_red, subset=Gap_columns)  # Highlight outliers in gap column (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_HTS_CD4_gap.cached_styles[current_cluster] = cluster_filtered_style  # Store styled DataFrame in cache by cluster\n",
    "\n",
    "            # -- Step 12: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered cluster DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month and cluster\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 13: Create descriptions\n",
    "            if (cluster_filtered_gap[Gap_columns[0]] != 0).any():  # Check for non-zero CD4 gaps\n",
    "                report_description = (  # Add description for CD4 gap\n",
    "                    f\"Report Name: {Gap_columns[0]}\\n\"  # Gap column name\n",
    "                    f\"{HTS_CD4_columns_spec[2]}\\nshould be equal to {HTS_CD4_columns_spec[3]}\\n\"  # New positives vs. total CD4 tested\n",
    "                    f\"Note: Where this CD4 gap is true, please ignore the outlier.\"  # Instruction to ignore outlier\n",
    "                )  \n",
    "\n",
    "            # -- Step 14: Export results\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=HTS_CD4_columns_spec,  # Italicize specific summary columns\n",
    "                    doc_indicators_to_underline=Gap_columns,  # Underline gap column\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 15: Cache overall unfiltered DataFrame shape\n",
    "        process_HTS_CD4_gap.cached_shape = df_HTS_CD4.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HTS_CD4_gap, 'cached_styles'):  # Check for cached styles dictionary\n",
    "            process_HTS_CD4_gap.cached_styles.clear()  # Clear cached styles\n",
    "        if hasattr(process_HTS_CD4_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HTS_CD4_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## - HIVST MSF\n",
    "### - HIVST Distribution Mode gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Distribution Mode gap\n",
    "def process_HIVST_Distr_Mode_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Distribution Mode gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST distribution by mode\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By)\",  # Assisted distribution by specific recipients\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By)\"  # Unassisted distribution by specific recipients\n",
    "        ]  # Defines primary HIVST distribution columns\n",
    "        df_columns_spec = [  # Specific column names for summary and comparison\n",
    "            \"Number of individual HIVST kits distributed - Assisted\",  # Total assisted distribution\n",
    "            \"Number of individual HIVST kits distributed - Uassisted\",  # Total unassisted distribution\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By - Self, Spouse, Sexual Partner, Children, Social Network, Other)\",  # Assisted distribution by recipients\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By - Self, Spouse, Sexual Partner, Children, Social Network, Other)\"  # Unassisted distribution by recipients\n",
    "        ]  # Defines columns for gap calculation and reporting\n",
    "        columns_to_keep = MSF_hierarchy + [\"Assisted\", \"Unassisted\"]  # Columns to retain from HIVST approach dataset\n",
    "        name = \"HIVST Distribution Mode Gap\"  # Base name for the report\n",
    "        gap_columns = [\"Assisted distribution mode gap\", \"Uassisted distribution mode gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}18\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_HIVST_Distri_Mode = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST distribution columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Distri_Mode is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_HIVST_Mode_extra = prepare_and_convert_df(  # Fetch and prepare DataFrame for HIVST approach\n",
    "            DHIS2_data_key=\"HTS MSF_hivst_approach\",  # Key to fetch HIVST approach dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=[\"Assisted\", \"Unassisted\"]  # Include total assisted and unassisted columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Mode_extra is None:  # Check if extra data preparation failed or returned empty\n",
    "            return  # Exit function if no valid extra data\n",
    "\n",
    "        df_HIVST_Mode_extra = df_HIVST_Mode_extra[columns_to_keep]  # Subset to retain only hierarchy and total assisted/unassisted columns\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Mode_extra.merge(  # Merge extra HIVST mode data with primary distribution data\n",
    "            df_HIVST_Distri_Mode,  # Target DataFrame for merge\n",
    "            on=MSF_hierarchy,  # Merge on hierarchy columns\n",
    "            how=\"right\"  # Right join to keep all rows from primary distribution data\n",
    "        )  # Updates DataFrame with merged data\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode.rename(columns={\n",
    "            \"Assisted\": f\"{df_columns_spec[0]}\",  # Rename to total assisted distribution\n",
    "            \"Unassisted\": f\"{df_columns_spec[1]}\",  # Rename to total unassisted distribution\n",
    "            \"Number of individual HIVST kits distributed - Assisted (Distribution By)\": f\"{df_columns_spec[2]}\",  # Rename to assisted by recipients\n",
    "            \"Number of individual HIVST kits distributed - Uassisted (Distribution By)\": f\"{df_columns_spec[3]}\"  # Rename to unassisted by recipients\n",
    "        })  # Updates column names to align with specified naming\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_HIVST_Distri_Mode.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns and reset index\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_HIVST_Distri_Mode.select_dtypes(include=['float64', 'float32']).columns  # Identify columns with float data types\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_HIVST_Distri_Mode[col] = df_HIVST_Distri_Mode[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_HIVST_Distri_Mode[gap_columns[0]] = np.where(  # Calculate gap for assisted distribution (requires numpy as np)\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[2]] != df_HIVST_Distri_Mode[df_columns_spec[0]],  # Check if assisted by recipients differs from total assisted\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[2]] - df_HIVST_Distri_Mode[df_columns_spec[0]],  # Compute gap (by recipients - total)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for assisted distribution\n",
    "        df_HIVST_Distri_Mode[gap_columns[1]] = np.where(  # Calculate gap for unassisted distribution\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[3]] != df_HIVST_Distri_Mode[df_columns_spec[1]],  # Check if unassisted by recipients differs from total unassisted\n",
    "            df_HIVST_Distri_Mode[df_columns_spec[3]] - df_HIVST_Distri_Mode[df_columns_spec[1]],  # Compute gap (by recipients - total)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for unassisted distribution\n",
    "\n",
    "        # -- Step 8: Reorder columns for output\n",
    "        reorder_columns = MSF_hierarchy + [\n",
    "            df_columns_spec[0], df_columns_spec[2], gap_columns[0], \n",
    "            df_columns_spec[1], df_columns_spec[3], gap_columns[1]\n",
    "        ]  # Define column order: hierarchy, assisted pair, assisted gap, unassisted pair, unassisted gap\n",
    "        df_HIVST_Distri_Mode = df_HIVST_Distri_Mode[reorder_columns]  # Reorder DataFrame columns for consistent output\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Distri_Mode)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Distr_Mode_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Distri_Mode.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Distr_Mode_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)   \n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_HIVST_Distri_Mode_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Distri_Mode,  # Input DataFrame with gaps\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Distri_Mode_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Distr_Mode_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Distr_Mode_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Distr_Mode_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_HIVST_Distri_Mode_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Distri_Mode_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_HIVST_Distr_Mode_gap.cached_style = df_HIVST_Distri_Mode_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Distr_Mode_gap.cached_shape = df_HIVST_Distri_Mode.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_HIVST_Distri_Mode_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_HIVST_Distri_Mode_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero assisted distribution gaps\n",
    "            report_description.append(  # Add description for assisted gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"  # Assisted gap column name\n",
    "                f\"{df_columns_spec[1]}\\n\"  # Total unassisted (incorrect reference, preserved as-is)\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Total assisted\n",
    "            )  # Append description to list\n",
    "        if (df_HIVST_Distri_Mode_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero unassisted distribution gaps\n",
    "            report_description.append(  # Add description for unassisted gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"  # Unassisted gap column name\n",
    "                f\"{df_columns_spec[3]}\\n\"  # Unassisted by recipients\n",
    "                f\"should be equal to {df_columns_spec[1]}\"  # Total unassisted\n",
    "            )  # Append description to list\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Distri_Mode_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize specified summary columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_HIVST_Distri_Mode_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Distr_Mode_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Distr_Mode_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Distr_Mode_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HIVST_Distr_Mode_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HIVST Testing Frequency gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Testing Frequency gap\n",
    "def process_HIVST_Test_Freq_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Testing Frequency gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST testing frequency metrics\n",
    "            \"Number of individual HIVST kits distributed (Directly Assisted & Unassisted)\",  # Total kits distributed\n",
    "            \"Number of individual HIVST kits distributed (Testing Frequency)\"  # Kits by testing frequency\n",
    "        ]  # Defines columns for HIVST testing frequency gap analysis\n",
    "        name = \"HIVST Testing Frequency Gap\"  # Base name for the report\n",
    "        gap_columns = [\"HIVST Testing Frequency gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}19\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Test_Freq = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST testing frequency columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Test_Freq is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate HIVST testing frequency gap\n",
    "        df_HIVST_Test_Freq[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_HIVST_Test_Freq[df_columns[1]] > df_HIVST_Test_Freq[df_columns[0]],  # Check if testing frequency exceeds total distributed\n",
    "            df_HIVST_Test_Freq[df_columns[1]] - df_HIVST_Test_Freq[df_columns[0]],  # Compute gap (frequency - total)\n",
    "            0  # Set to 0 if no gap (frequency not greater than total)\n",
    "        )  # Adds gap column for testing frequency\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Test_Freq)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Test_Freq_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Test_Freq.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Test_Freq_gap.cached_style # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_HIVST_Test_Freq_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Test_Freq,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Test_Freq_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Test_Freq_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Test_Freq_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Test_Freq_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_HIVST_Test_Freq_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Test_Freq_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_HIVST_Test_Freq_gap.cached_style = df_HIVST_Test_Freq_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Test_Freq_gap.cached_shape = df_HIVST_Test_Freq.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_HIVST_Test_Freq_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_HIVST_Test_Freq_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero testing frequency gaps\n",
    "            report_description = (  # Create description for testing frequency gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{df_columns[1]}\\n\"  # Testing frequency\n",
    "                f\"should be equal to {df_columns[0]}\"  # Total distributed\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Test_Freq_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            widget_display_df(df_HIVST_Test_Freq_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Test_Freq_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Test_Freq_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Test_Freq_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HIVST_Test_Freq_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HIVST Result gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Result gap\n",
    "def process_HIVST_Result_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Result gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST result metrics\n",
    "            \"Number of individual HIVST kits distributed (Directly Assisted & Unassisted)\",  # Total kits distributed\n",
    "            \"Number of individual reporting HIVST results\"  # Kits with reported results\n",
    "        ]  # Defines columns for HIVST result gap analysis\n",
    "        name = \"HIVST Result Gap\"  # Base name for the report\n",
    "        gap_columns = [\"HIVST Result gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}20\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Result = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST result columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Result is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate HIVST result gap\n",
    "        df_HIVST_Result[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_HIVST_Result[df_columns[1]] != df_HIVST_Result[df_columns[0]],  # Check if reported results differ from total distributed\n",
    "            df_HIVST_Result[df_columns[0]] - df_HIVST_Result[df_columns[1]],  # Compute gap (distributed - reported)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for HIVST results\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Result)  # Format DataFrame column headers (assumed function)\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Result_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Result.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Result_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_HIVST_Test_Freq_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Result,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Test_Freq_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Result_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Result_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Result_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_HIVST_Test_Freq_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Test_Freq_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_yellow, subset=gap_columns)  # Highlight non-zero gaps in yellow (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_HIVST_Result_gap.cached_style = df_HIVST_Test_Freq_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Result_gap.cached_shape = df_HIVST_Result.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_HIVST_Test_Freq_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_HIVST_Test_Freq_gap[gap_columns[0]] != 0).any():  # Check for non-zero result gaps\n",
    "            report_description = (  # Create description for result gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"  # Gap column name\n",
    "                f\"{df_columns[1]}\\n\"  # Reported results\n",
    "                f\"should be equal to {df_columns[0]}\"  # Total distributed\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"  # Instruction to review gap\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Test_Freq_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_HIVST_Test_Freq_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Result_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Result_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Result_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HIVST_Result_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HIVST Reactive Confirmation and Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Reactive and Linkage gap\n",
    "def process_HIVST_Reactive_Link_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Reactive and Linkaget gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST reactive and linkage metrics\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test (HTS)\",  # Referred for confirmatory test\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV positive test results.\",  # Confirmed positive\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV negative test results.\",  # Confirmed negative\n",
    "            \"Number of individuals with confirmed HIV-positive results who are successfully linked with HIV care and treatment\"  # Linked to care\n",
    "        ]  # Defines primary HIVST columns for gap analysis\n",
    "        df_columns_spec = [  # Specific column names for summary and reporting\n",
    "            \"Number of individual reporting HIVST results - Reactive\",  # Total reactive results\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test (HTS)\",  # Referred for confirmatory test\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV positive test results.\",  # Confirmed positive\n",
    "            \"Number of individuals reporting reactive HIVST results referred for confirmatory test(HTS) who received HIV negative test results.\",  # Confirmed negative\n",
    "            \"Number of individuals with confirmed HIV-positive results who are successfully linked with HIV care and treatment\"  # Linked to care\n",
    "        ]  # Defines columns for gap calculation and documentation\n",
    "        df_columns2 = ['Reactive']  # Column for additional reactive data from second dataset\n",
    "        name = \"HIVST Reactive Linkage Gap\"  # Base name for the report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"HIVST reactive referral for confirmatory gap\", \n",
    "            \"HIVST confirmatory test result gap\",\n",
    "            \"HIVST confirmed positive linkage gap\"\n",
    "        ]  # Defines gap column names\n",
    "        report_name = f\"{name}21\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Reactive_Link = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST reactive and linkage columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Reactive_Link is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_main2 = prepare_and_convert_df(  # Fetch and prepare DataFrame for HIVST response classification\n",
    "            DHIS2_data_key=\"HTS MSF_hivst_response_classification\",  # Key to fetch HIVST response dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=df_columns2  # Include reactive column\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main2 is None:  # Check if extra data preparation failed or returned empty\n",
    "            return  # Exit function if no valid extra data\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link.merge(  # Merge primary data with additional reactive data\n",
    "            df_main2,  # Target DataFrame for merge\n",
    "            on=MSF_hierarchy,  # Merge on hierarchy columns\n",
    "            how=\"left\"  # Left join to keep all rows from primary data\n",
    "        )  # Updates DataFrame with merged data\n",
    "        \n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link.rename(columns={  # Rename columns to align with specified names\n",
    "            f\"{df_columns2[0]}\": f\"{df_columns_spec[0]}\"  # Rename 'Reactive' to total reactive results\n",
    "        })  # Updates column names in DataFrame\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_HIVST_Reactive_Link.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns and reset index\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_HIVST_Reactive_Link.select_dtypes(include=['float64', 'float32']).columns  # Identify columns with float data types\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_HIVST_Reactive_Link[col] = df_HIVST_Reactive_Link[col].astype(int)  # Convert float columns to integers\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link[MSF_hierarchy + df_columns_spec]  # Reorder DataFrame to include hierarchy and specified columns\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_HIVST_Reactive_Link[gap_columns[0]] = np.where(  # Calculate referral for confirmatory test gap (requires numpy as np)\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[1]] != df_HIVST_Reactive_Link[df_columns_spec[0]],  # Check if referred differs from total reactive\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[1]] - df_HIVST_Reactive_Link[df_columns_spec[0]],  # Compute gap (referred - reactive)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds referral gap column\n",
    "        df_HIVST_Reactive_Link[gap_columns[1]] = np.where(  # Calculate confirmatory test result gap\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[2:4]].sum(axis=1) != df_HIVST_Reactive_Link[df_columns_spec[1]],  # Check if sum of positive and negative results differs from referred\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[2:4]].sum(axis=1) - df_HIVST_Reactive_Link[df_columns_spec[1]],  # Compute gap (results sum - referred)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds confirmatory test gap column\n",
    "        df_HIVST_Reactive_Link[gap_columns[2]] = np.where(  # Calculate confirmed positive linkage gap\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[2]] != df_HIVST_Reactive_Link[df_columns_spec[4]],  # Check if linked differs from confirmed positive\n",
    "            df_HIVST_Reactive_Link[df_columns_spec[4]] - df_HIVST_Reactive_Link[df_columns_spec[2]],  # Compute gap (linked - confirmed positive)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds linkage gap column\n",
    "\n",
    "        # -- Step 8: Reorder columns for output\n",
    "        reorder_columns = MSF_hierarchy + [  # Define column order: hierarchy, reactive pair, referral gap, test results pair, test gap, linkage pair\n",
    "            df_columns_spec[0], df_columns_spec[1], gap_columns[0], \n",
    "            df_columns_spec[2], df_columns_spec[3], gap_columns[1],\n",
    "            df_columns_spec[4], gap_columns[2]\n",
    "        ]  # Specifies ordered columns for DataFrame\n",
    "        df_HIVST_Reactive_Link = df_HIVST_Reactive_Link[reorder_columns]  # Reorder DataFrame columns for consistent output\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Reactive_Link)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Reactive_Link_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Reactive_Link.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Reactive_Link_gap.cached_style # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_HIVST_Reactive_Link_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Reactive_Link,  # Input DataFrame with gaps\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Reactive_Link_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Reactive_Link_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Reactive_Link_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Reactive_Link_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 12: Style the DataFrame\n",
    "        df_HIVST_Reactive_Link_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Reactive_Link_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_HIVST_Reactive_Link_gap.cached_style = df_HIVST_Reactive_Link_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Reactive_Link_gap.cached_shape = df_HIVST_Reactive_Link.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 14: Define export variables\n",
    "        report_month = df_HIVST_Reactive_Link_gap['ReportPeriod'].iloc[0]  # Extract report month from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns[0]] != 0).any():  # Check for non-zero referral gaps\n",
    "            report_description.append(  # Add description for referral gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"\n",
    "            )  # Append description to list\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero confirmatory test gaps\n",
    "            report_description.append(  # Add description for confirmatory test gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\nplus {df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[1]}\"\n",
    "            )  # Append description to list\n",
    "        if (df_HIVST_Reactive_Link_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero linkage gaps\n",
    "            report_description.append(  # Add description for linkage gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns_spec[4]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[2]}\"\n",
    "            )  # Append description to list\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 16: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Reactive_Link_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize specified summary columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 17: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)   # Print display name with separators\n",
    "            widget_display_df(df_HIVST_Reactive_Link_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Reactive_Link_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Reactive_Link_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Reactive_Link_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HIVST_Reactive_Link_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HIVST Prevention Service gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Prevention Service gap\n",
    "def process_HIVST_Prevention_Serv_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Prevention Service gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST prevention service metrics\n",
    "            \"Number of individual reporting HIVST results\",  # Total individuals reporting HIVST results\n",
    "            \"Number of individuals reporting non reactive HIVST results that referred prevention services.\",  # Referred to prevention services\n",
    "            \"Number of individuals reporting non reactive HIVST results that accessed prevention services\"  # Accessed prevention services\n",
    "        ]  # Defines columns for HIVST prevention service gap analysis\n",
    "        name = \"HIVST Prevention Service Gap\"  # Base name for the report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"HIVST non-reactive referral for prevention services gap\", \n",
    "            \"HIVST non-reactive client that accessed for prevention services gap\"\n",
    "        ]  # Defines gap column names\n",
    "        report_name = f\"{name}22\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Prevention_Serv = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST prevention service columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Prevention_Serv is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_HIVST_Prevention_Serv[gap_columns[0]] = np.where(  # Calculate referral for prevention services gap (requires numpy as np)\n",
    "            df_HIVST_Prevention_Serv[df_columns[1]] > df_HIVST_Prevention_Serv[df_columns[0]],  # Check if referred exceeds total reporting\n",
    "            df_HIVST_Prevention_Serv[df_columns[1]] - df_HIVST_Prevention_Serv[df_columns[0]],  # Compute gap (referred - total reporting)\n",
    "            0  # Set to 0 if no gap (referred not greater than total)\n",
    "        )  # Adds referral gap column\n",
    "        df_HIVST_Prevention_Serv[gap_columns[1]] = np.where(  # Calculate access to prevention services gap\n",
    "            df_HIVST_Prevention_Serv[df_columns[2]] != df_HIVST_Prevention_Serv[df_columns[1]],  # Check if accessed differs from referred\n",
    "            df_HIVST_Prevention_Serv[df_columns[2]] - df_HIVST_Prevention_Serv[df_columns[1]],  # Compute gap (accessed - referred)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds access gap column\n",
    "\n",
    "        # -- Step 4: Reorder columns for output\n",
    "        reorder_columns = MSF_hierarchy + [  # Define column order: hierarchy, total reporting, referred, referral gap, accessed, access gap\n",
    "            df_columns[0], df_columns[1], gap_columns[0], \n",
    "            df_columns[2], gap_columns[1]\n",
    "        ]  # Specifies ordered columns for DataFrame\n",
    "        df_HIVST_Prevention_Serv = df_HIVST_Prevention_Serv[reorder_columns]  # Reorder DataFrame columns for consistent output\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Prevention_Serv)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Prevention_Serv_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Prevention_Serv.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Prevention_Serv_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 7: Filter and validate gaps\n",
    "        df_HIVST_Prevention_Serv_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Prevention_Serv,  # Input DataFrame with gaps\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Prevention_Serv_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Prevention_Serv_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Prevention_Serv_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 8: Style the DataFrame\n",
    "        df_HIVST_Prevention_Serv_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Prevention_Serv_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap[0])  # Highlight first gap (referral) in red (assumed function)\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap[1])  # Highlight second gap (access) in yellow (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 9: Cache styled DataFrame and shape\n",
    "        process_HIVST_Prevention_Serv_gap.cached_style = df_HIVST_Prevention_Serv_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Prevention_Serv_gap.cached_shape = df_HIVST_Prevention_Serv.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 10: Define export variables\n",
    "        report_month = df_HIVST_Prevention_Serv_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 11: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_HIVST_Prevention_Serv_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero referral gaps\n",
    "            report_description.append(  # Add description for referral gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be too greater than {df_columns[0]}\"  # Add description for referral gap\n",
    "            )  # Append description to list\n",
    "        if (df_HIVST_Prevention_Serv_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero access gaps\n",
    "            report_description.append(  # Add description for access gap\n",
    "                f\"Report Name: {gap_columns[0]} \\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[1]}\"  # Report description for access gap\n",
    "                f\"Note: Access gap should be reviewed.\"\n",
    "            )  # Append description to list\n",
    "        report_description = \"\\n\\n\".join(report_description)  # -- Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 12: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Prevention_Serv_gap_style, # -- Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # -- Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # -- Italicize specified columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # # -- Excel file path\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 13: Optionally display styled DataFrame\n",
    "        if display_output:  # -- Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_HIVST_Prevention_Serv_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # -- Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Prevention_Serv_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Prevention_Serv_gap, 'cached_shape'):  # -- Check for cached shape\n",
    "            del process_HIVST_Prevention_Serv_gap.cached_shape  # -- Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - HIVST Partner Screening gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process HIVST Partner Screening gap\n",
    "def process_HIVST_Partner_Screening_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process HIVST Partner Screening  gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for HIVST partner screening metrics\n",
    "            \"Number of partners of people living with HIV screened with HIVST kit (confirmed during follow up)\",  # Partners screened\n",
    "            \"Number of partners of people living with HIV reporting HIVST results\"  # Partners reporting results\n",
    "        ]  # Defines columns for HIVST partner screening gap analysis\n",
    "        name = \"HIVST Partner Screening Gap\"  # Base name for the report\n",
    "        gap_columns = [\"HIVST partner screening gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}22\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_HIVST_Partner_Screening = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include HIVST partner screening columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_HIVST_Partner_Screening is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate HIVST partner screening gap\n",
    "        df_HIVST_Partner_Screening[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_HIVST_Partner_Screening[df_columns[1]] != df_HIVST_Partner_Screening[df_columns[0]],  # Check if reported results differ from screened partners\n",
    "            df_HIVST_Partner_Screening[df_columns[1]] - df_HIVST_Partner_Screening[df_columns[0]],  # Compute gap (reported - screened)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for partner screening\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_HIVST_Partner_Screening)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_HIVST_Partner_Screening_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_HIVST_Partner_Screening.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_HIVST_Partner_Screening_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing  \n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_HIVST_Partner_Screening_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_HIVST_Partner_Screening,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_HIVST_Partner_Screening_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_HIVST_Partner_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_HIVST_Partner_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_HIVST_Partner_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_HIVST_Partner_Screening_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_HIVST_Partner_Screening_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight gap in yellow (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_HIVST_Partner_Screening_gap.cached_style = df_HIVST_Partner_Screening_gap_style  # Store styled DataFrame\n",
    "        process_HIVST_Partner_Screening_gap.cached_shape = df_HIVST_Partner_Screening.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_HIVST_Partner_Screening_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_HIVST_Partner_Screening_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero screening gaps\n",
    "            report_description = (  # Create description for screening gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_HIVST_Partner_Screening_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_HIVST_Partner_Screening_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_HIVST_Partner_Screening_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_HIVST_Partner_Screening_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_HIVST_Partner_Screening_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_HIVST_Partner_Screening_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## ICT MSF\n",
    "### - ICT Offering gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ICT Index Acceptance gap\n",
    "def process_ICT_Index_Acceptance_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ICT Index Acceptance  gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for ICT index acceptance metrics\n",
    "            \"Number of HIV Positive Clients Offered Index Testing\",  # Clients offered index testing\n",
    "            \"Number of HIV Positive Clients Accepting Index Testing\"  # Clients accepting index testing\n",
    "        ]  # Defines columns for ICT index acceptance gap analysis\n",
    "        name = \"ICT Index Acceptance Gap\"  # Base name for the report\n",
    "        gap_columns = [\"ICT index acceptance gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}24\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "        \n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include ICT index acceptance columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate ICT index acceptance gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if acceptances exceed offers\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Compute gap (acceptances - offers)\n",
    "            0  # Set to 0 if no gap (acceptances not greater than offers)\n",
    "        )  # Adds gap column for index acceptance\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Index_Acceptance_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ICT_Index_Acceptance_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_mine_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ICT_Index_Acceptance_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ICT_Index_Acceptance_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ICT_Index_Acceptance_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_mine_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_ICT_Index_Acceptance_gap.cached_style = df_mine_gap_style  # Store styled DataFrame\n",
    "        process_ICT_Index_Acceptance_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero acceptance gaps\n",
    "            report_description = (  # Create description for acceptance gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_mine_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_mine_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ICT_Index_Acceptance_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_ICT_Index_Acceptance_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_ICT_Index_Acceptance_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ICT_Index_Acceptance_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## ICT MSF\n",
    "### - ICT Contact gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ICT Contact gap\n",
    "def process_ICT_Contact_gap(display_output=None):  # Function to process ICT Contact gaps\n",
    "    \"\"\"\n",
    "    Process ICT Contact gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for ICT contact metrics\n",
    "            \"Number of HIV Positive Clients Accepting Index Testing\",  # Clients accepting index testing\n",
    "            \"Number of Children enumerated and Partners elicited from index client\"  # Contacts enumerated\n",
    "        ]  # Defines columns for ICT contact gap analysis\n",
    "        name = \"ICT Contact Gap\"  # Base name for the report\n",
    "        gap_columns = [\"ICT contact gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}25\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include ICT contact columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate ICT contact gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] < df_main[df_columns[0]],  # Check if enumerated contacts are less than clients accepting index testing\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Compute gap (contacts - acceptances)\n",
    "            0  # Set to 0 if no gap (contacts not less than acceptances)\n",
    "        )  # Adds gap column for ICT contacts\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Contact_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ICT_Contact_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_mine_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ICT_Contact_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ICT_Contact_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ICT_Contact_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_mine_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight gap in yellow (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_ICT_Contact_gap.cached_style = df_mine_gap_style  # Store styled DataFrame\n",
    "        process_ICT_Contact_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero contact gaps\n",
    "            report_description = (  # Create description for contact gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be greater than {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_mine_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_mine_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ICT_Contact_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_ICT_Contact_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_ICT_Contact_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ICT_Contact_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ICT HTS gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ICT HTS gap\n",
    "def process_ICT_HTS_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ICT HTS gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for ICT HTS metrics\n",
    "            \"Number of Children enumerated and Partners elicited from index client\",  # Enumerated contacts\n",
    "            \"Number of contacts of index clients tested HIV Positive\",  # Contacts tested positive\n",
    "            \"Number of contacts of index clients tested HIV Negative\"  # Contacts tested negative\n",
    "        ]  # Defines columns for ICT HTS gap analysis\n",
    "        name = \"ICT Contact Testing Gap\"  # Base name for the report\n",
    "        gap_columns = [\"ICT contact testing gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}26\"  # Report name with unique suffix\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include ICT HTS columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Clean and convert data types\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        # Explicitly convert relevant columns to numeric, coercing errors to 0\n",
    "        for col in df_columns:  # Iterate over data columns\n",
    "            df_main[col] = pd.to_numeric(df_main[col], errors='coerce').fillna(0).astype(int)  # Convert to numeric, handle errors, and cast to integer\n",
    "\n",
    "        # -- Step 4: Calculate ICT HTS gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_main[df_columns[1:3]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of tested (positive + negative) differs from enumerated contacts\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Compute gap (tested sum - enumerated)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        ).astype(int)  # Ensure gap column is integer type\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ICT_HTS_gap, 'cached_styles'):  # Check if cached styles dictionary exists\n",
    "                cached_shape = getattr(process_ICT_HTS_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_ICT_HTS_gap.cached_styles.items():  # Iterate over cached cluster styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 7: Initialize cache\n",
    "        if not hasattr(process_ICT_HTS_gap, 'cached_styles'):  # Check if cache dictionary is not initialized\n",
    "            process_ICT_HTS_gap.cached_styles = {}  # Initialize empty dictionary for caching styled DataFrames\n",
    "\n",
    "        # -- Step 8: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_main['Cluster'].unique())  # Extract unique cluster values from DataFrame (requires pandas as pd)\n",
    "\n",
    "        # -- Step 9: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_main[df_main['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            ICT_HTS_msg = f\"No {current_cluster} {report_name}\"  # Define message for no gaps in current cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for current cluster\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length\n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "                df=cluster_filtered,  # Input cluster-specific DataFrame\n",
    "                msg=ICT_HTS_msg,  # Message to display if no gaps\n",
    "                opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found for cluster\n",
    "                if current_cluster in process_ICT_HTS_gap.cached_styles:  # Check if cluster is in cache\n",
    "                    del process_ICT_HTS_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered cluster DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight gap in yellow (assumed function)\n",
    "            )  # Creates styled DataFrame for cluster\n",
    "\n",
    "            process_ICT_HTS_gap.cached_styles[current_cluster] = cluster_filtered_style  # Store styled DataFrame in cache for cluster\n",
    "\n",
    "            # -- Step 10: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month and cluster\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 11: Create descriptions\n",
    "            report_description = []  # Initialize empty list for descriptions\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero testing gaps\n",
    "                report_description.append(  # Add description for testing gap\n",
    "                    f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                    f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"  # Describe expected equality\n",
    "                    f\"should be equal to {df_columns[0]}\\n\"\n",
    "                    f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "                )  # Append description to list\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 12: Export results\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                    doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame for cluster (assumed widget function)\n",
    "\n",
    "        # -- Step 13: Cache overall unfiltered DataFrame shape\n",
    "        process_ICT_HTS_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦔ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ICT_HTS_gap, 'cached_styles'):  # Check for cached styles dictionary\n",
    "            process_ICT_HTS_gap.cached_styles.clear()  # Clear all cached styles\n",
    "        if hasattr(process_ICT_HTS_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ICT_HTS_gap.cached_shape  # -- Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - ICT Positive Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process ICT Positive Linkage gap\n",
    "def process_ICT_Positive_Link_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process ICT Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for ICT Positive Linkage metrics\n",
    "            \"Number of contacts of index clients tested HIV Positive\",  # Contacts tested positive\n",
    "            \"Number of contacts of index clients linked to ART\"  # Contacts linked to ART\n",
    "        ]  # Defines columns for ICT linkage gap analysis\n",
    "        name = \"ICT Contact Testing Gap\"  # Base name for report (misnamed, preserved as-is)\n",
    "        gap_columns = [\"ICT contact testing gap\"]  # Name for the calculated gap column (misnamed, preserved as-is)\n",
    "        report_name = f\"{name}27\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Prepare data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"HTS MSF\",  # Key to fetch HTS MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include ICT linkage columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate ICT Positive Linkage gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if linked contacts differ from tested positive\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Compute gap (linked - tested positive)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds linkage gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_ICT_Positive_Link_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_ICT_Positive_Link_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_mine_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_mine_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_ICT_Positive_Link_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_ICT_Positive_Link_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_ICT_Positive_Link_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the DataFrame\n",
    "        df_mine_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_mine_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_ICT_Positive_Link_gap.cached_style = df_mine_gap_style  # Store styled DataFrame\n",
    "        process_ICT_Positive_Link_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Define export variables\n",
    "        report_month = df_mine_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_mine_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero linkage gaps\n",
    "            report_description = (  # Create description for linkage gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"\n",
    "                f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_mine_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Optionally display styled DataFrame\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_mine_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_ICT_Positive_Link_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_ICT_Positive_Link_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_ICT_Positive_Link_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_ICT_Positive_Link_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## PMCTC MSF\n",
    "### - PMTCT New ANC Testing gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT New ANC HTS gap\n",
    "def process_PMTCT_ANC_Optmz_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT New ANC HTS gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of primary column names for PMTCT ANC metrics\n",
    "            \"Number of new ANC Clients\",  # New ANC clients\n",
    "            \"Number of pregnant women with previously known HIV positive infection\"  # Known HIV positives\n",
    "        ]  # Defines primary columns for initial data fetch\n",
    "        df_columns_spec = [  # Comprehensive list of all relevant columns\n",
    "            'Number of new ANC Clients',  # New ANC clients\n",
    "            'Number of pregnant women with previously known HIV positive infection',  # Known HIV positives\n",
    "            'Number of pregnant women HIV tested and received results (ANC)',  # Tested at ANC\n",
    "            'Number of pregnant women HIV tested and received results (L&D)',  # Tested at Labor & Delivery\n",
    "            'Number of pregnant women HIV tested and received results (<72hrs Post Partum)'  # Tested <72hrs postpartum\n",
    "        ]  # Defines all columns for analysis and reporting\n",
    "        df_columns2 = ['ANC', 'L&D', '<72hrs Post Partum']  # Service delivery point columns from secondary dataset\n",
    "        name = \"PMTCT New ANC HTS Optimization Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT new ANC HTS gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}28\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include primary PMTCT ANC columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_main2 = prepare_and_convert_df(  # Fetch and prepare secondary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp\",  # Key to fetch PMTCT MSF service delivery point dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=df_columns2  # Include service delivery point columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main2 is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_main = df_main.merge(  # Merge primary and secondary DataFrames\n",
    "            df_main2,  # Secondary DataFrame with service delivery point data\n",
    "            on=MSF_hierarchy,  # Merge on MSF hierarchy columns\n",
    "            how=\"left\"  # Left join to keep all rows from primary data\n",
    "        )  # Updates df_main with merged data\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_main = df_main.rename(columns={  # Rename service delivery point columns to match df_columns_spec\n",
    "            f\"{df_columns2[0]}\": f\"{df_columns_spec[2]}\",  # Rename ANC to ANC tested results\n",
    "            f\"{df_columns2[1]}\": f\"{df_columns_spec[3]}\",  # Rename L&D to L&D tested results\n",
    "            f\"{df_columns2[2]}\": f\"{df_columns_spec[4]}\"  # Rename <72hrs Post Partum to postpartum tested results\n",
    "        })  # Apply renamed columns to DataFrame\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_main.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort DataFrame by hierarchy columns\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # Identify float-type columns\n",
    "        for col in float_columns:  # Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)  # Apply integer conversion\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT ANC HTS gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[1:3]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of known positives and ANC tested differs from new ANC clients\n",
    "            df_main[df_columns_spec[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Compute gap (sum - new ANC clients)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for PMTCT ANC HTS\n",
    "\n",
    "        # -- Step 8: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 9: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_ANC_Optmz_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 10: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_ANC_Optmz_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_ANC_Optmz_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 11: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 12: Cache styled DataFrame and shape\n",
    "        process_PMTCT_ANC_Optmz_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_ANC_Optmz_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 13: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 14: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Create description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\npluse {df_columns_spec[2]}\\n\"  # Describe expected equality (typo preserved)\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Specify expected relationship\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 15: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize specific columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 16: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_ANC_Optmz_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_ANC_Optmz_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_ANC_Optmz_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Positive gap\n",
    "def process_PMTCT_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Positive metrics\n",
    "            \"Number of pregnant women HIV tested and received results (ANC)\",  # Tested at ANC\n",
    "            \"Number of pregnant women HIV tested and received results (L&D)\",  # Tested at Labor & Delivery\n",
    "            \"Number of pregnant women HIV tested and received results (<72hrs Post Partum)\",  # Tested <72hrs postpartum\n",
    "            \"Number of pregnant women tested HIV positive (ANC)\",  # HIV positive at ANC\n",
    "            \"Number of pregnant women tested HIV positive (L&D)\",  # HIV positive at Labor & Delivery\n",
    "            \"Number of pregnant women tested HIV positive (<72hrs Post Partum)\"  # HIV positive <72hrs postpartum\n",
    "        ]  # Defines columns for PMTCT positive gap analysis\n",
    "        df_columns2 = ['ANC', 'L&D', '<72hrs Post Partum']  # Service delivery point columns from datasets\n",
    "        name = \"PMTCT Positive Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"PMTCT positive (ANC) gap\",  # ANC positive gap\n",
    "            \"PMTCT positive (L&D) gap\",  # L&D positive gap\n",
    "            \"PMTCT positive (<72hrs Post Partum) gap\"  # <72hrs Post Partum positive gap\n",
    "        ]  # Defines gap columns\n",
    "        report_name = f\"{name}29\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp\",  # Key to fetch PMTCT MSF service delivery point dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns2  # Include service delivery point columns for tested results\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Fetch and prepare additional HIVST mode data\n",
    "        df_main2 = prepare_and_convert_df(  # Fetch and prepare secondary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF_sdp_pos\",  # Key to fetch PMTCT MSF positive results dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=df_columns2  # Include service delivery point columns for positive results\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main2 is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 4: Merge datasets\n",
    "        df_main = df_main.merge(  # Merge primary and secondary DataFrames\n",
    "            df_main2,  # Secondary DataFrame with positive results\n",
    "            on=MSF_hierarchy,  # Merge on MSF hierarchy columns\n",
    "            how=\"left\"  # Left join to keep all rows from primary DataFrame\n",
    "        )  # Updates df_main with merged data\n",
    "\n",
    "        # -- Step 5: Rename columns for consistency\n",
    "        df_main = df_main.rename(columns={  # Rename merged columns to match df_columns\n",
    "            f'ANC_x': f\"{df_columns[0]}\",  # Rename ANC tested to ANC tested results\n",
    "            'L&D_x': f\"{df_columns[1]}\",  # Rename L&D tested to L&D tested results\n",
    "            '<72hrs Post Partum_x': f\"{df_columns[2]}\",  # Rename <72hrs Post Partum to postpartum tested\n",
    "            'ANC_y': f\"{df_columns[3]}\",  # Rename ANC positives to ANC positive results\n",
    "            'L&D_y': f\"{df_columns[4]}\",  # Rename L&D positives to L&D positive results\n",
    "            '<72hrs Post Partum_y': f\"{df_columns[5]}\"  # Rename <72hrs Post Partum to postpartum positive\n",
    "        })  # Apply renamed columns to DataFrame\n",
    "\n",
    "        # -- Step 6: Clean and format data\n",
    "        df_main.sort_values(by=MSF_hierarchy, inplace=True, ignore_index=True)  # Sort by hierarchy columns\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64']).columns  # Identify float-type columns\n",
    "        for col in float_columns:  # Convert float columns to integers\n",
    "            df_main[col] = df_main[col].astype(int)  # Apply integer conversion\n",
    "\n",
    "        # -- Step 7: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate ANC positive gap (requires numpy as np)\n",
    "            df_main[df_columns[3]] > df_main[df_columns[0]],  # Check if ANC positives exceed ANC tested\n",
    "            df_main[df_columns[3]] - df_main[df_columns[0]],  # Compute gap (positives - tested)\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds ANC positive gap column\n",
    "\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate L&D positive gap\n",
    "            df_main[df_columns[4]] > df_main[df_columns[1]],  # Check if L&D positives exceed L&D tested\n",
    "            df_main[df_columns[4]] - df_main[df_columns[1]],  # Compute gap (positives - tested)\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds L&D positive gap column\n",
    "\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate <72hrs Post Partum positive gap\n",
    "            df_main[df_columns[5]] > df_main[df_columns[2]],  # Check if postpartum positives exceed postpartum tested\n",
    "            df_main[df_columns[5]] - df_main[df_columns[2]],  # Compute gap (positives - tested)\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds <72hrs Post Partum positive gap column\n",
    "\n",
    "        # -- Step 8: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 9: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 10: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gaps\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 11: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 12: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 13: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 14: Create descriptions for Word document\n",
    "        report_description = []  # Initialize empty list for descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero ANC gaps\n",
    "            report_description.append(  # Add description for ANC gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected ANC constraint\n",
    "            )  # Append ANC description\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero L&D gaps\n",
    "            report_description.append(  # Add description for L&D gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[4]}\\n\"\n",
    "                f\"should not be greater than {df_columns[1]}\"  # Describe expected L&D constraint\n",
    "            )  # Append L&D description\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero <72hrs Post Partum gaps\n",
    "            report_description.append(  # Add description for postpartum gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns[5]}\\n\"\n",
    "                f\"should not be greater than {df_columns[2]}\"  # Describe expected postpartum constraint\n",
    "            )  # Append postpartum description\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 15: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 16: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Previously Known gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Previously Known gap\n",
    "def process_PMTCT_PK_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Previously Known gap, comparing known HIV-positive pregnant women\n",
    "    to those already on ART prior to pregnancy. Exports results as image, Excel, and\n",
    "    Word files. Caches the styled DataFrame and displays it on subsequent calls if\n",
    "    data shape is unchanged.\n",
    "\n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the DataFrame for gaps.\n",
    "            Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Previously Known metrics\n",
    "            \"Number of pregnant women with previously known HIV positive infection\",  # Known HIV positives\n",
    "            \"Number of HIV positive pregnant women already on ART prior to this pregnancy\"  # ART prior to pregnancy\n",
    "        ]  # Defines columns for PMTCT Previously Known gap analysis\n",
    "        name = \"PMTCT Previously Known Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT previously known gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}30\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Previously Known columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT Previously Known gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if ART counts differ from known positives\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Compute gap (ART - known positives)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for Previously Known\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_PK_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_PK_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_PK_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_PK_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_PK_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_PMTCT_PK_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_PK_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = \"\"  # Initialize empty description string\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero Previously Known gaps\n",
    "            report_description = (  # Create description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 13: Handle errors\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_PK_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_PK_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_PK_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_PK_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Positive Linkage gap\n",
    "def process_PMTCT_Positive_Linkage_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Positive Linkage gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Positive Linkage metrics\n",
    "            \"Number of pregnant women tested HIV positive\",  # Total HIV positives\n",
    "            \"Number of HIV positive pregnant women newly started on ART during ANC <36wks of pregnancy\",  # ART initiation ANC <36wks\n",
    "            \"Number of HIV positive pregnant women newly started on ART during ANC >36wks of pregnancy\",  # ART initiation ANC >36wks\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Labour\",  # ART initiation during Labour\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (<72 hrs)\",  # ART initiation Postpartum <72hrs\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (>72 hrs - < 6 months)\",  # ART initiation Postpartum >72hrs-<6 months\n",
    "            \"Number of HIV positive pregnant women newly started on ART during Post Partum (>6 - 12 months)\"  # ART initiation Postpartum >6-12 months\n",
    "        ]  # Defines columns for PMTCT Positive Linkage gap analysis\n",
    "        name = \"PMTCT Positive Linkage Known Gap\"  # Base name for report (misnamed, preserved as-is)\n",
    "        gap_columns = [\"PMTCT positive linkage gap\"]  # Name for the calculated gap column\n",
    "        report_name = f\"{name}31\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Positive Linkage columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT Positive Linkage gap (requires numpy as np)\n",
    "            df_main[df_columns[1:7]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of ART initiations differs from total positives\n",
    "            df_main[df_columns[1:7]].sum(axis=1) - df_main[df_columns[0]],  # Compute gap (ART sum - positives)\n",
    "            0  # Set to 0 if no gap (values equal)\n",
    "        )  # Adds gap column for Positive Linkage\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_Positive_Linkage_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap\n",
    "            msg=No_gap_msg,  # Message to display if no gaps are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_Positive_Linkage_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight gap in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Positive_Linkage_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_Positive_Linkage_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero Positive Linkage gaps\n",
    "            report_description = (  # Create description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\npluse {df_columns[2]}\\npluse {df_columns[3]}\\npluse {df_columns[4]}\"  # Describe ART initiation sum (typo preserved)\n",
    "                f\"\\npluse {df_columns[5]}\\npluse {df_columns[6]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Specify expected equality\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Positive_Linkage_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Seroconversion gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Seroconversion gap\n",
    "def process_PMTCT_Seroconversion_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Seroconversion gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Seroconversion metrics\n",
    "            \"Number of pregnant women retested after initial HIV negative test\",  # Women retested after initial negative\n",
    "            \"Number of pregnant women retested who seroconverted to HIV positive after initial HIV negative test\"  # Women who seroconverted\n",
    "        ]  # Defines columns for PMTCT Seroconversion analysis\n",
    "        name = \"PMTCT Seroconversion Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT seroconversion gap\"]  # Name for the calculated check column\n",
    "        report_name = f\"{name}32\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no seroconversions are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Seroconversion columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate seroconversion checks\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT Seroconversion check (requires numpy as np)\n",
    "            df_main[df_columns[1]] > 0,  # Check if any seroconversions occurred\n",
    "            df_main[df_columns[1]],  # Set check value to number of seroconversions\n",
    "            0  # Set to 0 if no seroconversions\n",
    "        )  # Adds seroconversion check column (flags positive values rather than a true gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column name for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_Seroconversion_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_Seroconversion_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate checks\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero seroconversion checks\n",
    "            df=df_main,  # Input DataFrame with check column\n",
    "            msg=No_gap_msg,  # Message to display if no seroconversions are found\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero check values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no seroconversions\n",
    "        if df_main_gap is None:  # Check if no seroconversions were found\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_Seroconversion_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_Seroconversion_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_Seroconversion_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no seroconversions\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight non-zero checks in yellow (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Seroconversion_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_Seroconversion_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero Seroconversion checks\n",
    "            report_description = (  # Create description for seroconversion\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"Note: {df_columns[1]} is a quality indicator and should be reviewed thoroughly.\"  # Highlight seroconversion as quality indicator\n",
    "            )  # Define Word document description\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline check column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 13: Handle errors\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Seroconversion_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_Seroconversion_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_Seroconversion_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Seroconversion_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Coinfection (syphilis) gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Syphilis Test gap\n",
    "def process_PMTCT_Syphilis_Test_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Syphilis Test gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Syphilis Test metrics\n",
    "            \"Number of new ANC Clients\",  # New ANC clients count\n",
    "            \"Number of new ANC Clients tested for syphilis - Total\",  # Clients tested for syphilis\n",
    "            \"Number of new ANC Clients tested positive for syphilis - Total\",  # Clients tested positive\n",
    "            \"Number of the ANC Clients treated for Syphilis - Total\"  # Clients treated for syphilis\n",
    "        ]  # Defines columns for PMTCT Syphilis Test analysis\n",
    "        name = \"PMTCT Syphilis Test Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT new ANC syphilis test gap\",  # Gap for testing vs. new clients\n",
    "                       \"PMTCT syphilis positive gap\",  # Gap for positives vs. tested\n",
    "                       \"PMTCT syphilis positive treatment gap\"]  # Gap for treated vs. positives\n",
    "        report_name = f\"{name}33\"  # Report name with unique suffix\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Syphilis Test columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT New ANC Syphilis Test gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if tested differs from new ANC clients\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds test gap column\n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PMTCT Syphilis Positive gap\n",
    "            df_main[df_columns[2]] > df_main[df_columns[1]],  # Check if positives exceed tested\n",
    "            df_main[df_columns[2]] - df_main[df_columns[1]],  # Calculate difference for gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds positive gap column\n",
    "        \n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate PMTCT Syphilis Positive Treatment gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[2]],  # Check if treated differs from positives\n",
    "            df_main[df_columns[3]] - df_main[df_columns[2]],  # Calculate difference for gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds treatment gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_styles'):  # Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_PMTCT_Syphilis_Test_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_PMTCT_Syphilis_Test_gap.cached_styles.items():  # Iterate over cached cluster styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display \n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Initialize cache\n",
    "        if not hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_PMTCT_Syphilis_Test_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 7: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_main['Cluster'].unique())  # Extract unique cluster names (requires pandas as pd)\n",
    "\n",
    "        # -- Step 8: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_main[df_main['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            PMTCT_Syphilis_msg = f\"No {current_cluster} {report_name}\"  # Message if no gaps found for cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with gaps\n",
    "                df=cluster_filtered,  # Input cluster-filtered DataFrame\n",
    "                msg=PMTCT_Syphilis_msg,  # Message to display if no gaps\n",
    "                opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found\n",
    "                if current_cluster in process_PMTCT_Syphilis_Test_gap.cached_styles:  # Check if cluster in cache\n",
    "                    del process_PMTCT_Syphilis_Test_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_yellow, subset=gap_columns_wrap[0])  # Highlight test gap in yellow (assumed function)\n",
    "                .map(outlier_red, subset=gap_columns_wrap[1:3])  # Highlight positive/treatment gaps in red\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_PMTCT_Syphilis_Test_gap.cached_styles[current_cluster] = cluster_filtered_style  # Cache styled DataFrame for cluster\n",
    "\n",
    "            # -- Step 9: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 10: Create descriptions for Word document\n",
    "            report_description = []  # Initialize list for report descriptions\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero test gaps\n",
    "                report_description.append(  # Add description for test gap\n",
    "                    f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                    f\"{df_columns[1]}\\n\"\n",
    "                    f\"should be equal to {df_columns[0]}\\n\"\n",
    "                    f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "                )  # Describe test gap issue\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero positive gaps\n",
    "                report_description.append(  # Add description for positive gap\n",
    "                    f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                    f\"{df_columns[2]}\\n\"\n",
    "                    f\"should not be greater than {df_columns[1]}\"\n",
    "                )  # Describe positive gap issue\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero treatment gaps\n",
    "                report_description.append(  # Add description for treatment gap\n",
    "                    f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                    f\"{df_columns[3]}\\n\"\n",
    "                    f\"should be equal to {df_columns[2]}\\n\"\n",
    "                    f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "                )  # Describe treatment gap issue\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 11: Export results to multiple formats\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                    doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 12: Cache overall unfiltered DataFrame shape\n",
    "        process_PMTCT_Syphilis_Test_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_PMTCT_Syphilis_Test_gap.cached_styles.clear()  # Clear cached styled DataFrames\n",
    "        if hasattr(process_PMTCT_Syphilis_Test_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Syphilis_Test_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Coinfection (HBV, HCV) gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Hepatitis Test gap\n",
    "def process_PMTCT_Hepatitis_Test_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Hepatitis Test gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Hepatitis Test metrics\n",
    "            \"Number of new ANC Clients\",  # New ANC clients count\n",
    "            \"Number of new ANC Clients tested for HBV ( ANC, L&D, <72hrs Post Partum)\",  # Clients tested for Hepatitis B\n",
    "            \"Number of new ANC Clients tested for HCV ( ANC, L&D, < 72hrs Post Partum)\"  # Clients tested for Hepatitis C\n",
    "        ]  # Defines columns for PMTCT Hepatitis Test analysis\n",
    "        name = \"PMTCT Hepatitis Test Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"PMTCT hepatitis B test gap\",  # Gap for HBV testing vs. new clients\n",
    "            \"PMTCT hepatitis C positive gap\"  # Gap for HCV testing vs. new clients\n",
    "        ]  # Defines gap column names\n",
    "        report_name = f\"{name}34\"  # Report name with unique suffix\n",
    "        \n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Hepatitis Test columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT Hepatitis B Test gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if HBV tested differs from new ANC clients\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for HBV gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds HBV test gap column\n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PMTCT Hepatitis C Test gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[0]],  # Check if HCV tested differs from new ANC clients\n",
    "            df_main[df_columns[2]] - df_main[df_columns[0]],  # Calculate difference for HCV gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds HCV test gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_styles'):  # Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_PMTCT_Hepatitis_Test_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_PMTCT_Hepatitis_Test_gap.cached_styles.items():  # Iterate over cached cluster styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Initialize cache\n",
    "        if not hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_PMTCT_Hepatitis_Test_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 7: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_main['Cluster'].unique())  # Extract unique cluster names (requires pandas as pd)\n",
    "\n",
    "        # -- Step 8: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_main[df_main['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            PMTCT_Hepatitis_msg = f\"No {current_cluster} {report_name}\"  # Message if no gaps found for cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with gaps\n",
    "                df=cluster_filtered,  # Input cluster-filtered DataFrame\n",
    "                msg=PMTCT_Hepatitis_msg,  # Message to display if no gaps\n",
    "                opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found\n",
    "                if current_cluster in process_PMTCT_Hepatitis_Test_gap.cached_styles:  # Check if cluster in cache\n",
    "                    del process_PMTCT_Hepatitis_Test_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight non-zero gaps in yellow (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_PMTCT_Hepatitis_Test_gap.cached_styles[current_cluster] = cluster_filtered_style  # Cache styled DataFrame for cluster\n",
    "\n",
    "            # -- Step 9: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 10: Create descriptions for Word document\n",
    "            report_description = []  # Initialize list for report descriptions\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero Hepatitis B test gaps\n",
    "                report_description.append(  # Add description for HBV test gap\n",
    "                    f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                    f\"{df_columns[1]}\\n\"\n",
    "                    f\"should be equal to {df_columns[0]}\\n\"\n",
    "                    f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "                )  # Describe HBV test gap issue\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero Hepatitis C test gaps\n",
    "                report_description.append(  # Add description for HCV test gap\n",
    "                    f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                    f\"{df_columns[2]}\\n\"\n",
    "                    f\"should be equal to {df_columns[0]}\\n\"\n",
    "                    f\"Note: Where this report is correct, please ignore the gap - only review.\"\n",
    "                )  # Describe HCV test gap issue\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 11: Export results to multiple formats\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                    doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 12: Cache overall unfiltered DataFrame shape\n",
    "        process_PMTCT_Hepatitis_Test_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_PMTCT_Hepatitis_Test_gap.cached_styles.clear()  # Clear cached styled DataFrames\n",
    "        if hasattr(process_PMTCT_Hepatitis_Test_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Hepatitis_Test_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Labour and Delivery gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Labour and Delivery gap\n",
    "def process_PMTCT_Labour_Delivery_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Labour and Delivery gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Labour and Delivery metrics\n",
    "            \"Total deliveries at facility (booked and unbooked pregnant women) - Total\",  # Total facility deliveries\n",
    "            \"Number of booked HIV positive pregnant women who delivered at facility - Total\",  # Booked HIV+ women delivered\n",
    "            \"Number of unbooked HIV positive pregnant women who delivered at the facility - Total\",  # Unbooked HIV+ women delivered\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\"  # Live births by HIV+ women\n",
    "        ]  # Defines columns for PMTCT Labour and Delivery analysis\n",
    "        name = \"PMTCT Labour and Delivery Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"PMTCT facility delivery by PPW gap\",  # Gap for booked/unbooked vs. total deliveries\n",
    "            \"PMTCT facility Llvebirth by PPW gap\"  # Gap for live births vs. booked/unbooked\n",
    "        ]  # Defines gap column names\n",
    "        report_name = f\"{name}35\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT Labour and Delivery columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT Facility Delivery by PPW gap (requires numpy as np)\n",
    "            df_main[df_columns[1:3]].sum(axis=1) > df_main[df_columns[0]],  # Check if sum of booked/unbooked exceeds total deliveries\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for delivery gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds delivery gap column\n",
    "        \n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PMTCT Facility Livebirth by PPW gap\n",
    "            df_main[df_columns[3]] < df_main[df_columns[1:3]].sum(axis=1),  # Check if live births are less than sum of booked/unbooked\n",
    "            df_main[df_columns[3]] - df_main[df_columns[1:3]].sum(axis=1),  # Calculate difference for livebirth gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds livebirth gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_Labour_Delivery_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_Labour_Delivery_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_Labour_Delivery_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Labour_Delivery_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_Labour_Delivery_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero delivery gaps\n",
    "            report_description.append(  # Add description for delivery gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected delivery equality\n",
    "            )  # Describe delivery gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero livebirth gaps\n",
    "            report_description.append(  # Add description for livebirth gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should not be less than {df_columns[1]}\\nplus {df_columns[2]}\"  # Describe expected livebirth relation\n",
    "                f\"Note: Where this PMTCT livebirth gap is true, please ignore the outlier.\"\n",
    "            )  # Describe livebirth gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_Labour_Delivery_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_Labour_Delivery_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Labour_Delivery_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT Facility HEI ARVs gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT Facility HEI ARVs gap\n",
    "def process_PMTCT_Facility_HEI_ARVs_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT Facility HEI ARVs gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT Facility HEI ARVs metrics\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # Total live births by HIV+ women\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery\",  # Infants receiving ARV within 72hrs\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery\"  # Infants receiving ARV after 72hrs\n",
    "        ]  # Defines columns for PMTCT Facility HEI ARVs analysis\n",
    "        df_columns2 = MSF_hierarchy + ['Facility']  # Combine MSF hierarchy and Facility column (assumed defined elsewhere)\n",
    "        columns_to_keep = MSF_hierarchy + [df_columns[0]] + [f\"{df_columns[1]} (within the Facility)\"] + [f\"{df_columns[2]} (within the Facility)\"]  # Combine hierarchy and renamed data columns\n",
    "        name = \"PMTCT Facility HEI ARVs Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT Facility HEI ARVs gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}36\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header``\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=df_columns  # Include PMTCT HEI ARVs columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Rename and prepare ARV within 72hrs data\n",
    "        df_main2 = DHIS2_data['PMTCT MSF_sd<72_in-outside'][df_columns2].rename(  # Select and rename columns from <72hrs dataset\n",
    "            columns={\"Facility\": f\"{df_columns[1]} (within the Facility)\"}  # Rename Facility to ARV within 72hrs\n",
    "        )  # Store renamed DataFrame for ARV within 72hrs\n",
    "\n",
    "        # -- Step 4: Rename and prepare ARV after 72hrs data\n",
    "        if not 'Facility' in DHIS2_data['PMTCT MSF_sd>72_in-outside'].columns:  # Check if Facility column exists in >72hrs dataset\n",
    "            df_main3 = pd.DataFrame(columns=df_columns2).rename(  # Create empty DataFrame with renamed columns (requires pandas as pd)\n",
    "                columns={\"Facility\": f\"{df_columns[2]} (within the Facility)\"}  # Rename Facility to ARV after 72hrs\n",
    "            )  # Store empty renamed DataFrame\n",
    "        else:\n",
    "            df_main3 = DHIS2_data['PMTCT MSF_sd>72_in-outside'][df_columns2].rename(  # Select and rename columns from >72hrs dataset\n",
    "                columns={\"Facility\": f\"{df_columns[2]} (within the Facility)\"}  # Rename Facility to ARV after 72hrs\n",
    "            )  # Store renamed DataFrame for ARV after 72hrs\n",
    "\n",
    "        # -- Step 5: Merge primary data with ARV data\n",
    "        df_main = df_main.merge(df_main2, on=MSF_hierarchy, how='left')  # Merge primary data with ARV within 72hrs data\n",
    "        df_main = df_main.merge(df_main3, on=MSF_hierarchy, how='left')  # Merge primary data with ARV after 72hrs data\n",
    "\n",
    "        # -- Step 6: Retain specified columns\n",
    "        df_main = df_main[columns_to_keep]  # Filter DataFrame to keep only specified columns\n",
    "\n",
    "        # -- Step 7: Clean and convert data types\n",
    "        df_main[df_columns[0]] = pd.to_numeric(df_main[df_columns[0]], errors='coerce')  # Convert total live births to numeric\n",
    "        df_main[f\"{df_columns[1]} (within the Facility)\"] = pd.to_numeric(df_main[f\"{df_columns[1]} (within the Facility)\"], errors='coerce')  # Convert ARV within 72hrs to numeric\n",
    "        df_main[f\"{df_columns[2]} (within the Facility)\"] = pd.to_numeric(df_main[f\"{df_columns[2]} (within the Facility)\"], errors='coerce')  # Convert ARV after 72hrs to numeric\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        float_columns = df_main.select_dtypes(include=['float64', 'float32']).columns  # Identify float columns in DataFrame\n",
    "        for col in float_columns:  # Iterate over float columns\n",
    "            df_main[col] = df_main[col].astype(int)  # Convert float columns to integers\n",
    "\n",
    "        # -- Step 8: Calculate PMTCT Facility HEI ARVs gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT ARV prophylaxis gap (requires numpy as np)\n",
    "            df_main[[f\"{df_columns[1]} (within the Facility)\", f\"{df_columns[2]} (within the Facility)\"]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of ARV prophylaxis differs from total live births\n",
    "            df_main[[f\"{df_columns[1]} (within the Facility)\", f\"{df_columns[2]} (within the Facility)\"]].sum(axis=1) - df_main[df_columns[0]],  # Calculate gap as sum minus total live births\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds ARV prophylaxis gap column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_PMTCT_Facility_HEI_ARVs_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 11: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap column\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_PMTCT_Facility_HEI_ARVs_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_PMTCT_Facility_HEI_ARVs_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 12: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 13: Cache styled DataFrame and shape\n",
    "        process_PMTCT_Facility_HEI_ARVs_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_PMTCT_Facility_HEI_ARVs_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 14: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 15: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero ARV prophylaxis gaps\n",
    "            report_description = (  # Define description for ARV gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  \n",
    "                f\"REPORT ONLY HEI ARVs FOR 2025 LIVE BIRTHS BY PPW.\"         \n",
    "                f\"Note: Where this PMTCT livebirth gap is true, please ignore the outlier.\"\n",
    "            )  # Describe ARV prophylaxis gap issue\n",
    "\n",
    "        # -- Step 16: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results``\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 17: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_PMTCT_Facility_HEI_ARVs_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_PMTCT_Facility_HEI_ARVs_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_Facility_HEI_ARVs_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT EID PCR Test gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT EID PCR Test gap\n",
    "def process_PMTCT_EID_PCR_Test_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT EID PCR Test gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT EID PCR Test metrics\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # Total live births by HIV+ women\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery\",  # Infants receiving ARV within 72hrs\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery\",  # Infants receiving ARV after 72hrs\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",  # Infants tested for PCR within 72hrs\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\"  # Infants tested for PCR after 72hrs\n",
    "        ]  # Defines columns for PMTCT EID PCR Test analysis\n",
    "        df_columns_spec = [  # List of column names including outside facility metrics\n",
    "            \"Number of live births by HIV positive women who delivered at the facility - Total\",  # Total live births by HIV+ women\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis within 72 hrs of delivery (outside the Facility)\",  # Infants receiving ARV within 72hrs outside facility\n",
    "            \"Number of HIV-exposed infants born to HIV positive women who received ARV prophylaxis after 72 hrs of delivery (outside the Facility)\",  # Infants receiving ARV after 72hrs outside facility\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",  # Infants tested for PCR within 72hrs\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\"  # Infants tested for PCR after 72hrs\n",
    "        ]  # Defines columns including outside facility data\n",
    "        df_columns2 = MSF_hierarchy + ['Outside Facility']  # Combine MSF hierarchy and Outside Facility column (assumed defined elsewhere)\n",
    "        columns_to_keep = (\n",
    "            MSF_hierarchy + [df_columns_spec[0]] + [df_columns_spec[1]] + \n",
    "            [df_columns_spec[2]] + [df_columns_spec[3]] + [df_columns_spec[4]]\n",
    "        )  # Combine hierarchy and specified data columns\n",
    "        name = \"PMTCT EID PCR Test Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT EID PCR Test gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}37\"  # Report name with unique suffix\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns\n",
    "            data_columns=df_columns  # Include PMTCT EID PCR Test columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Rename and prepare ARV within 72hrs data\n",
    "        if 'Outside Facility' not in DHIS2_data['PMTCT MSF_sd<72_in-outside'].columns:  # Check if Outside Facility column exists in <72hrs dataset\n",
    "            df_main2 = pd.DataFrame(columns=df_columns2).rename(  # Create empty DataFrame with renamed columns (requires pandas as pd)\n",
    "                columns={\"Outside Facility\": df_columns_spec[1]}  # Rename Outside Facility to ARV within 72hrs outside\n",
    "            )  # Store empty renamed DataFrame\n",
    "        else:\n",
    "            df_main2 = DHIS2_data['PMTCT MSF_sd<72_in-outside'][df_columns2].rename(  # Select and rename columns from <72hrs dataset\n",
    "                columns={\"Outside Facility\": df_columns_spec[1]}  # Rename Outside Facility to ARV within 72hrs outside\n",
    "            )  # Store renamed DataFrame for ARV within 72hrs\n",
    "\n",
    "        # -- Step 4: Rename and prepare ARV after 72hrs data\n",
    "        if 'Outside Facility' not in DHIS2_data['PMTCT MSF_sd>72_in-outside'].columns:  # Check if Outside Facility column exists in >72hrs dataset\n",
    "            df_main3 = pd.DataFrame(columns=df_columns2).rename(  # Create empty DataFrame with renamed columns\n",
    "                columns={\"Outside Facility\": df_columns_spec[2]}  # Rename Outside Facility to ARV after 72hrs outside\n",
    "            )  # Store empty renamed DataFrame\n",
    "        else:\n",
    "            df_main3 = DHIS2_data['PMTCT MSF_sd>72_in-outside'][df_columns2].rename(  # Select and rename columns from >72hrs dataset\n",
    "                columns={\"Outside Facility\": df_columns_spec[2]}  # Rename Outside Facility to ARV after 72hrs outside\n",
    "            )  # Store renamed DataFrame for ARV after 72hrs\n",
    "\n",
    "        # -- Step 5: Merge primary data with ARV data\n",
    "        df_main = df_main.merge(df_main2, on=MSF_hierarchy, how='left')  # Merge primary data with ARV within 72hrs data\n",
    "        df_main = df_main.merge(df_main3, on=MSF_hierarchy, how='left')  # Merge primary data with ARV after 72hrs data\n",
    "\n",
    "        # -- Step 6: Retain specified columns\n",
    "        df_main = df_main[columns_to_keep]  # Filter DataFrame to keep only specified columns\n",
    "\n",
    "        # -- Step 7: Clean and convert data types\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        # Explicitly convert relevant columns to numeric, coercing errors to 0\n",
    "        for col in df_columns_spec:  # Iterate over specified columns\n",
    "            df_main[col] = pd.to_numeric(df_main[col], errors='coerce').fillna(0).astype(int)  # Convert to numeric and then to integer\n",
    "\n",
    "        # -- Step 8: Calculate PMTCT EID PCR Test gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT EID PCR Test gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[3:5]].sum(axis=1) != df_main[df_columns_spec[0:3]].sum(axis=1),  # Check if sum of PCR tests differs from sum of live births and ARVs\n",
    "            df_main[df_columns_spec[3:5]].sum(axis=1) - df_main[df_columns_spec[0:3]].sum(axis=1),  # Calculate gap as PCR tests minus live births and ARVs\n",
    "            0  # Set to 0 if no gap\n",
    "        ).astype(int)  # Ensure integer type for gap column\n",
    "\n",
    "        # -- Step 9: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 10: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_styles'):  # Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_PMTCT_EID_PCR_Test_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_PMTCT_EID_PCR_Test_gap.cached_styles.items():  # Iterate over cached cluster styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 11: Initialize cache\n",
    "        if not hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_PMTCT_EID_PCR_Test_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 12: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_main['Cluster'].unique())  # Extract unique cluster names (requires pandas as pd)\n",
    "\n",
    "        # -- Step 13: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_main[df_main['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            PMTCT_EID_msg = f\"No {current_cluster} {report_name}\"  # Message if no gaps found for cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with gaps\n",
    "                df=cluster_filtered,  # Input cluster-filtered DataFrame\n",
    "                msg=PMTCT_EID_msg,  # Message to display if no gaps\n",
    "                opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found\n",
    "                if current_cluster in process_PMTCT_EID_PCR_Test_gap.cached_styles:  # Check if cluster in cache\n",
    "                    del process_PMTCT_EID_PCR_Test_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight non-zero gaps in yellow (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_PMTCT_EID_PCR_Test_gap.cached_styles[current_cluster] = cluster_filtered_style  # Cache styled DataFrame for cluster\n",
    "\n",
    "            # -- Step 14: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 15: Create descriptions for Word document\n",
    "            report_description = []  # Initialize list for report descriptions\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero EID PCR Test gaps\n",
    "                report_description.append(  # Add description for EID PCR Test gap\n",
    "                    f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                    f\"{df_columns_spec[0]}\\nplus {df_columns_spec[1]}\\nplus {df_columns_spec[2]}\\n\"\n",
    "                    f\"should be equal to {df_columns[3]}\\nplus {df_columns_spec[4]}\\n\"\n",
    "                    f\"REPORT ONLY EID PCR TEST FOR 2025 LIVE BIRTHS BY PPW.\\n\"\n",
    "                    f\"Note: Where this PMTCT EID PCR Test gap is true, please ignore the outlier.\"\n",
    "                )  # Describe EID PCR Test gap issue\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 16: Export results to multiple formats\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                    doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "        # -- Step 17: Cache overall unfiltered DataFrame shape\n",
    "        process_PMTCT_EID_PCR_Test_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_PMTCT_EID_PCR_Test_gap.cached_styles.clear()  # Clear cached styled DataFrames\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_EID_PCR_Test_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PMTCT EID PCR Test Result gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PMTCT EID PCR Test Result gap\n",
    "def process_PMTCT_EID_PCR_Test_Result_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PMTCT EID PCR Test Result gap, exporting results as image, Excel, and Word files.\n",
    "    Iterates over each cluster, caches styled DataFrames, and displays them on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PMTCT EID PCR Test Result metrics\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test within 72 hrs of birth\",  # Infants tested for PCR within 72hrs\n",
    "            \"Number of Infants born to HIV positive women whose blood samples were taken for DNA PCR test between >72 hrs - < 2 months of birth\",  # Infants tested for PCR after 72hrs\n",
    "            \"Number of HIV PCR results received for babies whose samples were taken within 72 hrs of birth\",  # PCR results received within 72hrs\n",
    "            \"Number of HIV PCR results received for babies whose samples were taken between >72 hrs - < 2 months of birth\"  # PCR results received after 72hrs\n",
    "        ]  # Defines columns for PMTCT EID PCR Test Result analysis\n",
    "        name = \"PMTCT EID PCR Test Result Gap\"  # Base name for report\n",
    "        gap_columns = [\"PMTCT EID PCR test result gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}38\"  # Report name with unique suffix\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"PMTCT MSF\",  # Key to fetch PMTCT MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PMTCT EID PCR Test Result columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Clean and convert data types\n",
    "        df_main = df_main.fillna(0)  # Replace NaN values with 0\n",
    "        # Explicitly convert relevant columns to numeric, coercing errors to 0\n",
    "        for col in df_columns:  # Iterate over specified columns\n",
    "            df_main[col] = pd.to_numeric(df_main[col], errors='coerce').fillna(0).astype(int)  # Convert to numeric and then to integer\n",
    "\n",
    "        # -- Step 4: Calculate PMTCT EID PCR Test Result gap\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PMTCT EID PCR Test Result gap (requires numpy as np)\n",
    "            df_main[df_columns[0:2]].sum(axis=1) != df_main[df_columns[2:4]].sum(axis=1),  # Check if sum of samples taken differs from sum of results received\n",
    "            df_main[df_columns[0:2]].sum(axis=1) - df_main[df_columns[2:4]].sum(axis=1),  # Calculate gap as samples minus results\n",
    "            0  # Set to 0 if no gap\n",
    "        ).astype(int)  # Ensure integer type for gap column\n",
    "\n",
    "        # -- Step 5: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 6: Check and display cached styled DataFrames\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_styles'):  # Check if cached styled DataFrames exist\n",
    "                cached_shape = getattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    for cluster, style in process_PMTCT_EID_PCR_Test_Result_gap.cached_styles.items():  # Iterate over cached cluster styles\n",
    "                        display_name = f\"✔️ Displaying {cluster} {report_name}\"  # Formatted display name for output\n",
    "                        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "                        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "                        print(print_display_name)  # Print display name with separators\n",
    "                        widget_display_df(style)  # Display cached styled DataFrame (assumed widget function)\n",
    "                    return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 7: Initialize cache\n",
    "        if not hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_styles'):  # Check if cache attribute exists\n",
    "            process_PMTCT_EID_PCR_Test_Result_gap.cached_styles = {}  # Initialize empty dictionary for caching styles\n",
    "\n",
    "        # -- Step 8: Identify unique clusters\n",
    "        cluster_list = pd.Series(df_main['Cluster'].unique())  # Extract unique cluster names (requires pandas as pd)\n",
    "\n",
    "        # -- Step 9: Process each cluster\n",
    "        for current_cluster in cluster_list:  # Iterate over each unique cluster\n",
    "            cluster_filtered = df_main[df_main['Cluster'] == current_cluster]  # Filter DataFrame for current cluster\n",
    "            \n",
    "            PMTCT_EID_msg = f\"No {current_cluster} {report_name}\"  # Message if no gaps found for cluster\n",
    "            display_name = f\"✔️ Displaying {current_cluster} {report_name}\"  # Formatted display name for output\n",
    "            display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "            print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "            cluster_filtered_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with gaps\n",
    "                df=cluster_filtered,  # Input cluster-filtered DataFrame\n",
    "                msg=PMTCT_EID_msg,  # Message to display if no gaps\n",
    "                opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "                opNeg=None,  # No negative value filter\n",
    "                opPos=None,  # No positive value filter\n",
    "                opZero=None,  # No zero value filter\n",
    "                opLT100=None  # No less-than-100 filter\n",
    "            )  # Returns filtered DataFrame or None if no gaps\n",
    "\n",
    "            if cluster_filtered_gap is None:  # Check if no gaps were found\n",
    "                if current_cluster in process_PMTCT_EID_PCR_Test_Result_gap.cached_styles:  # Check if cluster in cache\n",
    "                    del process_PMTCT_EID_PCR_Test_Result_gap.cached_styles[current_cluster]  # Remove cluster from cache\n",
    "                continue  # Skip to next cluster\n",
    "\n",
    "            cluster_filtered_style = (  # Apply styling to filtered DataFrame\n",
    "                cluster_filtered_gap.style  # Create style object from filtered DataFrame\n",
    "                .hide(axis='index')  # Hide row index for cleaner display\n",
    "                .map(outlier_yellow, subset=gap_columns_wrap)  # Highlight non-zero gaps in yellow (assumed function)\n",
    "            )  # Creates styled DataFrame for display/export\n",
    "\n",
    "            process_PMTCT_EID_PCR_Test_Result_gap.cached_styles[current_cluster] = cluster_filtered_style  # Cache styled DataFrame for cluster\n",
    "\n",
    "            # -- Step 10: Define export variables\n",
    "            report_name_cluster = f\"{current_cluster}_{report_name}\"  # Create cluster-specific report name\n",
    "            report_month = cluster_filtered_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "            report_image_name = f\"{report_month}_{report_name_cluster}.png\"  # Create image file name with report month\n",
    "            report_sheet_name = f\"{current_cluster}_{report_name}\"  # Define Excel sheet name with cluster\n",
    "\n",
    "            # -- Step 11: Create descriptions for Word document\n",
    "            report_description = []  # Initialize list for report descriptions\n",
    "            if (cluster_filtered_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero EID PCR Test Result gaps\n",
    "                report_description.append(  # Add description for EID PCR Test Result gap\n",
    "                    f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                    f\"{df_columns[0]}\\nplus {df_columns[1]}\\n\"\n",
    "                    f\"should be equal to {df_columns[2]}\\nplus {df_columns[3]}\\n\"\n",
    "                    f\"REPORT ONLY EID PCR TEST RESULT FOR 2025 LIVE BIRTHS BY PPW.\\n\"\n",
    "                    f\"Note: Where this {name} is true, please ignore the outlier.\"\n",
    "                )  # Describe EID PCR Test Result gap issue\n",
    "            report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "            # -- Step 12: Export results to multiple formats\n",
    "            if not display_output:  # Check if user requested to export results\n",
    "                export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                    report_name=report_name_cluster,  # Cluster-specific report name\n",
    "                    df_style=cluster_filtered_style,  # Styled DataFrame for export\n",
    "                    img_file_name=report_image_name,  # Image file name\n",
    "                    img_file_path=sub_folder2_image_file_msf_outlier,  # Image file path (assumed defined)\n",
    "                    doc_description=report_description,  # Word document description\n",
    "                    doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                    doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                    xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                    xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "                )  # Exports to specified formats\n",
    "\n",
    "            if display_output:  # Check if display is requested\n",
    "                print(print_display_name)  # Print display name with separators\n",
    "                widget_display_df(cluster_filtered_style)  # Display styled DataFrame (assumed widget function)\n",
    "        \n",
    "        # -- Step 13: Cache overall unfiltered DataFrame shape\n",
    "        process_PMTCT_EID_PCR_Test_Result_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_styles'):  # Check for cached styles\n",
    "            process_PMTCT_EID_PCR_Test_Result_gap.cached_styles.clear()  # Clear cached styled DataFrames\n",
    "        if hasattr(process_PMTCT_EID_PCR_Test_Result_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_PMTCT_EID_PCR_Test_Result_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## NSP MSF\n",
    "### - PWID Newly Recriuted gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process NSP Newly Recruited gap\n",
    "def process_NSP_Newly_Recruited_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process NSP Newly Recruited gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for NSP Newly Recruited metrics\n",
    "            \"Number of PWID Newly recruited into the program within the reporting month\",  # Newly recruited PWID count\n",
    "            \"Number of PWID New and old recruited into the program within the reporting month\"  # Total new and old PWID count\n",
    "        ]  # Defines columns for NSP Newly Recruited analysis\n",
    "        name = \"PWID Newly Recruited Gap\"  # Base name for report\n",
    "        gap_columns = [\"PWID newly recruited gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}39\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"NSP MSF\",  # Key to fetch NSP MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include NSP Newly Recruited columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gap for newly recruited PWID\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate NSP Newly Recruited gap (requires numpy as np)\n",
    "            df_main[df_columns[0]] > df_main[df_columns[1]],  # Check if newly recruited exceeds total new and old recruited\n",
    "            df_main[df_columns[0]] - df_main[df_columns[1]],  # Calculate difference for gap\n",
    "            0  # Set to 0 if no gap\n",
    "        ).astype(int)  # Ensure integer type for gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        #df_columns_spec_wrap = wrap_column_headers2(df_columns_spec)  # Commented out in original code, preserved as is\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_NSP_Newly_Recruited_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_NSP_Newly_Recruited_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_NSP_Newly_Recruited_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap column\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_NSP_Newly_Recruited_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_NSP_Newly_Recruited_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_NSP_Newly_Recruited_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_NSP_Newly_Recruited_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_NSP_Newly_Recruited_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_NSP_Newly_Recruited_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero newly recruited gaps\n",
    "            report_description = (  # Define description for gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[0]}\\n\"\n",
    "                f\"should not be greater than {df_columns[1]}\"  # Describe expected relation\n",
    "            )  # Describe newly recruited gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap column\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_NSP_Newly_Recruited_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_NSP_Newly_Recruited_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_NSP_Newly_Recruited_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_NSP_Newly_Recruited_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PWID HTS Positive Linkage gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PWID HTS Positive gap\n",
    "def process_NSP_HTS_Positive_Linkage_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PWID HTS Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PWID HTS Positive and Linkage metrics\n",
    "            \"Number of PWID tested for HIV and received their test result\",  # PWID tested and received results\n",
    "            \"Number of PWID tested for HIV Positive during the reporting month\",  # PWID tested HIV positive\n",
    "            \"Number of PWID tested for HIV Positive and were linked to ART during the reporting month\"  # PWID linked to ART\n",
    "        ]  # Defines columns for PWID HTS Positive and Linkage analysis\n",
    "        name = \"PWID HTS Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"PWID HTS positive gap\", \"PWID positive linkage gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}40\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "        \n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"NSP MSF\",  # Key to fetch NSP MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PWID HTS Positive and Linkage columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PWID HTS Positive gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if HIV positive tests exceed total tested\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for positive gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds HTS Positive gap column\n",
    "\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PWID Positive Linkage gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[1]],  # Check if ART linkage differs from HIV positive tests\n",
    "            df_main[df_columns[2]] - df_main[df_columns[1]],  # Calculate difference for linkage gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds Positive Linkage gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_NSP_HTS_Positive_Linkage_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_NSP_HTS_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_NSP_HTS_Positive_Linkage_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_NSP_HTS_Positive_Linkage_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_NSP_HTS_Positive_Linkage_gap.cached_shape = df_main.shape  # Store original DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS Positive gaps\n",
    "            report_description.append(  # Add description for HTS Positive gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS Positive\n",
    "            )  # Describe HTS Positive gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero Positive Linkage gaps\n",
    "            report_description.append(  # Add description for Positive Linkage gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[1]}\"  # Describe expected equality for linkage\n",
    "            )  # Describe Positive Linkage gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=df_columns, # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_NSP_HTS_Positive_Linkage_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_NSP_HTS_Positive_Linkage_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_NSP_HTS_Positive_Linkage_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PWID Coinfection gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PWID Coinfection gap\n",
    "def process_NSP_Coinfection_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PWID Coinfection gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PWID Coinfection metrics\n",
    "            \"Number of PWID Screened for STI and scored 1+ within the reporting month\",  # PWID screened for STI\n",
    "            \"Number of PWID Screened for STI and scored 1+ who were referred for STI treatment\",  # PWID referred for STI treatment\n",
    "            \"Number of PWID Screened for TB and scored 1+ within reporting month\",  # PWID screened for TB\n",
    "            \"Number of PWID Screened for TB and scored 1+ who were referred for TB treatment\"  # PWID referred for TB treatment\n",
    "        ]  # Defines columns for PWID Coinfection analysis\n",
    "        name = \"PWID Coinfection Gap\"  # Base name for report\n",
    "        gap_columns = [\n",
    "            \"PWID coinfection treatment - STI gap\",\n",
    "            \"PWID coinfection treatment - TB gap\"\n",
    "        ]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}41\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"NSP MSF\",  # Key to fetch NSP MSF\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PWID Coinfection columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PWID Coinfection Treatment - STI gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if STI referrals differ from STI screened\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for STI gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds STI Coinfection gap column\n",
    "\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PWID Coinfection Treatment - TB gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[2]],  # Check if TB referrals differ from TB screened\n",
    "            df_main[df_columns[3]] - df_main[df_columns[2]],  # Calculate difference for TB gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds TB Coinfection gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_NSP_Coinfection_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_NSP_Coinfection_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_NSP_Coinfection_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_NSP_Coinfection_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_NSP_Coinfection_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_NSP_Coinfection_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_NSP_Coinfection_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_NSP_Coinfection_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_NSP_Coinfection_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero STI Coinfection gaps\n",
    "            report_description.append(  # Add description for STI Coinfection gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for STI\n",
    "            )  # Describe STI Coinfection gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero TB Coinfection gaps\n",
    "            report_description.append(  # Add description for TB Coinfection gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should be equal to {df_columns[2]}\"  # Describe expected equality for TB\n",
    "            )  # Describe TB Coinfection gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_NSP_Coinfection_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_NSP_Coinfection_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_NSP_Coinfection_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_NSP_Coinfection_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PWID Substance Abuse gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PWID Substance Abuse gap\n",
    "def process_NSP_Substance_Abuse_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PWID Coinfection gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PWID Substance Abuse metrics\n",
    "            \"Number of PWID that developed an Injection abscess within the reporting month\",  # PWID with injection abscess\n",
    "            \"Number of PWID treated for Injection abscess within the reporting month\",  # PWID treated for injection abscess\n",
    "            \"Number of PWID with Opiod overdose within the reporting month\",  # PWID with opioid overdose\n",
    "            \"Number of PWID with Opiod overdose who were resuscitated medically within the reporting month\"  # PWID resuscitated for opioid overdose\n",
    "        ]  # Defines columns for PWID Substance Abuse analysis\n",
    "        name = \"PWID Substance Abuse Gap\"  # Base name for report\n",
    "        gap_columns = [\n",
    "            \"PWID injection abuse gap\",\n",
    "            \"PWID Opid overdose gap\"  # Note: Typo 'Opid' preserved as in original\n",
    "        ]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}42\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"NSP MSF\",  # Key to fetch NSP MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PWID Substance Abuse columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PWID Injection Abuse gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if abscess treatments differ from abscess cases\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for injection abuse gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds Injection Abuse gap column\n",
    "\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PWID Opioid Overdose gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[2]],  # Check if overdose resuscitations differ from overdose cases\n",
    "            df_main[df_columns[3]] - df_main[df_columns[2]],  # Calculate difference for opioid overdose gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds Opioid Overdose gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_NSP_Substance_Abuse_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_NSP_Substance_Abuse_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_NSP_Substance_Abuse_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_NSP_Substance_Abuse_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_NSP_Substance_Abuse_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_NSP_Substance_Abuse_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_NSP_Substance_Abuse_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_NSP_Substance_Abuse_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_NSP_Substance_Abuse_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero Injection Abuse gaps\n",
    "            report_description.append(  # Add description for Injection Abuse gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for injection abscess\n",
    "            )  # Describe Injection Abuse gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero Opioid Overdose gaps\n",
    "            report_description.append(  # Add description for Opioid Overdose gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"\n",
    "                f\"should be equal to {df_columns[2]}\"  # Describe expected equality for opioid overdose\n",
    "            )  # Describe Opioid Overdose gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_NSP_Substance_Abuse_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_NSP_Substance_Abuse_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_NSP_Substance_Abuse_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_NSP_Substance_Abuse_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - PWID MAT Referral gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process PWID MAT Referral gap\n",
    "def process_NSP_MAT_Referral_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process PWID Coinfection gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PWID MAT Referral metrics\n",
    "            \"Number of PWID eligible for medication-assisted therapy (MAT)\",  # PWID eligible for MAT\n",
    "            \"Number of PWID referred for medication-assisted therapy\"  # PWID referred for MAT\n",
    "        ]  # Defines columns for PWID MAT Referral analysis\n",
    "        name = \"PWID Medication Assisted Theraphy Gap\"  # Base name for report (typo: 'Theraphy' preserved)\n",
    "        gap_columns = [\"PWID MAT referral gap\"]  # Names for calculated gap columns (typo: 'Refferal' preserved)\n",
    "        report_name = f\"{name}43\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"NSP MSF\",  # Key to fetch NSP MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PWID MAT Referral columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PWID MAT Referral gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if MAT referrals differ from eligible PWID\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for MAT referral gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MAT Referral gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_NSP_MAT_Referral_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_NSP_MAT_Referral_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_NSP_MAT_Referral_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_NSP_MAT_Referral_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_NSP_MAT_Referral_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_NSP_MAT_Referral_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_NSP_MAT_Referral_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_NSP_MAT_Referral_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_NSP_MAT_Referral_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero MAT Referral gaps\n",
    "            report_description = (  # Define description for MAT Referral gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for MAT referrals\n",
    "            )  # Describe MAT Referral gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_NSP_MAT_Referral_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_NSP_MAT_Referral_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_NSP_MAT_Referral_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_NSP_MAT_Referral_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "## KP Prev MSF\n",
    "### - KP-Prev MSH gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP MHS and Psychosocial Support gap\n",
    "def process_KP_MHS_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP MHS and Psychosocial Support gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP MHS and Psychosocial Support metrics\n",
    "            \"NTHRIP-Number of KPs who were screened for Mental Health and Psychosocial support during the reporting period\",  # KPs screened for MHS\n",
    "            \"NTHRIP-Number of KPs who were diagnosed with Mental Health and Psychosocial issues during the reporting month\",  # KPs diagnosed with MHS issues\n",
    "            \"NTHRIP-Number of KPs who were diagnosed with Mental Health and Psychosocial issues and were offered support services during the reporting month\"  # KPs offered MHS support\n",
    "        ]  # Defines columns for KP MHS analysis\n",
    "        name = \"KP Prev MHS and Psychosocial Support Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-MHS and psychological dignosed gap\",  # Typo: 'dignosed' preserved\n",
    "            \"KP Prev-MHS and psychological support gap\"  # Typo: 'psychological' preserved\n",
    "        ]  # Defines gap columns for MHS metrics\n",
    "        report_name = f\"{name}44\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP MHS columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate MHS diagnosis gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if diagnosed exceeds screened\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for diagnosis gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MHS diagnosis gap column\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate MHS support gap\n",
    "            df_main[df_columns[2]] < df_main[df_columns[1]],  # Check if support is less than diagnosed\n",
    "            df_main[df_columns[2]] - df_main[df_columns[1]],  # Calculate difference for support gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MHS support gap column\n",
    "        \n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_MHS_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_MHS_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_MHS_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_MHS_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_MHS_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_MHS_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_MHS_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_MHS_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_MHS_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero MHS diagnosis gaps\n",
    "            report_description.append(  # Add description for MHS diagnosis gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for diagnosis\n",
    "            )  # Describe MHS diagnosis gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero MHS support gaps\n",
    "            report_description.append(  # Add description for MHS support gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[2]}\\n\"\n",
    "                f\"should not be less than {df_columns[1]}\"  # Describe expected relation for support\n",
    "            )  # Describe MHS support gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_MHS_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_MHS_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_MHS_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_MHS_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-Prev MSH by Type gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP MHS and Psychosocial Support gap\n",
    "def process_KP_MHS_Access_Type_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP KP MHS and Psychosocial Support gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP MHS and Psychosocial Support metrics\n",
    "            \"NTHRIP-Number of KPs who were screened for Mental Health and Psychosocial support during the reporting period\",  # KPs screened for MHS\n",
    "            \"NTHRIP-Number of KPs who were diagnosed with Mental Health and Psychosocial issues during the reporting month\",  # KPs diagnosed with MHS issues\n",
    "            \"NTHRIP-Number of KPs who were diagnosed with Mental Health and Psychosocial issues and were offered support services during the reporting month\"  # KPs offered MHS support\n",
    "        ]  # Defines columns for KP MHS analysis\n",
    "        df_columns_spec = [  # List of specified columns including aggregated access types\n",
    "            df_columns[0], f\"{df_columns[0]} (Walk-In and Community)\",  # Screened columns\n",
    "            df_columns[1], f\"{df_columns[1]} (Walk-In and Community)\",  # Diagnosed columns\n",
    "            df_columns[2], f\"{df_columns[2]} (Walk-In and Community)\"   # Support columns\n",
    "        ]  # Defines columns for access type comparisons\n",
    "        df_columns2 = [\"Community\", \"Walk-In\"]  # Access type columns for aggregation\n",
    "        name = \"KP Prev_Prev MHS and Psychosocial Support by Access Type Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-MHS and psychosocial support by access type (Walk-In and Community) gap\",\n",
    "            \"KP Prev-MHS and psychosocial diagnosis by access type (Walk-In and Community) gap\",\n",
    "            \"KP Prev-MHS and psychosocial issues offered support services by access type (Walk-In and Community) gap\"\n",
    "        ]  # Defines gap columns for MHS metrics\n",
    "        report_name = f\"{name}45\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare main DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP MHS columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        df_main2 = DHIS2_data['KP Prev MSF_access_type_mhs'][MSF_hierarchy + df_columns2].copy()  # Copy MHS access type data\n",
    "        df_main2[df_columns2] = df_main2[df_columns2].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert access type columns to numeric, fill NaN with 0\n",
    "        df_main2[df_columns_spec[1]] = df_main2[df_columns2].sum(axis=1)  # Sum Community and Walk-In for MHS screening\n",
    "        df_main2.drop(columns=df_columns2, inplace=True)  # Drop original access type columns\n",
    "\n",
    "        df_main3 = DHIS2_data['KP Prev MSF_access_type_msh_diagnose'][MSF_hierarchy + df_columns2].copy()  # Copy MHS diagnosis access type data (typo: 'msh' preserved)\n",
    "        df_main3[df_columns2] = df_main3[df_columns2].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert access type columns to numeric, fill NaN with 0\n",
    "        df_main3[df_columns_spec[3]] = df_main3[df_columns2].sum(axis=1)  # Sum Community and Walk-In for MHS diagnosis\n",
    "        df_main3.drop(columns=df_columns2, inplace=True)  # Drop original access type columns\n",
    "\n",
    "        df_main4 = DHIS2_data['KP Prev MSF_access_type_msh_support'][MSF_hierarchy + df_columns2].copy()  # Copy MHS support access type data (typo: 'msh' preserved)\n",
    "        df_main4[df_columns2] = df_main4[df_columns2].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert access type columns to numeric, fill NaN with 0\n",
    "        df_main4[df_columns_spec[5]] = df_main4[df_columns2].sum(axis=1)  # Sum Community and Walk-In for MHS support\n",
    "        df_main4.drop(columns=df_columns2, inplace=True)  # Drop original access type columns\n",
    "\n",
    "        df_main = df_main.merge(df_main2, on=MSF_hierarchy, how='left')  # Merge main DataFrame with MHS screening access type data\n",
    "        df_main = df_main.merge(df_main3, on=MSF_hierarchy, how='left')  # Merge with MHS diagnosis access type data\n",
    "        df_main = df_main.merge(df_main4, on=MSF_hierarchy, how='left')  # Merge with MHS support access type data\n",
    "\n",
    "        df_main[df_columns_spec] = df_main[df_columns_spec].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int) # Convert specified columns to numeric, fill NaN with 0, and cast to int\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate MHS screening gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[1]] != df_main[df_columns_spec[0]],  # Check if access type sum differs from total screened\n",
    "            df_main[df_columns_spec[1]] - df_main[df_columns_spec[0]],  # Calculate difference for screening gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MHS screening gap column\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate MHS diagnosis gap\n",
    "            df_main[df_columns_spec[3]] != df_main[df_columns_spec[2]],  # Check if access type sum differs from total diagnosed\n",
    "            df_main[df_columns_spec[3]] - df_main[df_columns_spec[2]],  # Calculate difference for diagnosis gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MHS diagnosis gap column\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate MHS support gap\n",
    "            df_main[df_columns_spec[5]] != df_main[df_columns_spec[4]],  # Check if access type sum differs from total supported\n",
    "            df_main[df_columns_spec[5]] - df_main[df_columns_spec[4]],  # Calculate difference for support gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds MHS support gap column\n",
    "        reorder_columns = (  # Define column order for DataFrame\n",
    "            MSF_hierarchy +\n",
    "            [\n",
    "                df_columns[0],  # Total MHS screened\n",
    "                df_columns_spec[1],  # MHS screened (Walk-In and Community)\n",
    "                gap_columns[0],  # MHS screening gap\n",
    "                df_columns[1],  # Total MHS diagnosed\n",
    "                df_columns_spec[3],  # MHS diagnosed (Walk-In and Community)\n",
    "                gap_columns[1],  # MHS diagnosis gap\n",
    "                df_columns[2],  # Total MHS supported\n",
    "                df_columns_spec[5],  # MHS supported (Walk-In and Community)\n",
    "                gap_columns[2],  # MHS support gap\n",
    "            ]\n",
    "        )  # Specifies ordered columns for clarity\n",
    "        df_main = df_main[reorder_columns]  # Reorder DataFrame columns to match specified order\n",
    "        df_main = df_main.reset_index(drop=True)  # Reset index to ensure clean DataFrame structure\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_MHS_Access_Type_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_MHS_Access_Type_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_MHS_Access_Type_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_MHS_Access_Type_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_MHS_Access_Type_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_MHS_Access_Type_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_MHS_Access_Type_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_MHS_Access_Type_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_MHS_Access_Type_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero MHS screening gaps\n",
    "            report_description.append(  # Add description for MHS screening gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for screening\n",
    "            )  # Describe MHS screening gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero MHS diagnosis gaps\n",
    "            report_description.append(  # Add description for MHS diagnosis gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[2]}\"  # Describe expected equality for diagnosis\n",
    "            )  # Describe MHS diagnosis gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero MHS support gaps\n",
    "            report_description.append(  # Add description for MHS support gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns_spec[5]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[4]}\"  # Describe expected equality for support\n",
    "            )  # Describe MHS support gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_MHS_Access_Type_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_MHS_Access_Type_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_MHS_Access_Type_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_MHS_Access_Type_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-GBV CSR (Counselled, Screened & Referred) gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP GBV CSR gap\n",
    "def process_KP_GBV_CSR_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP GBV CSR gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP GBV CSR metrics\n",
    "            \"NTHRIP-Number of PLHIV Counselled on gender norms\",  # PLHIV counselled on gender norms\n",
    "            \"NTHRIP-Number of PLHIV screened for GBV\",  # PLHIV screened for GBV\n",
    "            \"NTHRIP-Number of PLHIV referred for post GBV care\"  # PLHIV referred for post-GBV care\n",
    "        ]  # Defines columns for KP GBV CSR analysis\n",
    "        name = \"KP Prev_GBV CSR Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-GBV screening gap\",\n",
    "            \"KP Prev-GBV referral gap\"\n",
    "        ]  # Defines gap columns for GBV metrics\n",
    "        report_name = f\"{name}46\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP GBV CSR columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate GBV screening gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if screened is greater than counselled\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for screening gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds GBV screening gap column\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate GBV referral gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[1]],  # Check if referrals differ from screened\n",
    "            df_main[df_columns[2]] - df_main[df_columns[1]],  # Calculate difference for referral gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds GBV referral gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_GBV_CSR_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_GBV_CSR_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_GBV_CSR_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)  # Print display name with separators\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_GBV_CSR_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_GBV_CSR_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_GBV_CSR_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_GBV_CSR_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_GBV_CSR_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_GBV_CSR_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero GBV screening gaps\n",
    "            report_description.append(  # Add description for GBV screening gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for screening\n",
    "            )  # Describe GBV screening gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero GBV referral gaps\n",
    "            report_description.append(  # Add description for GBV referral gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\n\"  # Note: Error, df_columns[3] does not exist, preserved as is\n",
    "                f\"should be equal to {df_columns[2]}\"  # Describe expected equality for referral\n",
    "            )  # Describe GBV referral gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:  # Check if user requested to export results\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)  # Print display name with separators\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_GBV_CSR_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_GBV_CSR_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_GBV_CSR_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_GBV_CSR_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-GBV Post GBV Sexual Violence PEP gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP Post GBV Sexual Violence gap\n",
    "def process_KP_Post_GBV_SV_PEP_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP Post GBV Sexual Violence gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP Post GBV Sexual Violence metrics\n",
    "            \"NTHRIP-Number of people receiving post-GBV care for Sexual Violence (post-rape care)\",  # People receiving post-GBV care\n",
    "            \"NTHRIP-Number of people receiving Post-Exposure Prophylaxis (PEP) services\"  # People receiving PEP services\n",
    "        ]  # Defines columns for KP Post GBV Sexual Violence analysis\n",
    "        name = \"KP Prev_GBV Post GBV SV PEP Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-GBV Post-Exposure Prophylaxis (PEP) services gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}47\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP Post GBV Sexual Violence columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PEP services gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] < df_main[df_columns[0]],  # Check if PEP services are less than post-GBV care\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for PEP services gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PEP services gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_Post_GBV_SV_PEP_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)   \n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_Post_GBV_SV_PEP_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_Post_GBV_SV_PEP_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_Post_GBV_SV_PEP_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_Post_GBV_SV_PEP_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero PEP services gaps\n",
    "            report_description = (  # Define description for PEP services gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be less than {df_columns[0]}\"  # Describe expected relation for PEP services\n",
    "            )  # Describe PEP services gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)   \n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_style'):  # Check for cached style (original had error: process_KP_Post_GBV_SV)\n",
    "            del process_KP_Post_GBV_SV_PEP_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_Post_GBV_SV_PEP_gap, 'cached_shape'):  # Check for cached shape (original had error: process_KP_Post_GBV_SV_PEP_gap)\n",
    "            del process_KP_Post_GBV_SV_PEP_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-KP_GBV Incidence of Violence or Abuse gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP GBV Incidence of Violence or Abuse gap\n",
    "def process_KP_GBV_IVA_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP GBV Incidence of Violence or Abuse gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP GBV Incidence of Violence or Abuse metrics\n",
    "            \"Number of KPs reporting incidence of Violence or Abuse during the reporting month\",  # KPs reporting violence or abuse\n",
    "            \"Number of KPs receiving Post GBV Clinical Care during the reporting month\"  # KPs receiving post-GBV clinical care\n",
    "        ]  # Defines columns for KP GBV Incidence of Violence or Abuse analysis\n",
    "        name = \"KP Prev_KP-GBV IVA Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-KP_GBV receiving post GBV clinical care gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}48\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP GBV Incidence columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate post-GBV clinical care gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if clinical care exceeds reported incidents\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for clinical care gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds post-GBV clinical care gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_GBV_IVA_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_GBV_IVA_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_GBV_IVA_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_GBV_IVA_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_GBV_IVA_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_GBV_IVA_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_GBV_IVA_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_GBV_IVA_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_GBV_IVA_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero post-GBV clinical care gaps\n",
    "            report_description = (  # Define description for post-GBV clinical care gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for clinical care\n",
    "            )  # Describe post-GBV clinical care gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_GBV_IVA_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_GBV_IVA_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_GBV_IVA_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_GBV_IVA_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-KP_GBV Legal Support gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP GBV Legal Support gap\n",
    "def process_KP_GBV_Legal_Support_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP GBV Legal Support gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP GBV Legal Support metrics\n",
    "            \"Number of KPs referred for Legal support or advice services during the reporting month\",  # KPs referred for legal support\n",
    "            \"Number of KPs received Legal support or services during the reporting month\"  # KPs receiving legal support (preserves grammatical error: 'received')\n",
    "        ]  # Defines columns for KP GBV Legal Support analysis\n",
    "        name = \"KP Prev_KP-GBV Legal Support Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-KP_GBV legal support gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}49\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP GBV Legal Support columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate legal support gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if received legal support differs from referrals\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for legal support gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds legal support gap column\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_GBV_Legal_Support_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_GBV_Legal_Support_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_GBV_Legal_Support_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_GBV_Legal_Support_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_GBV_Legal_Support_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_GBV_Legal_Support_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_GBV_Legal_Support_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_GBV_Legal_Support_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_GBV_Legal_Support_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero legal support gaps\n",
    "            report_description = (  # Define description for legal support gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for legal support\n",
    "            )  # Describe legal support gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_GBV_Legal_Support_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_GBV_Legal_Support_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_GBV_Legal_Support_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_GBV_Legal_Support_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PEP PEP gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PEP gap\n",
    "def process_KP_PEP_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PEP gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP PEP metrics\n",
    "            \"NTHRIP-Number of reported HIV exposures during the reporting month (excluding HIV-exposed babies)\",  # Reported HIV exposures\n",
    "            \"NTHRIP-Number of persons provided with post-exposure prophylaxis\"  # Persons provided with PEP\n",
    "        ]  # Defines columns for KP PEP analysis\n",
    "        name = \"KP Prev_PEP PEP Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-PEP gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}50\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP PEP columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PEP gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] != df_main[df_columns[0]],  # Check if PEP provision differs from reported exposures\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for PEP gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PEP gap column (original comment incorrectly references legal support gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PEP_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PEP_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PEP_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)   \n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PEP_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PEP_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PEP_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PEP_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PEP_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PEP_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero PEP gaps\n",
    "            report_description = (  # Define description for PEP gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for PEP provision\n",
    "            )  # Describe PEP gap issue\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PEP_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PEP_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PEP_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PEP_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_KP PrEP Product Recieved MSM gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Product Received MSM gap\n",
    "def process_KP_PrEP_Product_Recieved_MSM_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Product Received MSM gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize         \n",
    "        df_columns = [  # List of column names for MSM PrEP metrics\n",
    "            \"NTHRIP-KP-6a Number of MSM who received any PrEP product at least once during the reporting period\",  # Total MSM receiving PrEP\n",
    "            \"NTHRIP-KP-6a Number of MSM who received any PrEP product at least once during the reporting period: PrEP Type\",  # PrEP receipt by type\n",
    "            \"NTHRIP-KP-6a Number of MSM who received any PrEP product at least once during the reporting period: PrEP Distribution\"  # PrEP receipt by distribution channel\n",
    "        ]  # Defines columns for MSM PrEP gap analysis\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total MSM receiving PrEP\n",
    "            f\"{df_columns[0]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[0]} ({df_name_distribution[0]}, {df_name_distribution[1]})\"  # Aggregated distribution channels\n",
    "        ]  # Defines specific columns for MSM PrEP gap calculations\n",
    "        name = \"KP Prev_KP-PrEP Product Received MSM Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-KP_PrEP product received by type MSM gap\",  # Gap by PrEP type\n",
    "            \"KP Prev-KP_PrEP product received by distribution MSM gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for TG PrEP metrics\n",
    "        report_name = f\"{name}51\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include MSM PrEP column\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(  # Create a mapping of old to new column names\n",
    "                df_columns,  # Original column names\n",
    "                df_columns_spec  # New column names for gap analysis\n",
    "            ))  # Maps original columns to new names\n",
    "        )  # Renames columns for consistency with gap analysis\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate PrEP type gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[1]] != df_main[df_columns_spec[0]],  # Check if sum by PrEP type differs from total\n",
    "            df_main[df_columns_spec[1]] - df_main[df_columns_spec[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references PEP gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP distribution gap\n",
    "            df_main[df_columns_spec[2]] != df_main[df_columns_spec[0]],  # Check if sum by distribution differs from total\n",
    "            df_main[df_columns_spec[2]] - df_main[df_columns_spec[0]],  # Calculate difference for PrEP distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP distribution gap column (original comment incorrectly references PEP gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Product_Recieved_MSM_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Product_Recieved_MSM_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Product_Recieved_MSM_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Product_Recieved_MSM_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Product_Recieved_MSM_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP distribution gaps\n",
    "            report_description.append(  # Add description for PrEP distribution gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"  # Note: Original incorrectly uses gap_columns[0]\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP distribution\n",
    "            )  # Describe PrEP distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Product_Recieved_MSM_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_MSM_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Product_Recieved_MSM_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_KP PrEP Product Recieved TG gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Product Received TG gap\n",
    "def process_KP_PrEP_Product_Recieved_TG_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Product Received TG gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for TG PrEP metrics\n",
    "            \"NTHRIP-KP-6b Number of transgender (TG) people who received any PrEP product at least once during the reporting period\",  # Total TG receiving PrEP\n",
    "            \"NTHRIP-KP-6b Number of transgender (TG) people who received any PrEP product at least once during the reporting period: Pregnancy/breastfeeding status\",  # PrEP receipt by pregnancy/breastfeeding status\n",
    "            \"NTHRIP-KP-6b Number of transgender (TG) people who received any PrEP product at least once during the reporting period: PrEP Type\",  # PrEP receipt by type\n",
    "            \"NTHRIP-KP-6b Number of transgender (TG) people who received any PrEP product at least once during the reporting period: PrEP Distribution\"  # PrEP receipt by distribution channel\n",
    "        ]  # Defines columns for TG PrEP gap analysis (original comment incorrectly references MSM PrEP metrics)\n",
    "        df_name_preg_breastfeeding = ['Pregnant', 'Breastfeeding']  # Pregnancy/breastfeeding status categories\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total TG receiving PrEP (original comment incorrectly references MSM)\n",
    "            f\"{df_columns[0]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[0]} ({df_name_distribution[0]}, {df_name_distribution[1]})\",  # Aggregated distribution channels\n",
    "            f\"{df_columns[0]} ({df_name_preg_breastfeeding[0]}, {df_name_preg_breastfeeding[1]})\"  # Aggregated pregnancy/breastfeeding status\n",
    "        ]  # Defines specific columns for TG PrEP gap calculations\n",
    "        name = \"KP Prev_KP-PrEP Product Received TG Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-KP_PrEP Product received by pregnancy/breastfeeding status TG gap\",  # Gap by pregnancy/breastfeeding status\n",
    "            \"KP Prev-KP_PrEP Product received by type TG gap\",  # Gap by PrEP type\n",
    "            \"KP Prev-KP_PrEP Product received by distribution TG gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for TG PrEP metrics\n",
    "        report_name = f\"{name}52\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include TG PrEP columns\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references MSM PrEP column)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(  # Create a mapping of old to new column names\n",
    "                df_columns,  # Original column names\n",
    "                df_columns_spec  # New column names for gap analysis\n",
    "            ))  # Maps original columns to new names\n",
    "        )  # Renames columns for consistency with gap analysis\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate pregnancy/breastfeeding gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[3]] > df_main[df_columns_spec[0]],  # Check if pregnancy/breastfeeding sum exceeds total\n",
    "            df_main[df_columns_spec[3]] - df_main[df_columns_spec[0]],  # Calculate difference for pregnancy/breastfeeding gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds pregnancy/breastfeeding gap column (original comment incorrectly references PEP gap and PrEP type gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP type gap\n",
    "            df_main[df_columns_spec[1]] != df_main[df_columns_spec[0]],  # Check if PrEP type sum differs from total\n",
    "            df_main[df_columns_spec[1]] - df_main[df_columns_spec[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references PEP gap and PrEP distribution gap)\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate distribution gap\n",
    "            df_main[df_columns_spec[2]] != df_main[df_columns_spec[0]],  # Check if distribution sum differs from total\n",
    "            df_main[df_columns_spec[2]] - df_main[df_columns_spec[0]],  # Calculate difference for distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds distribution gap column (original comment incorrectly references PEP gap and PrEP pregnancy/breastfeeding gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Product_Recieved_TG_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Product_Recieved_TG_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Product_Recieved_TG_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Product_Recieved_TG_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Product_Recieved_TG_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero pregnancy/breastfeeding gaps\n",
    "            report_description.append(  # Add description for pregnancy/breastfeeding gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should not be greater than {df_columns_spec[0]}\"  # Describe expected relation for pregnancy/breastfeeding\n",
    "            )  # Describe pregnancy/breastfeeding gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"  # Preserves correct use of gap_columns[1]\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero distribution gaps\n",
    "            report_description.append(  # Add description for distribution gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"  # Preserves correct use of gap_columns[2]\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for distribution\n",
    "            )  # Describe distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Product_Recieved_TG_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_TG_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Product_Recieved_TG_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_KP PrEP Product Recieved SW gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Product Received SW gap\n",
    "def process_KP_PrEP_Product_Recieved_SW_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Product Received SW gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for SW PrEP metrics\n",
    "            \"NTHRIP-KP-6c Number of sex workers who received any PrEP product at least once during the reporting period\",  # Total SW receiving PrEP\n",
    "            \"NTHRIP-KP-6c Number of sex workers who received any PrEP product at least once during the reporting period: Pregnancy/breastfeeding status\",  # PrEP receipt by pregnancy/breastfeeding status\n",
    "            \"NTHRIP-KP-6c Number of sex workers who received any PrEP product at least once during the reporting period: PrEP Type\",  # PrEP receipt by type\n",
    "            \"NTHRIP-KP-6c Number of sex workers who received any PrEP product at least once during the reporting period: PrEP Distribution\"  # PrEP receipt by distribution channel\n",
    "        ]  # Defines columns for SW PrEP gap analysis\n",
    "        df_name_preg_breastfeeding = ['Pregnant', 'Breastfeeding']  # Pregnancy/breastfeeding status categories\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total SW receiving PrEP\n",
    "            f\"{df_columns[0]} ({df_name_preg_breastfeeding[0]}, {df_name_preg_breastfeeding[1]})\",  # Aggregated pregnancy/breastfeeding status\n",
    "            f\"{df_columns[0]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[0]} ({df_name_distribution[0]}, {df_name_distribution[1]})\"  # Aggregated distribution channels\n",
    "        ]  # Defines specific columns for SW PrEP gap calculations\n",
    "        name = \"KP Prev_KP-PrEP Product Received SW Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-KP_PrEP Product received by pregnancy/breastfeeding status SW gap\",  # Gap by pregnancy/breastfeeding status\n",
    "            \"KP Prev-KP_PrEP Product received by type SW gap\",  # Gap by PrEP type\n",
    "            \"KP Prev-KP_PrEP Product received by distribution SW gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for SW PrEP metrics\n",
    "        report_name = f\"{name}53\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include SW PrEP columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(  # Create a mapping of old to new column names\n",
    "                df_columns,  # Original column names\n",
    "                df_columns_spec  # New column names for gap analysis\n",
    "            ))  # Maps original columns to new names\n",
    "        )  # Renames columns for consistency with gap analysis\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate pregnancy/breastfeeding gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[1]] > df_main[df_columns_spec[0]],  # Check if pregnancy/breastfeeding sum exceeds total\n",
    "            df_main[df_columns_spec[1]] - df_main[df_columns_spec[0]],  # Calculate difference for pregnancy/breastfeeding gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds pregnancy/breastfeeding gap column (original comment incorrectly references PEP gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP type gap\n",
    "            df_main[df_columns_spec[2]] != df_main[df_columns_spec[0]],  # Check if PrEP type sum differs from total\n",
    "            df_main[df_columns_spec[2]] - df_main[df_columns_spec[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references PEP gap)\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate distribution gap\n",
    "            df_main[df_columns_spec[3]] != df_main[df_columns_spec[0]],  # Check if distribution sum differs from total\n",
    "            df_main[df_columns_spec[3]] - df_main[df_columns_spec[0]],  # Calculate difference for distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds distribution gap column (original comment incorrectly references PEP gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Product_Recieved_SW_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Product_Recieved_SW_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Product_Recieved_SW_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Product_Recieved_SW_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Product_Recieved_SW_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero pregnancy/breastfeeding gaps\n",
    "            report_description.append(  # Add description for pregnancy/breastfeeding gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns_spec[0]}\"  # Describe expected relation for pregnancy/breastfeeding\n",
    "            )  # Describe pregnancy/breastfeeding gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"  # Preserves correct use of gap_columns[1]\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero distribution gaps\n",
    "            report_description.append(  # Add description for distribution gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"  # Preserves correct use of gap_columns[2]\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for distribution\n",
    "            )  # Describe distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Product_Recieved_SW_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_SW_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Product_Recieved_SW_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_KP PrEP Product Recieved PWID gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Product Received PWID gap\n",
    "def process_KP_PrEP_Product_Recieved_PWID_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Product Received PWID gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PWID PrEP metrics\n",
    "            \"NTHRIP-KP-6d Number of PWID who received any PrEP product at least once during the reporting period\",  # Total PWID receiving PrEP\n",
    "            \"NTHRIP-KP-6d Number of PWID who received any PrEP product at least once during the reporting period: Pregnancy/Breastfeeding Status\",  # PrEP receipt by pregnancy/breastfeeding status\n",
    "            \"NTHRIP-KP-6d Number of PWID who received any PrEP product at least once during the reporting period: PrePType\",  # PrEP receipt by type (preserves typo: 'PrePType')\n",
    "            \"NTHRIP-KP-6d Number of PWID who received any PrEP product at least once during the reporting period: PrEPDistribution\"  # PrEP receipt by distribution channel (preserves typo: 'PrEPDistribution')\n",
    "        ]  # Defines columns for PWID PrEP gap analysis\n",
    "        df_name_preg_breastfeeding = ['Pregnant', 'Breastfeeding']  # Pregnancy/breastfeeding status categories\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total PWID receiving PrEP\n",
    "            f\"{df_columns[0]} ({df_name_preg_breastfeeding[0]}, {df_name_preg_breastfeeding[1]})\",  # Aggregated pregnancy/breastfeeding status\n",
    "            f\"{df_columns[0]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[0]} ({df_name_distribution[0]}, {df_name_distribution[1]})\"  # Aggregated distribution channels\n",
    "        ]  # Defines specific columns for PWID PrEP gap calculations\n",
    "        name = \"KP Prev_KP-PrEP Product received PWID Gap\"  # Base name for report\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-KP_PrEP Product received by pregnancy/breastfeeding status PWID gap\",  # Gap by pregnancy/breastfeeding status\n",
    "            \"KP Prev-KP_PrEP Product received by type PWID gap\",  # Gap by PrEP type\n",
    "            \"KP Prev-KP_PrEP Product received by distribution PWID gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for PWID PrEP metrics\n",
    "        report_name = f\"{name}54\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare primary DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PWID PrEP columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(  # Create a mapping of old to new column names\n",
    "                df_columns,  # Original column names\n",
    "                df_columns_spec  # New column names for gap analysis\n",
    "            ))  # Maps original columns to new names\n",
    "        )  # Renames columns for consistency with gap analysis\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate pregnancy/breastfeeding gap (requires numpy as np)\n",
    "            df_main[df_columns_spec[1]] > df_main[df_columns_spec[0]],  # Check if pregnancy/breastfeeding sum exceeds total\n",
    "            df_main[df_columns_spec[1]] - df_main[df_columns_spec[0]],  # Calculate difference for pregnancy/breastfeeding gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds pregnancy/breastfeeding gap column (original comment incorrectly references PEP gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP type gap\n",
    "            df_main[df_columns_spec[2]] != df_main[df_columns_spec[0]],  # Check if PrEP type sum differs from total\n",
    "            df_main[df_columns_spec[2]] - df_main[df_columns_spec[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references PEP gap)\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate distribution gap\n",
    "            df_main[df_columns_spec[3]] != df_main[df_columns_spec[0]],  # Check if distribution sum differs from total\n",
    "            df_main[df_columns_spec[3]] - df_main[df_columns_spec[0]],  # Calculate difference for distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds distribution gap column (original comment incorrectly references PEP gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Product_Recieved_PWID_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Product_Recieved_PWID_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Product_Recieved_PWID_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Product_Recieved_PWID_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Product_Recieved_PWID_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero pregnancy/breastfeeding gaps\n",
    "            report_description.append(  # Add description for pregnancy/breastfeeding gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns_spec[0]}\"  # Describe expected relation for pregnancy/breastfeeding\n",
    "            )  # Describe pregnancy/breastfeeding gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"  # Preserves correct use of gap_columns[1]\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero distribution gaps\n",
    "            report_description.append(  # Add description for distribution gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"  # Preserves correct use of gap_columns[2]\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for distribution\n",
    "            )  # Describe distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Product_Recieved_PWID_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Product_Recieved_PWID_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Product_Recieved_PWID_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-KP_Condom Distribution gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP Condom Distribution gap\n",
    "def process_KP_Condom_Distribution_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP Condom Distribution gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for condom distribution metrics\n",
    "            \"NTHRIP-Number of Condoms distributed during the reporting period\",  # Total condoms distributed\n",
    "            \"NTHRIP-Number of Condoms distributed during the reporting period (Total Male Condoms)\",  # Male condoms distributed\n",
    "            \"NTHRIP-Number of Condoms distributed during the reporting period (Total Female Condoms)\"  # Female condoms distributed\n",
    "        ]  # Defines columns for condom distribution analysis\n",
    "        name = \"KP Prev_KP-Condom Distribution Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-KP_Condom Distribution by male and female gap\"]  # Names for calculated gap columns (preserves typo: 'femalegap')\n",
    "        report_name = f\"{name}55\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include condom distribution columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate condom distribution gap (requires numpy as np)\n",
    "            df_main[df_columns[1:3]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of male and female condoms differs from total\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for condom distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds condom distribution gap column (original comment incorrectly references PrEP type gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_Condom_Distribution_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_Condom_Distribution_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_Condom_Distribution_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_Condom_Distribution_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_Condom_Distribution_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_Condom_Distribution_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_Condom_Distribution_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_Condom_Distribution_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_Condom_Distribution_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero condom distribution gaps\n",
    "            report_description = (  # Define description for condom distribution gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for condom distribution\n",
    "            )  # Describe condom distribution gap issue (original comment incorrectly references PrEP type gap)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_Condom_Distribution_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_Condom_Distribution_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_Condom_Distribution_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_Condom_Distribution_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-KP_Condom Lubricants Distribution gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP Lubricants Distribution gap\n",
    "def process_KP_Lubricants_Distribution_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP Lubricants Distribution gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for lubricant distribution metrics\n",
    "            \"NTHRIP-Number of Lubricants distributed during the reporting period\",  # Total lubricants distributed\n",
    "            \"NTHRIP-Number of Lubricants distributed during the reporting period (Total Lubricants Distributed Male)\",  # Male-targeted lubricants distributed\n",
    "            \"NTHRIP-Number of Lubricants distributed during the reporting period(Total Lubricants Distributed Female)\"  # Female-targeted lubricants distributed (preserves missing space)\n",
    "        ]  # Defines columns for lubricant distribution analysis\n",
    "        name = \"KP Prev_KP-Condom Lubricants Distribution Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-KP_Condom Lubricants distribution by male and female gap\"]  # Names for calculated gap columns (preserves typo: 'femalegap')\n",
    "        report_name = f\"{name}56\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include lubricant distribution columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate lubricant distribution gap (requires numpy as np)\n",
    "            df_main[df_columns[1:3]].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of male and female lubricants differs from total\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for lubricant distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds lubricant distribution gap column (original comment incorrectly references condom distribution gap)\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_Lubricants_Distribution_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_Lubricants_Distribution_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_Lubricants_Distribution_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_Lubricants_Distribution_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_Lubricants_Distribution_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_Lubricants_Distribution_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_Lubricants_Distribution_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_Lubricants_Distribution_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_Lubricants_Distribution_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero lubricant distribution gaps\n",
    "            report_description = (  # Define description for lubricant distribution gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for lubricant distribution\n",
    "            )  # Describe lubricant distribution gap issue \n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_Lubricants_Distribution_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_Lubricants_Distribution_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_Lubricants_Distribution_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_Lubricants_Distribution_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_GP PrEP Enrolment gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Enrolment gap\n",
    "def process_KP_PrEP_Enrolment_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Enrolment gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PrEP enrolment metrics\n",
    "            \"NTHRIP-Number of individuals who were newly enrolled on pre-exposure prophylaxis (PrEP) to prevent HIV infection in the reporting period\",  # Total individuals newly enrolled on PrEP\n",
    "            \"NTHRIP-Number of individuals who were newly enrolled on pre-exposure prophylaxis (PrEP) to prevent HIV infection in the reporting period: Pregnancy/breastfeeding status\",  # PrEP enrolment by pregnancy/breastfeeding status\n",
    "            \"NTHRIP-Number of individuals who were newly enrolled on pre-exposure prophylaxis (PrEP) to prevent HIV infection in the reporting period: PrEP Type\",  # PrEP enrolment by type\n",
    "            \"NTHRIP-Number of individuals who were newly enrolled on pre-exposure prophylaxis (PrEP) to prevent HIV infection in the reporting period: PrEP Distribution\"  # PrEP enrolment by distribution channel\n",
    "        ]  # Defines columns for PrEP enrolment analysis\n",
    "        df_name_preg_breastfeeding = ['Pregnant', 'Breastfeeding']  # Pregnancy/breastfeeding status categories\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total PrEP enrolment\n",
    "            f\"{df_columns[1]} ({df_name_preg_breastfeeding[0]}, {df_name_preg_breastfeeding[1]})\",  # Aggregated pregnancy/breastfeeding status\n",
    "            f\"{df_columns[2]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[3]} ({df_name_distribution[0]}, {df_name_distribution[1]})\"  # Aggregated distribution channels\n",
    "        ]  # Defines specific columns for gap calculations\n",
    "        name = \"KP Prev_PrEP-GP Enrolment Gap\"  # Base name for report (preserves typo: 'GP')\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-PrEP_GP PrEP enrolment by pregnancy/breastfeeding status gap\",  # Gap by pregnancy/breastfeeding status (preserves typo: 'GP')\n",
    "            \"KP Prev-PrEP_GP PrEP enrolment by type gap\",  # Gap by PrEP type (preserves typo: 'GP')\n",
    "            \"KP Prev-PrEP-GP PrEP enrolment by distribution gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for PrEP enrolment metrics\n",
    "        report_name = f\"{name}57\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP enrolment columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate pregnancy/breastfeeding gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if pregnancy/breastfeeding enrolment exceeds total\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for pregnancy/breastfeeding gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds pregnancy/breastfeeding gap column (original comment incorrectly references lubricant distribution gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP type gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[0]],  # Check if PrEP type enrolment differs from total\n",
    "            df_main[df_columns[2]] - df_main[df_columns[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references lubricant distribution gap)\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate distribution gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[0]],  # Check if distribution enrolment differs from total\n",
    "            df_main[df_columns[3]] - df_main[df_columns[0]],  # Calculate difference for distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds distribution gap column (original comment incorrectly references lubricant distribution gap)\n",
    "\n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(df_columns, df_columns_spec))  # Map original columns to specific names\n",
    "        )  # Renames columns for better readability\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Enrolment_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Enrolment_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Enrolment_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Enrolment_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Enrolment_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Enrolment_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Enrolment_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Enrolment_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Enrolment_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero pregnancy/breastfeeding gaps\n",
    "            report_description.append(  # Add description for pregnancy/breastfeeding gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns_spec[0]}\"  # Describe expected relation for pregnancy/breastfeeding\n",
    "            )  # Describe pregnancy/breastfeeding gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero distribution gaps\n",
    "            report_description.append(  # Add description for distribution gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for distribution\n",
    "            )  # Describe distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Enrolment_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Enrolment_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Enrolment_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Enrolment_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_GP PrEP Restart gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Restart gap\n",
    "def process_KP_PrEP_Restart_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Restart gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for PrEP restart metrics\n",
    "            \"NTHRIP-Number of individuals that returned for a follow-up or re-initiation visit to receive PrEP during the reporting period\",  # Total individuals restarting or following up on PrEP\n",
    "            \"NTHRIP-Number of individuals that returned for a follow-up or re-initiation visit to receive PrEP during the reporting period: Pregnancy/breastfeeding status\",  # PrEP restart by pregnancy/breastfeeding status\n",
    "            \"NTHRIP-Number of individuals that returned for a follow-up or re-initiation visit to receive PrEP during the reporting period: PrEP Type\",  # PrEP restart by type\n",
    "            \"NTHRIP-Number of individuals that returned for a follow-up or re-initiation visit to receive PrEP during the reporting period: PrEP Distribution\"  # PrEP restart by distribution channel\n",
    "        ]  # Defines columns for PrEP restart analysis\n",
    "        df_name_preg_breastfeeding = ['Pregnant', 'Breastfeeding']  # Pregnancy/breastfeeding status categories\n",
    "        df_name_type = ['Injectable', 'Oral', 'Others']  # Types of PrEP products\n",
    "        df_name_distribution = ['Community', 'Facility']  # Distribution channels for PrEP\n",
    "        df_columns_spec = [  # Specific columns for gap analysis\n",
    "            df_columns[0],  # Total PrEP restart\n",
    "            f\"{df_columns[1]} ({df_name_preg_breastfeeding[0]}, {df_name_preg_breastfeeding[1]})\",  # Aggregated pregnancy/breastfeeding status\n",
    "            f\"{df_columns[2]} ({df_name_type[0]}, {df_name_type[1]}, {df_name_type[2]})\",  # Aggregated PrEP types\n",
    "            f\"{df_columns[3]} ({df_name_distribution[0]}, {df_name_distribution[1]})\"  # Aggregated distribution channels\n",
    "        ]  # Defines specific columns for gap calculations\n",
    "        name = \"KP Prev_PrEP-GP Restart Gap\"  # Base name for report (preserves typo: 'GP')\n",
    "        gap_columns = [  # Names for calculated gap columns\n",
    "            \"KP Prev-PrEP_GP PrEP Restart by pregnancy/breastfeeding status gap\",  # Gap by pregnancy/breastfeeding status (preserves typo: 'GP')\n",
    "            \"KP Prev-PrEP_GP PrEP Restart by type gap\",  # Gap by PrEP type (preserves typo: 'GP')\n",
    "            \"KP Prev-PrEP-GP PrEP Restart by distribution gap\"  # Gap by distribution channel\n",
    "        ]  # Defines gap columns for PrEP restart metrics\n",
    "        report_name = f\"{name}58\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP restart columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate pregnancy/breastfeeding gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  # Check if pregnancy/breastfeeding restart exceeds total\n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  # Calculate difference for pregnancy/breastfeeding gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds pregnancy/breastfeeding gap column (original comment incorrectly references lubricant distribution gap)\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate PrEP type gap\n",
    "            df_main[df_columns[2]] != df_main[df_columns[0]],  # Check if PrEP type restart differs from total\n",
    "            df_main[df_columns[2]] - df_main[df_columns[0]],  # Calculate difference for PrEP type gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds PrEP type gap column (original comment incorrectly references lubricant distribution gap)\n",
    "        df_main[gap_columns[2]] = np.where(  # Calculate distribution gap\n",
    "            df_main[df_columns[3]] != df_main[df_columns[0]],  # Check if distribution restart differs from total\n",
    "            df_main[df_columns[3]] - df_main[df_columns[0]],  # Calculate difference for distribution gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds distribution gap column (original comment incorrectly references lubricant distribution gap)\n",
    "\n",
    "        df_main = df_main.rename(  # Rename columns for clarity\n",
    "            columns=dict(zip(df_columns, df_columns_spec))  # Map original columns to specific names\n",
    "        )  # Renames columns for better readability\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Restart_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Restart_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Restart_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Restart_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Restart_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Restart_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Restart_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Restart_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Restart_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero pregnancy/breastfeeding gaps\n",
    "            report_description.append(  # Add description for pregnancy/breastfeeding gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns_spec[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns_spec[0]}\"  # Describe expected relation for pregnancy/breastfeeding\n",
    "            )  # Describe pregnancy/breastfeeding gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero PrEP type gaps\n",
    "            report_description.append(  # Add description for PrEP type gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns_spec[2]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for PrEP type\n",
    "            )  # Describe PrEP type gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[2]] != 0).any():  # Check for non-zero distribution gaps\n",
    "            report_description.append(  # Add description for distribution gap\n",
    "                f\"Report Name: {gap_columns[2]}\\n\"\n",
    "                f\"{df_columns_spec[3]}\\n\"\n",
    "                f\"should be equal to {df_columns_spec[0]}\"  # Describe expected equality for distribution\n",
    "            )  # Describe distribution gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines for clarity\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns_spec,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Restart_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Restart_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Restart_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Restart_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_MSF PrEP Eligible gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Eligible gap\n",
    "def process_KP_PrEP_Eligible_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Eligible gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = ['No. of individuals who were eligible and started PrEP in the reporting month']  # Column for total eligible individuals starting PrEP\n",
    "        high_risk_kp = [  # List of high-risk key population categories\n",
    "            'Serodiscordant Couples (SDC)', 'SW', 'Partners of Sex Workers', 'Injecting Drug Users',\n",
    "            'Individuals who engage in anal sex on a prolonged and regular basis', \n",
    "            'Exposed adolescents and young people', 'Transgender People', 'Other population'\n",
    "        ]  # Defines key populations for PrEP eligibility analysis\n",
    "        name = \"KP Prev_PrEP-MSF Eligible Gap\"  # Base name for report (preserves typo: 'MSF')\n",
    "        gap_columns = [\"KP Prev-PrEP_MSF PrEP eligible by KP risk population gap\"]  # Name for calculated gap column (preserves typo: 'MSF')\n",
    "        report_name = f\"{name}59\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP eligibility column\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references PrEP restart columns)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        df_main2 = DHIS2_data['KP Prev MSF_PrEP_eligible_for_pk_at_risk'][MSF_hierarchy + high_risk_kp].copy()  # Copy DataFrame for high-risk KP disaggregation\n",
    "        df_main = df_main.merge(  # Merge primary and high-risk KP DataFrames\n",
    "            df_main2, \n",
    "            on=MSF_hierarchy, \n",
    "            how='left'  # Left join to retain all records from df_main\n",
    "        )  # Combines total eligibility with disaggregated KP data\n",
    "\n",
    "        df_main[high_risk_kp] = df_main[high_risk_kp].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert KP columns to numeric, replacing non-numeric with 0\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap by KP risk population (requires numpy as np)\n",
    "            df_main[high_risk_kp].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of KP categories differs from total\n",
    "            df_main[high_risk_kp].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for KP eligibility gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds gap column for KP risk population\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Eligible_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Eligible_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Eligible_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Eligible_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Eligible_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Eligible_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Eligible_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Eligible_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Eligible_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero KP risk population gaps\n",
    "            report_description = (  # Add description for KP risk population gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"A sum of these KP high risk population {high_risk_kp}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for KP risk population\n",
    "            )  # Describe KP risk population gap issue (original comment incorrectly references pregnancy/breastfeeding gaps)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns + high_risk_kp,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Eligible_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Eligible_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Eligible_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Eligible_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_MSF PrEP Received gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Received gap\n",
    "def process_KP_PrEP_Received_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Received gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [\"No. of individuals who received PrEP in the reporting month\"]  # Column for PrEP received\n",
    "        high_risk_kp = [  # List of high-risk key population categories\n",
    "            'Serodiscordant Couples (SDC)', 'SW', 'Partners of Sex Workers', 'Injecting Drug Users',\n",
    "            'Individuals who engage in anal sex on a prolonged and regular basis', \n",
    "            'Exposed adolescents and young people', 'Transgender People', 'Other population'\n",
    "        ]  # Defines key populations for PrEP eligibility analysis\n",
    "        name = \"KP Prev_PrEP-MSF Received Gap\"  # Base name for report \n",
    "        gap_columns = [\"KP Prev-PrEP_MSF PrEP received by KP risk population gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}60\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP eligibility column\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references PrEP restart columns)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        df_main2 = DHIS2_data['KP Prev MSF_PrEP_received_for_pk_at_risk'][MSF_hierarchy + high_risk_kp].copy()  # Copy DataFrame for high-risk KP disaggregation\n",
    "        df_main = df_main.merge(  # Merge primary and high-risk KP DataFrames\n",
    "            df_main2, \n",
    "            on=MSF_hierarchy, \n",
    "            how='left'  # Left join to retain all records from df_main\n",
    "        )  # Combines total eligibility with disaggregated KP data\n",
    "\n",
    "        df_main[high_risk_kp] = df_main[high_risk_kp].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert KP columns to numeric, replacing non-numeric with 0\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap by KP risk population (requires numpy as np)\n",
    "            df_main[high_risk_kp].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of KP categories differs from total\n",
    "            df_main[high_risk_kp].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for KP eligibility gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds gap column for KP risk population\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Received_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Received_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Received_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Received_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Received_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Received_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Received_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Received_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Received_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero KP risk population gaps\n",
    "            report_description = (  # Add description for KP risk population gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"A sum of these KP high risk population {high_risk_kp}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for KP risk population\n",
    "            )  # Describe KP risk population gap issue (original comment incorrectly references pregnancy/breastfeeding gaps)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns + high_risk_kp,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Received_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Received_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Received_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Received_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_MSF PrEP Returned and Retested Negetive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Retest Negative gap\n",
    "def process_KP_PrEP_Retest_Negative_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Retest Negative gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [\"No. of individuals who returning for PrEP who received repeat HIV testing in the reporting month: HIV Negative\"]  # Column for individuals retested HIV negative for PrEP\n",
    "        high_risk_kp = [  # List of high-risk key population categories\n",
    "            'Serodiscordant Couples (SDC)', 'SW', 'Partners of Sex Workers', 'Injecting Drug Users',\n",
    "            'Individuals who engage in anal sex on a prolonged and regular basis', \n",
    "            'Exposed adolescents and young people', 'Transgender People', 'Other population'\n",
    "        ]  # Defines key populations for PrEP retesting analysis\n",
    "        name = \"KP Prev_PrEP-MSF RR Negative Gap\"  # Base name for report (preserves incorrect reference to 'Received')\n",
    "        gap_columns = [\"KP Prev-PrEP_MSF PrEP retested  with a negative report gap\"]  # Name for calculated gap column (preserves incorrect reference to 'Received')\n",
    "        report_name = f\"{name}61\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP retest negative column\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references PrEP eligibility column)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        df_main2 = DHIS2_data['KP Prev MSF_PrEP_returned_with_retesting_negetive_for_pk_at_risk'][MSF_hierarchy + high_risk_kp].copy()  # Copy DataFrame for high-risk KP disaggregation (preserves typo: 'negetive')\n",
    "        df_main = df_main.merge(  # Merge primary and high-risk KP DataFrames\n",
    "            df_main2, \n",
    "            on=MSF_hierarchy, \n",
    "            how='left'  # Left join to retain all records from df_main\n",
    "        )  # Combines total retest negative data with disaggregated KP data\n",
    "\n",
    "        df_main[high_risk_kp] = df_main[high_risk_kp].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert KP columns to numeric, replacing non-numeric with 0\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap by KP risk population (requires numpy as np)\n",
    "            df_main[high_risk_kp].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of KP categories differs from total\n",
    "            df_main[high_risk_kp].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for KP retest negative gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds gap column for KP risk population\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Retest_Negative_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Retest_Negative_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Retest_Negative_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Retest_Negative_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Retest_Negative_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Retest_Negative_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Retest_Negative_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Retest_Negative_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Retest_Negative_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero KP risk population gaps\n",
    "            report_description = (  # Add description for KP risk population gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"A sum of these KP high risk population {high_risk_kp}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for KP risk population\n",
    "            )  # Describe KP risk population gap issue (original comment incorrectly references pregnancy/breastfeeding gaps)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns + high_risk_kp,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Retest_Negative_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Retest_Negative_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Retest_Negative_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Retest_Negative_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_MSF PrEP Returned and Retested Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Retest Positive gap\n",
    "def process_KP_PrEP_Retest_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Retest Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [\"No. of individuals who returning for PrEP who received repeat HIV testing in the reporting month: HIV Positive\"]  # Column for individuals retested HIV negative for PrEP\n",
    "        high_risk_kp = [  # List of high-risk key population categories\n",
    "            'Serodiscordant Couples (SDC)', 'SW', 'Partners of Sex Workers', 'Injecting Drug Users',\n",
    "            'Individuals who engage in anal sex on a prolonged and regular basis', \n",
    "            'Exposed adolescents and young people', 'Transgender People', 'Other population'\n",
    "        ]  # Defines key populations for PrEP retesting analysis\n",
    "        name = \"KP Prev_PrEP-MSF RR Positive Gap\"  # Base name for report (preserves incorrect reference to 'Received')\n",
    "        gap_columns = [\"KP Prev-PrEP_MSF PrEP retested with a positive report gap\"]  # Name for calculated gap column (preserves incorrect reference to 'Received')\n",
    "        report_name = f\"{name}62\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP retest negative column\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references PrEP eligibility column)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        df_main2 = DHIS2_data['KP Prev MSF_PrEP_returned_with_retesting_positive_for_pk_at_risk'][MSF_hierarchy + high_risk_kp].copy()  # Copy DataFrame for high-risk KP disaggregation (preserves typo: 'negetive')\n",
    "        df_main = df_main.merge(  # Merge primary and high-risk KP DataFrames\n",
    "            df_main2, \n",
    "            on=MSF_hierarchy, \n",
    "            how='left'  # Left join to retain all records from df_main\n",
    "        )  # Combines total retest negative data with disaggregated KP data\n",
    "\n",
    "        df_main[high_risk_kp] = df_main[high_risk_kp].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert KP columns to numeric, replacing non-numeric with 0\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap by KP risk population (requires numpy as np)\n",
    "            df_main[high_risk_kp].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of KP categories differs from total\n",
    "            df_main[high_risk_kp].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for KP retest negative gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds gap column for KP risk population\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Retest_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Retest_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Retest_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Retest_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Retest_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Retest_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Retest_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Retest_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Retest_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero KP risk population gaps\n",
    "            report_description = (  # Add description for KP risk population gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"A sum of these KP high risk population {high_risk_kp}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for KP risk population\n",
    "            )  # Describe KP risk population gap issue (original comment incorrectly references pregnancy/breastfeeding gaps)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns + high_risk_kp,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Retest_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Retest_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Retest_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Retest_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-PrEP_MSF PrEP Discontinue gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP PrEP Retest Positive gap\n",
    "def process_KP_PrEP_Discontinued_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP PrEP Retest Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled DataFrame and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [\"No. of individuals who discontinued PrEP\"]  # Column for individuals retested HIV negative for PrEP\n",
    "        high_risk_kp = [  # List of high-risk key population categories\n",
    "            'Serodiscordant Couples (SDC)', 'SW', 'Partners of Sex Workers', 'Injecting Drug Users',\n",
    "            'Individuals who engage in anal sex on a prolonged and regular basis', \n",
    "            'Exposed adolescents and young people', 'Transgender People', 'Other population'\n",
    "        ]  # Defines key populations for analysis\n",
    "        name = \"KP Prev_PrEP-MSF PrEP Discontined Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev-PrEP_MSF PrEP discontinued gap\"]  # Name for calculated gap column\n",
    "        report_name = f\"{name}63\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include PrEP retest negative column\n",
    "        )  # Returns processed DataFrame or None if failed (original comment incorrectly references PrEP eligibility column)\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "\n",
    "        df_main2 = DHIS2_data['KP Prev MSF_PrEP_discountined_for_pk_at_risk'][MSF_hierarchy + high_risk_kp].copy()  # Copy DataFrame for high-risk KP disaggregation (preserves typo: 'negetive')\n",
    "        df_main = df_main.merge(  # Merge primary and high-risk KP DataFrames\n",
    "            df_main2, \n",
    "            on=MSF_hierarchy, \n",
    "            how='left'  # Left join to retain all records from df_main\n",
    "        )  # Combines total retest negative data with disaggregated KP data\n",
    "\n",
    "        df_main[high_risk_kp] = df_main[high_risk_kp].apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert KP columns to numeric, replacing non-numeric with 0\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate gap by KP risk population (requires numpy as np)\n",
    "            df_main[high_risk_kp].sum(axis=1) != df_main[df_columns[0]],  # Check if sum of KP categories differs from total\n",
    "            df_main[high_risk_kp].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for KP retest negative gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds gap column for KP risk population\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_PrEP_Discontinued_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_PrEP_Discontinued_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_PrEP_Discontinued_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_PrEP_Discontinued_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_PrEP_Discontinued_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_PrEP_Discontinued_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_PrEP_Discontinued_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_PrEP_Discontinued_gap.cached_style = df_main_gap_style  # Store styled DataFrame in cache\n",
    "        process_KP_PrEP_Discontinued_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape in cache\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero KP risk population gaps\n",
    "            report_description = (  # Add description for KP risk population gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"A sum of these KP high risk population {high_risk_kp}\\n\"\n",
    "                f\"should be equal to {df_columns[0]}\"  # Describe expected equality for KP risk population\n",
    "            )  # Describe KP risk population gap issue (original comment incorrectly references pregnancy/breastfeeding gaps)\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns + high_risk_kp,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display output is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_PrEP_Discontinued_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_PrEP_Discontinued_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_PrEP_Discontinued_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_PrEP_Discontinued_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS TST gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS and Positive gap\n",
    "def process_KP_HTS_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"Number of key population receiving HIV prevention services - (defined packages of services by topology)\",  # KP receiving HIV prevention services\n",
    "            \"Number of KPs that received HIS Test during the reporting period and know their HIV status - Total Walk-In\",  # KPs testing positive via walk-in\n",
    "            \"Number of KPs that received HIS Test during the reporting period and know their HIV status - Total Community\",  # KPs testing positive via community\n",
    "            \"Number of KPs who tested HIV Positive during the reporting period - Total Walk-In\",    # KPs testing positive via walk-in\n",
    "            \"Number of KPs who tested HIV Positive during the reporting period - Total Community\"   # KPs testing positive via community\n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS HTS and Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\n",
    "            \"KP Prev HTS (Walk-In and Community) gap\",\n",
    "            \"KP Prev HTS positive (Walk-In and Community) gap\"\n",
    "        ]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}64\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1:3]].sum(axis=1) > df_main[df_columns[0]],  # Check if total tested (walk-in + community) exceeds prevention services\n",
    "            df_main[df_columns[1:3]].sum(axis=1) - df_main[df_columns[0]],  # Calculate difference for HTS gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds HTS gap column\n",
    "        df_main[gap_columns[1]] = np.where(  # Calculate KP HTS Positive gap\n",
    "            df_main[df_columns[3:5]].sum(axis=1) > df_main[df_columns[1:3]].sum(axis=1),  # Check if total positive (walk-in + community) exceeds total tested\n",
    "            df_main[df_columns[3:5]].sum(axis=1) - df_main[df_columns[1:3]].sum(axis=1),  # Calculate difference for Positive gap\n",
    "            0  # Set to 0 if no gap\n",
    "        )  # Adds Positive gap column\n",
    "\n",
    "        order_columns = MSF_hierarchy + [  # Define column order for DataFrame\n",
    "            df_columns[0],  # KP receiving HIV prevention services\n",
    "            df_columns[1],  # KP Walk-In HTS\n",
    "            df_columns[2],  # KP Community HTS\n",
    "            gap_columns[0],  # KP HTS gap\n",
    "            df_columns[3],  # KP Walk-In Positive\n",
    "            df_columns[4],  # KP Community Positive\n",
    "            gap_columns[1]  # KP Positive gap\n",
    "        ]  # Specifies ordered columns for clarity\n",
    "\n",
    "        df_main = df_main[order_columns]  # Reorder DataFrame columns to match specified order\n",
    "        df_main = df_main.reset_index(drop=True)  # Reset index to ensure clean DataFrame structure\n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        report_description = []  # Initialize list for report descriptions\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description.append(  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\nplus {df_columns[2]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            )  # Describe HTS gap issue\n",
    "        if (df_main_gap[gap_columns_wrap[1]] != 0).any():  # Check for non-zero Positive gaps\n",
    "            report_description.append(  # Add description for Positive gap\n",
    "                f\"Report Name: {gap_columns[1]}\\n\"\n",
    "                f\"{df_columns[3]}\\nplus {df_columns[4]}\\n\"\n",
    "                f\"should not be greater than {df_columns[1]} plus {df_columns[2]}\"  # Describe expected relation for Positive\n",
    "            )  # Describe Positive gap issue\n",
    "        report_description = \"\\n\\n\".join(report_description)  # Join descriptions with double newlines\n",
    "\n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-3b (TG) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 3b and Positive gap\n",
    "def process_KP_HTS_3b_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 3b and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-3b Number of TG that have received an HIV test during the reporting period in KP-specific programs and know their results\",\n",
    "            \"HTS-3b Number of TG that have received an HIV test during the reporting period in KP-specific programs and HIV positive results\"\n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 3b (TG) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 3b positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}65\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_3b_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_3b_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_3b_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_3b_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_3b_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_3b_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_3b_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_3b_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_3b_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_3b_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_3b_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_3b_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_3b_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-3c (SW) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 3c and Positive gap\n",
    "def process_KP_HTS_3c_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 3c and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-3c Number of sex workers that have received an HIV test during the reporting period in KP-specific programs and know their results\",\n",
    "            \"HTS-3c Number of sex workers that have received an HIV test during the reporting period in KP-specific programs and received HIV-positive results\"   \n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 3c (SW) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 3c positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}66\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_3c_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_3c_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_3c_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_3c_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_3c_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_3c_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_3c_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_3c_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_3c_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_3c_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_3c_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_3c_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_3c_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-3d (PWID) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 3d and Positive gap\n",
    "def process_KP_HTS_3d_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 3d and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-3d Number of people who inject drugs (PWID) that have received an HIV test during the reporting period in KP-specific programs and know their results\",\n",
    "            \"HTS-3d Number of people who inject drugs (PWID) that have received an HIV test during the reporting period in KP-specific programs and received HIV positive results\"   \n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 3d (PWID) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 3d positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}67\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_3d_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_3d_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_3d_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_3d_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_3d_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_3d_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_3d_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_3d_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_3d_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_3d_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_3d_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_3d_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_3d_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-3e (OVC) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 3e and Positive gap\n",
    "def process_KP_HTS_3e_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 3e and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-3e Number of other vulnerable populations (OVP) that have received an HIV test during the reporting period and know their results\",\n",
    "            \"HTS-3e Number of other vulnerable populations (OVP) that have received an HIV test during the reporting period and received HIV-positive results\"\n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 3e (OVC) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 3e positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}68\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_3e_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_3e_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_3e_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_3e_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_3e_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_3e_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_3e_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_3e_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_3e_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_3e_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_3e_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_3e_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_3e_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-3f (Prinsons) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 3f and Positive gap\n",
    "def process_KP_HTS_3f_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 3f and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-3f Number of people in prisons and other closed settings that have received an HIV test during the reporting period and know their results \",\n",
    "            \"HTS-3f Number of people in prisons and other closed settings that have received an HIV test during the reporting period and received HIV-positive results\"\n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 3f (Prisons) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 3f positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}69\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_3f_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_3f_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_3f_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    print(print_display_name)\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_3f_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_3f_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_3f_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_3f_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_3f_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_3f_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_3f_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_3f_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_3f_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_3f_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------\n",
    "\n",
    "### - KP-HTS HTS-2 (AGYQ) Positive gap\n",
    "# -----------------------------------------------------------------------------------------\n",
    "# -- Define the main function to process KP HTS 2 and Positive gap\n",
    "def process_KP_HTS_2_Positive_gap(display_output=None):\n",
    "    \"\"\"\n",
    "    Process KP HTS 2 and Positive gap, exporting results as image, Excel, and Word files.\n",
    "    Caches the styled df and displays it on subsequent calls if data shape unchanged.\n",
    "    \n",
    "    Args:\n",
    "        display_output (bool, optional): If True, displays the df for gap. Defaults to None (treated as False unless explicitly True).\n",
    "    \"\"\"\n",
    "    try:  # Begin exception handling for robust error management\n",
    "        # -- Step 1: Initialize constants\n",
    "        df_columns = [  # List of column names for KP HTS and Positive metrics\n",
    "            \"HTS-2 Percentage of high risk AGYW that have received an HIV test during the reporting period in AGYW programs\",\n",
    "            \"HTS-2 Percentage of high-risk AGYW that have received an HIV test during the reporting period in AGYW programs that tested positive for HIV\"\n",
    "        ]  # Defines columns for KP HTS and Positive analysis\n",
    "        name = \"KP Prev_HTS 2 (AGYW) Positive Gap\"  # Base name for report\n",
    "        gap_columns = [\"KP Prev HTS 2 positive gap\"]  # Names for calculated gap columns\n",
    "        report_name = f\"{name}70\"  # Report name with unique suffix\n",
    "        No_gap_msg = f\"No {report_name}\"  # Message to display if no gaps are found\n",
    "        display_name = f\"✔️ Displaying {report_name}\"  # Formatted display name for output\n",
    "        display_line = \"-\" * (len(display_name) + 1)  # Create separator line based on display name length          \n",
    "        print_display_name = f\"{display_line}\\n{display_name}\\n{display_line}\"  # Combined string for display header\n",
    "\n",
    "        # -- Step 2: Fetch and prepare primary data\n",
    "        df_main = prepare_and_convert_df(  # Fetch and prepare DataFrame from DHIS2\n",
    "            DHIS2_data_key=\"KP Prev MSF\",  # Key to fetch KP Prev MSF dataset\n",
    "            hierarchy_columns=MSF_hierarchy,  # Predefined MSF hierarchy columns (assumed defined elsewhere)\n",
    "            data_columns=df_columns  # Include KP HTS and Positive columns\n",
    "        )  # Returns processed DataFrame or None if failed\n",
    "        if df_main is None:  # Check if data preparation failed or returned empty\n",
    "            return  # Exit function if no valid data\n",
    "        \n",
    "        # -- Step 3: Calculate gaps\n",
    "        df_main[gap_columns[0]] = np.where(  # Calculate KP HTS gap (requires numpy as np)\n",
    "            df_main[df_columns[1]] > df_main[df_columns[0]],  \n",
    "            df_main[df_columns[1]] - df_main[df_columns[0]],  \n",
    "            0  # Set to 0 if no gap\n",
    "        )  \n",
    "\n",
    "        # -- Step 4: Wrap column headers for better readability\n",
    "        wrap_column_headers(df_main)  # Format DataFrame column headers (assumed function)\n",
    "        gap_columns_wrap = wrap_column_headers2(gap_columns)  # Wrap gap column names for display\n",
    "\n",
    "        # -- Step 5: Check and display cached styled DataFrame\n",
    "        if display_output:  # Check if display output is requested\n",
    "            if hasattr(process_KP_HTS_2_Positive_gap, 'cached_style'):  # Check if cached styled DataFrame exists\n",
    "                cached_shape = getattr(process_KP_HTS_2_Positive_gap, 'cached_shape', None)  # Retrieve cached DataFrame shape\n",
    "                current_shape = df_main.shape  # Get current unfiltered DataFrame shape\n",
    "                if cached_shape == current_shape:  # Compare shapes to use cached version\n",
    "                    display = process_KP_HTS_2_Positive_gap.cached_style  # Retrieve cached styled DataFrame\n",
    "                    widget_display_df(display)  # Display cached styled DataFrame (assumed widget function)\n",
    "                return  # Exit to avoid reprocessing\n",
    "\n",
    "        # -- Step 6: Filter and validate gaps\n",
    "        df_main_gap = filter_gap_and_check_empty_df(  # Filter DataFrame for rows with non-zero gaps\n",
    "            df=df_main,  # Input DataFrame with gap columns\n",
    "            msg=No_gap_msg,  # Message to display if no gaps\n",
    "            opNonZero=gap_columns_wrap,  # Filter for non-zero gap values\n",
    "            opNeg=None,  # No negative value filter\n",
    "            opPos=None,  # No positive value filter\n",
    "            opZero=None,  # No zero value filter\n",
    "            opLT100=None  # No less-than-100 filter\n",
    "        )  # Returns filtered DataFrame or None if no gaps\n",
    "        if df_main_gap is None:  # Check if no gaps were found\n",
    "            if hasattr(process_KP_HTS_2_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "                del process_KP_HTS_2_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "            if hasattr(process_KP_HTS_2_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "                del process_KP_HTS_2_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "            return  # Exit function if no gaps\n",
    "\n",
    "        # -- Step 7: Style the filtered DataFrame\n",
    "        df_main_gap_style = (  # Apply styling to filtered DataFrame\n",
    "            df_main_gap.style  # Create style object from filtered DataFrame\n",
    "            .hide(axis='index')  # Hide row index for cleaner display\n",
    "            .map(outlier_red, subset=gap_columns_wrap)  # Highlight non-zero gaps in red (assumed function)\n",
    "        )  # Creates styled DataFrame for display/export\n",
    "\n",
    "        # -- Step 8: Cache styled DataFrame and shape\n",
    "        process_KP_HTS_2_Positive_gap.cached_style = df_main_gap_style  # Store styled DataFrame\n",
    "        process_KP_HTS_2_Positive_gap.cached_shape = df_main.shape  # Store original unfiltered DataFrame shape\n",
    "\n",
    "        # -- Step 9: Prepare export variables\n",
    "        report_month = df_main_gap['ReportPeriod'].iloc[0]  # Extract report period from filtered DataFrame\n",
    "        report_image_name = f\"{report_month}_{report_name}.png\"  # Create image file name with report month\n",
    "        report_image_path = f\"{sub_folder2_image_file_msf_outlier}\"  # Define image file path (assumed defined)\n",
    "        report_sheet_name = report_name  # Define Excel sheet name same as report name\n",
    "\n",
    "        # -- Step 10: Create descriptions for Word document\n",
    "        if (df_main_gap[gap_columns_wrap[0]] != 0).any():  # Check for non-zero HTS gaps\n",
    "            report_description = (  # Add description for HTS gap\n",
    "                f\"Report Name: {gap_columns[0]}\\n\"\n",
    "                f\"{df_columns[1]}\\n\"\n",
    "                f\"should not be greater than {df_columns[0]}\"  # Describe expected relation for HTS\n",
    "            ) \n",
    "        # -- Step 11: Export results to multiple formats\n",
    "        if not display_output:\n",
    "            export_df_to_doc_image_excel(  # Export styled DataFrame to image, Excel, and Word\n",
    "                report_name=report_name,  # Report name for file naming\n",
    "                df_style=df_main_gap_style,  # Styled DataFrame for export\n",
    "                img_file_name=report_image_name,  # Image file name\n",
    "                img_file_path=report_image_path,  # Image file path\n",
    "                doc_description=report_description,  # Word document description\n",
    "                doc_indicators_to_italicize=df_columns,  # Italicize input columns\n",
    "                doc_indicators_to_underline=gap_columns,  # Underline gap columns\n",
    "                xlm_file_path=doc_file_msf_outlier_xlsx,  # Excel file path (assumed defined)\n",
    "                xlm_sheet_name=report_sheet_name  # Excel sheet name\n",
    "            )  # Exports to specified formats\n",
    "\n",
    "        # -- Step 12: Display styled DataFrame if requested\n",
    "        if display_output:  # Check if display is requested\n",
    "            print(print_display_name)\n",
    "            widget_display_df(df_main_gap_style)  # Display styled DataFrame (assumed widget function)\n",
    "\n",
    "    except Exception as e:  # Catch any processing errors\n",
    "        print(f\"⦸ Error processing {report_name}: {str(e)}\")  # Print error with report name\n",
    "        if hasattr(process_KP_HTS_2_Positive_gap, 'cached_style'):  # Check for cached style\n",
    "            del process_KP_HTS_2_Positive_gap.cached_style  # Clear cached styled DataFrame\n",
    "        if hasattr(process_KP_HTS_2_Positive_gap, 'cached_shape'):  # Check for cached shape\n",
    "            del process_KP_HTS_2_Positive_gap.cached_shape  # Clear cached DataFrame shape\n",
    "        return  # Exit on error\n",
    "# End of the function ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b7a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .custom-vbox {\n",
       "        background-color: #e8e8e8f6 !important;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .custom-vbox {\n",
       "        background-color: #e8e8e8da !important;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63d8f9984c446099eaba8435a078860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HBox(children=(Button(description='Main Actions ▼', layout=Layout(border_bottom=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -- List of function descriptions for display\n",
    "function_description_name = [\n",
    "    \"Get Data\",  # Description for LGA report rate gap\n",
    "    \"ANSO Report Rate\",  # Description for LGA report rate gap\n",
    "    \"LGA Report Rate\",  # Description for facility report rate gap\n",
    "    \"AGYW HTS\",  # Description for AGYW HTS gap\n",
    "    \"AGYW Pos\",  # Description for AGYW positive gap\n",
    "    \"AGYW Pos Linkage\",  # Description for AGYW positive linkage gap\n",
    "    \"AGYW TB Screening\",  # Description for AGYW TB screening gap\n",
    "    \"ART PosEnrolment\",  # Description for ART positive enrolment gap\n",
    "    \"ART-3 subsets\",  # Description for ART regimen line, MMD and DSD\n",
    "    \"ART Tx_New TB Screening\",  # Description for ART Tx_New TB screening gap\n",
    "    \"ART TB Presumptive Test\",  # Description for ART TB presumptive test gap\n",
    "    \"ART TB Treatment\",  # Description for ART TB treatment gap\n",
    "    \"ART Viral Load Suppression\",  # Description for ART viral load suppression gap\n",
    "    \"HTS New Positive\",  # Description for HTS new positive gap\n",
    "    \"HTS TB Screening\",  # Description for HTS TB screening gap\n",
    "    \"HTS Enrolment\",  # Description for HTS enrolment\n",
    "    \"HTS Discordant Couples Test\",  # Description for HTS discordant couple testing gap\n",
    "    \"HTS CD4 Test\",  # Description for HTS CD4 test result gap\n",
    "    \"HIVST Mode\",  # Description for HIVST distribution mode gap\n",
    "    \"HIVST Test Freq.\",  # Description for HIVST distribution mode gap\n",
    "    \"HIVST Result\",  # Description for HIVST result gap\n",
    "    \"HIVST Reactive Link\",  # Description for HIVST reactive, confirmation and linkage gap\n",
    "    \"HIVST Prevention Service\",  # Description for HIVST prevention service and linkage gap\n",
    "    \"HIVST Partner Screening\",  # Description for HIVST partner screening gap\n",
    "    \"ICT Index Acceptance\",  # Description for ICT index acceptance gap\n",
    "    \"ICT Contact\",  # Description for ICT contact gap\n",
    "    \"ICT HTS\",  # Description for ICT HTS gap\n",
    "    \"ICT Positive Linkage\",  # Description for ICT positive linkage gap\n",
    "    \"PMTCT New ANC HTS\",  # Description for PMTCT new ANC gap\n",
    "    \"PMTCT Positive\",  # Description for PMTCT positive gap\n",
    "    \"PMTCT Previously Known\",  # Description for PMTCT previously known gap\n",
    "    \"PMTCT Positive Linkage\",  # Description for PMTCT positive linkage\n",
    "    \"PMTCT Seroconversion\",  # Description for PMTCT seroconversion gap\n",
    "    \"PMTCT Syphilis Test\",  # Description for PMTCT syphilis test gap\n",
    "    \"PMTCT Hepatitis Test\",  # Description for PMTCT hepatitis test gap\n",
    "    \"PMTCT Labour and Delivery\",  # Description for PMTCT labour and delivery gap\n",
    "    \"PMTCT Facility HEI ARVs\",  # Description for PMTCT facility HEI ARVs gap\n",
    "    \"PMTCT EID PCR Test\",  # Description for PMTCT EID PCR test gap\n",
    "    \"PMTCT EID PCR Test Result\",  # Description for PMTCT EID PCR test result gap\n",
    "    \"NSP Newly Recruited\",  # Description for NSP Newly recruited gap\n",
    "    \"NSP HTS Positive Linkage\",  # Description for NSP HTS positive linkage gap\n",
    "    \"NSP Coinfection Treatment\",  # Description for NSP coinfection treatment gap\n",
    "    \"NSP Substance Abuse\",  # Description for NSP substance abuse gap\n",
    "    \"NSP MAT Referral\",  # Description for NSP MAT referral gap\n",
    "    \"KP Prev MHS\",  # Description for KP Prev MHS gap\n",
    "    \"KP Prev MSH Access Type\",  # Description for KP Prev MSH access type gap\n",
    "    \"KP GBV CSR\",  # Description for KP Prev GBV CSR gap\n",
    "    \"KP GBV Post GBV\",  # Description for KP Prev GBV post GBV gap\n",
    "    \"KP KP_GBV IVA\",  # Description for KP Prev GBV incident of voilence or abuse\n",
    "    \"KP KP_GBV Legal Support\",  # Description for KP Prev GBV legal support gap\n",
    "    \"KP PEP\",  # Description for KP PEP gap\n",
    "    \"KP PrEP_KP Product (MSM)\",  # Description for KP PrEP product MSM gap\n",
    "    \"KP PrEP_KP Product (TG)\",  # Description for KP PrEP product TG gap\n",
    "    \"KP PrEP_KP Product (SW)\",  # Description for KP PrEP product SW gap\n",
    "    \"KP PrEP_KP Product (PWID)\",  # Description for KP PrEP product PWID gap\n",
    "    \"KP KP_Condom Distribution\",  # Description for KP condom distribution gap\n",
    "    \"KP KP_Condom Lubricants\",  # Description for KP condom lubricants gap\n",
    "    \"KP PrEP_GP Enrolment\",  # Description for KP PrEP enrolment gap\n",
    "    \"KP PrEP_GP Restart\",  # Description for KP PrEP restart gap\n",
    "    \"KP PrEP_MSF PrEP Eligible\",  # Description for KP PrEP eligible gap\n",
    "    \"KP PrEP_MSF PrEP Received\", # Description for KP PrEP received gap\n",
    "    \"KP KP_PrEP R&R Negetive\",  # Description for KP PrEP returned and restested negative gap\n",
    "    \"KP KP_PrEP R&R Positive\",  # Description for KP PrEP returned and restested positive gap\n",
    "    \"KP KP_PrEP Discounted\",  # Description for KP PrEP discounted gap \n",
    "    \"KP HTS TST\",  # Description for KP HTS TST gap\n",
    "    \"KP HTS 3b (TG) Positive\",  # Description for KP HTS 3b (TG) positive gap\n",
    "    \"KP HTS 3c (SW) Positive\",  # Description for KP HTS 3c (SW) positive gap\n",
    "    \"KP HTS 3d (PWID) Positive\",  # Description for KP HTS 3d (PWID) positive gap\n",
    "    \"KP HTS 3e (OVC) Positive\",  # Description for KP HTS 3e (OVC) positive gap\n",
    "    \"KP HTS 3f (Prison) Positive\",  # Description for KP HTS 3f (Prison) positive gap\n",
    "    \"KP HTS 2 (AGYW) Positive\"  # Description for KP HTS 2 (AGYW) positive gap\n",
    "]\n",
    "\n",
    "# -- Define constants for UI elements\n",
    "ui_title = \"ANSO IHVN DHIS2 MSF Console\"  # Report title to be displayed in bold\n",
    "author = \"Reuben Edidiong\"  # Author name, kept plain due to terminal italic limitation\n",
    "version = \"msf.vlr v1.0\"  # Version identifier for the report\n",
    "ui_sepperator_line = 150  # Length of separator lines (adjustable; 80 for cleaner look)\n",
    "bold = \"\\033[1m\"  # ANSI code for bold text\n",
    "reset = \"\\033[0m\"  # ANSI code to reset formatting\n",
    "\n",
    "# -- Core components for separators\n",
    "header = f\"{bold}{ui_title}{reset} {f'© {author} {version}':>122}\"  # -- Header with bold title, right-aligned copyright\n",
    "top_line = f\"{'-' * ui_sepperator_line}\\n\"      # -- Top separator line\n",
    "bottom_line = f\"\\n{'-' * ui_sepperator_line}\"    # -- Bottom separator line\n",
    "spacing = \"\\n\" * 15                              # -- Empty line gap in ui_separator_clear\n",
    "\n",
    "# -- Separator definitions\n",
    "ui_separator_top = f\"{header}\\n{top_line}\"       # -- Top separator: header followed by a single line\n",
    "ui_separator_bottom = f\"{bottom_line}\"           # -- Bottom separator: just a single line\n",
    "ui_separator_clear = (                           # -- Full clear separator: header, top line, spacing, bottom line\n",
    "    f\"{ui_separator_top}\\n\"\n",
    "    f\"{spacing}\"\n",
    "    f\"{bottom_line}\"\n",
    ")\n",
    "\n",
    "def run_jupyter_mode():\n",
    "    \"\"\"\n",
    "    Runs an interactive Jupyter interface with buttons to execute report processing functions.\n",
    "    Group names are displayed with a maximum of 6 buttons per line, breaking to a new line for additional buttons.\n",
    "    Sub-buttons are smaller in width than main buttons and appear when a group name is clicked.\n",
    "    \n",
    "    Args:\n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        None \n",
    "    \"\"\"\n",
    "\n",
    "    # -- Step 1: Create buttons with descriptive labels\n",
    "    botton0 = widgets.Button(description=f\"{function_description_name[0]}\")\n",
    "    botton1 = widgets.Button(description=f\"{function_description_name[1]}\")\n",
    "    botton2 = widgets.Button(description=f\"{function_description_name[2]}\")\n",
    "    botton3 = widgets.Button(description=f\"{function_description_name[3]}\")\n",
    "    botton4 = widgets.Button(description=f\"{function_description_name[4]}\")\n",
    "    botton5 = widgets.Button(description=f\"{function_description_name[5]}\")\n",
    "    botton6 = widgets.Button(description=f\"{function_description_name[6]}\")\n",
    "    botton7 = widgets.Button(description=f\"{function_description_name[7]}\")\n",
    "    botton8 = widgets.Button(description=f\"{function_description_name[8]}\")\n",
    "    botton9 = widgets.Button(description=f\"{function_description_name[9]}\")\n",
    "    botton10 = widgets.Button(description=f\"{function_description_name[10]}\")\n",
    "    botton11 = widgets.Button(description=f\"{function_description_name[11]}\")\n",
    "    botton12 = widgets.Button(description=f\"{function_description_name[12]}\")\n",
    "    botton13 = widgets.Button(description=f\"{function_description_name[13]}\")\n",
    "    botton14 = widgets.Button(description=f\"{function_description_name[14]}\")\n",
    "    botton15 = widgets.Button(description=f\"{function_description_name[15]}\")\n",
    "    botton16 = widgets.Button(description=f\"{function_description_name[16]}\")\n",
    "    botton17 = widgets.Button(description=f\"{function_description_name[17]}\")\n",
    "    botton18 = widgets.Button(description=f\"{function_description_name[18]}\")\n",
    "    botton19 = widgets.Button(description=f\"{function_description_name[19]}\")\n",
    "    botton20 = widgets.Button(description=f\"{function_description_name[20]}\")\n",
    "    botton21 = widgets.Button(description=f\"{function_description_name[21]}\")\n",
    "    botton22 = widgets.Button(description=f\"{function_description_name[22]}\")\n",
    "    botton23 = widgets.Button(description=f\"{function_description_name[23]}\")\n",
    "    botton24 = widgets.Button(description=f\"{function_description_name[24]}\")\n",
    "    botton25 = widgets.Button(description=f\"{function_description_name[25]}\")\n",
    "    botton26 = widgets.Button(description=f\"{function_description_name[26]}\")\n",
    "    botton27 = widgets.Button(description=f\"{function_description_name[27]}\")\n",
    "    botton28 = widgets.Button(description=f\"{function_description_name[28]}\")\n",
    "    botton29 = widgets.Button(description=f\"{function_description_name[29]}\")\n",
    "    botton30 = widgets.Button(description=f\"{function_description_name[30]}\")\n",
    "    botton31 = widgets.Button(description=f\"{function_description_name[31]}\")\n",
    "    botton32 = widgets.Button(description=f\"{function_description_name[32]}\")\n",
    "    botton33 = widgets.Button(description=f\"{function_description_name[33]}\") \n",
    "    botton34 = widgets.Button(description=f\"{function_description_name[34]}\")\n",
    "    botton35 = widgets.Button(description=f\"{function_description_name[35]}\") \n",
    "    botton36 = widgets.Button(description=f\"{function_description_name[36]}\")\n",
    "    botton37 = widgets.Button(description=f\"{function_description_name[37]}\")\n",
    "    botton38 = widgets.Button(description=f\"{function_description_name[38]}\")\n",
    "    botton39 = widgets.Button(description=f\"{function_description_name[39]}\")\n",
    "    botton40 = widgets.Button(description=f\"{function_description_name[40]}\")\n",
    "    botton41 = widgets.Button(description=f\"{function_description_name[41]}\")\n",
    "    botton42 = widgets.Button(description=f\"{function_description_name[42]}\")\n",
    "    botton43 = widgets.Button(description=f\"{function_description_name[43]}\")\n",
    "    botton44 = widgets.Button(description=f\"{function_description_name[44]}\")\n",
    "    botton45 = widgets.Button(description=f\"{function_description_name[45]}\")\n",
    "    botton46 = widgets.Button(description=f\"{function_description_name[46]}\")\n",
    "    botton47 = widgets.Button(description=f\"{function_description_name[47]}\")\n",
    "    botton48 = widgets.Button(description=f\"{function_description_name[48]}\")\n",
    "    botton49 = widgets.Button(description=f\"{function_description_name[49]}\")\n",
    "    botton50 = widgets.Button(description=f\"{function_description_name[50]}\")\n",
    "    botton51 = widgets.Button(description=f\"{function_description_name[51]}\")\n",
    "    botton52 = widgets.Button(description=f\"{function_description_name[52]}\")\n",
    "    botton53 = widgets.Button(description=f\"{function_description_name[53]}\")\n",
    "    botton54 = widgets.Button(description=f\"{function_description_name[54]}\")\n",
    "    botton55 = widgets.Button(description=f\"{function_description_name[55]}\")\n",
    "    botton56 = widgets.Button(description=f\"{function_description_name[56]}\")\n",
    "    botton57 = widgets.Button(description=f\"{function_description_name[57]}\")\n",
    "    botton58 = widgets.Button(description=f\"{function_description_name[58]}\")\n",
    "    botton59 = widgets.Button(description=f\"{function_description_name[59]}\")\n",
    "    botton60 = widgets.Button(description=f\"{function_description_name[60]}\")\n",
    "    botton61 = widgets.Button(description=f\"{function_description_name[61]}\")\n",
    "    botton62 = widgets.Button(description=f\"{function_description_name[62]}\")\n",
    "    botton63 = widgets.Button(description=f\"{function_description_name[63]}\")\n",
    "    botton64 = widgets.Button(description=f\"{function_description_name[64]}\")\n",
    "    botton65 = widgets.Button(description=f\"{function_description_name[65]}\")\n",
    "    botton66 = widgets.Button(description=f\"{function_description_name[66]}\")\n",
    "    botton67 = widgets.Button(description=f\"{function_description_name[67]}\")\n",
    "    botton68 = widgets.Button(description=f\"{function_description_name[68]}\")\n",
    "    botton69 = widgets.Button(description=f\"{function_description_name[69]}\")\n",
    "    botton70 = widgets.Button(description=f\"{function_description_name[70]}\")\n",
    "    generate_report = widgets.Button(description=\"Export Report\") \n",
    "    clear_button = widgets.Button(description=\"Clear screen\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # -- Step 2: Define button handlers \n",
    "    def on_botton0_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            fetch_dhis2_data_interactive_jupyter_mode()\n",
    "            print(ui_separator_bottom)\n",
    "            \n",
    "    def on_botton1_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_lga_report_rate_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton2_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_facility_report_rate_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton3_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_HTS_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton4_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton5_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_Positive_Linkage_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton6_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_AGYW_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton7_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_PosEnrolment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton8_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_RegimentLine_MMD_DSD_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton9_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton10_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Presumptive_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton11_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_TB_Treatment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton12_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ART_Viral_Load_Suppression_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton13_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_New_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton14_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_TB_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton15_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_Enrolment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton16_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_Couple_Counselling_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton17_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HTS_CD4_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton18_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Distr_Mode_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton19_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Test_Freq_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton20_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Result_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton21_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Reactive_Link_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton22_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Prevention_Serv_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton23_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_HIVST_Partner_Screening_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton24_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Index_Acceptance_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton25_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Contact_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton26_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_HTS_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton27_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_ICT_Positive_Link_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton28_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_ANC_Optmz_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton29_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton30_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_PK_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton31_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Positive_Linkage_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton32_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Seroconversion_gap(display_output=True)\n",
    "            print(ui_separator_bottom) \n",
    "    \n",
    "    def on_botton33_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Syphilis_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton34_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Hepatitis_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton35_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Labour_Delivery_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton36_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_Facility_HEI_ARVs_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton37_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_EID_PCR_Test_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton38_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_PMTCT_EID_PCR_Test_Result_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton39_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_NSP_Newly_Recruited_gap(display_output=True)\n",
    "            print(ui_separator_bottom)      \n",
    "    \n",
    "    def on_botton40_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_NSP_HTS_Positive_Linkage_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton41_click(b):   \n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_NSP_Coinfection_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton42_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_NSP_Substance_Abuse_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton43_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_NSP_MAT_Referral_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton44_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_MHS_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton45_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_MHS_Access_Type_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton46_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_GBV_CSR_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton47_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_Post_GBV_SV_PEP_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton48_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_GBV_IVA_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton49_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_GBV_Legal_Support_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton50_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PEP_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton51_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Product_Recieved_MSM_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton52_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Product_Recieved_TG_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton53_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Product_Recieved_SW_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton54_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Product_Recieved_PWID_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton55_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_Condom_Distribution_gap(display_output=True)\n",
    "            print(ui_separator_bottom)    \n",
    "    \n",
    "    def on_botton56_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_Lubricants_Distribution_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton57_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Enrolment_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton58_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Restart_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton59_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Eligible_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton60_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Received_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton61_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Retest_Negative_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton62_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Retest_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton63_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_PrEP_Discontinued_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton64_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton65_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_3b_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton66_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_3c_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton67_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_3d_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton68_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_3e_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "    \n",
    "    def on_botton69_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_3f_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_botton70_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            process_KP_HTS_2_Positive_gap(display_output=True)\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    def on_clear_button_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_clear)\n",
    "\n",
    "    # List of gap functions with their descriptions for progress tracking\n",
    "    gap_functions = [\n",
    "        ('process_lga_report_rate_gap', 'LGA Report Rate Gap'),\n",
    "        ('process_facility_report_rate_gap', 'Facility Report Rate Gap'),\n",
    "        ('process_AGYW_HTS_gap', 'AGYW HTS Gap'),\n",
    "        ('process_AGYW_Positive_gap', 'AGYW Positive Gap'),\n",
    "        ('process_AGYW_Positive_Linkage_gap', 'AGYW Positive Linkage Gap'),\n",
    "        ('process_AGYW_TB_Screening_gap', 'AGYW TB Screening Gap'),\n",
    "        ('process_ART_PosEnrolment_gap', 'ART Positive-Enrolment Gap'),\n",
    "        ('process_ART_RegimentLine_MMD_DSD_gap', 'ART Regimen-Line MMD DSD Gap'),\n",
    "        ('process_ART_TB_Screening_gap', 'ART TB Screening Gap'),\n",
    "        ('process_ART_TB_Presumptive_Test_gap', 'ART TB Presumptive Test Gap'),\n",
    "        ('process_ART_TB_Treatment_gap', 'ART TB Treatment Gap'),\n",
    "        ('process_ART_Viral_Load_Suppression_gap', 'ART Viral Load Suppression Gap'),\n",
    "        ('process_HTS_New_Positive_gap', 'HTS New Positive Gap'),\n",
    "        ('process_HTS_TB_Screening_gap', 'HTS TB Screening Gap'),\n",
    "        ('process_HTS_Enrolment_gap', 'HTS Enrolment Gap'),\n",
    "        ('process_HTS_Couple_Counselling_gap', 'HTS Couple Counselling Gap'),\n",
    "        ('process_HTS_CD4_gap', 'HTS CD4 Gap'),\n",
    "        ('process_HIVST_Distr_Mode_gap', 'HIVST Distribution Mode Gap'),\n",
    "        ('process_HIVST_Test_Freq_gap', 'HIVST Testing Frequency Gap'),\n",
    "        ('process_HIVST_Result_gap', 'HIVST Result Gap'),\n",
    "        ('process_HIVST_Reactive_Link_gap', 'HIVST Reactive and Linkage Gap'),\n",
    "        ('process_HIVST_Prevention_Serv_gap', 'HIVST Prevention Service Gap'),\n",
    "        ('process_HIVST_Partner_Screening_gap', 'HIVST Partner Screening Gap'),\n",
    "        ('process_ICT_Index_Acceptance_gap', 'ICT Index Acceptance Gap'),\n",
    "        ('process_ICT_Contact_gap', 'ICT Contact Gap'),\n",
    "        ('process_ICT_HTS_gap', 'ICT HTS Gap'),\n",
    "        ('process_ICT_Positive_Link_gap', 'ICT Positive Linkage Gap'),\n",
    "        ('process_PMTCT_ANC_Optmz_gap', 'PMTCT New ANC HTS Optimization Gap'),\n",
    "        ('process_PMTCT_Positive_gap', 'PMTCT Positive Gap'),\n",
    "        ('process_PMTCT_PK_gap', 'PMTCT Previously Known Gap'),\n",
    "        ('process_PMTCT_Positive_Linkage_gap', 'PMTCT Positive Linkage Gap'),\n",
    "        ('process_PMTCT_Seroconversion_gap', 'PMTCT Seroconversion Gap'),\n",
    "        ('process_PMTCT_Syphilis_Test_gap', 'PMTCT Syphilis Test Gap'),\n",
    "        ('process_PMTCT_Hepatitis_Test_gap', 'PMTCT Hepatitis Test Gap'),\n",
    "        ('process_PMTCT_Labour_Delivery_gap', 'PMTCT Labour and Delivery Gap'),\n",
    "        ('process_PMTCT_Facility_HEI_ARVs_gap', 'PMTCT Facility HEI ARVs Gap'),\n",
    "        ('process_PMTCT_EID_PCR_Test_gap', 'PMTCT EID PCR Test Gap'),\n",
    "        ('process_PMTCT_EID_PCR_Test_Result_gap', 'PMTCT EID PCR Test Result Gap'),\n",
    "        ('process_NSP_Newly_Recruited_gap', 'NSP Newly Recruited Gap'),\n",
    "        ('process_NSP_HTS_Positive_Linkage_gap', 'NSP HTS Positive and Linkage Gap'),\n",
    "        ('process_NSP_Coinfection_gap', 'NSP Coinfection Gap'),\n",
    "        ('process_NSP_Substance_Abuse_gap', 'NSP Substance Abuse Gap'),\n",
    "        ('process_NSP_MAT_Referral_gap', 'NSP MAT Referral Gap'),\n",
    "        ('process_KP_MHS_gap', 'KP MHS and Psychosocial Support Gap'),\n",
    "        ('process_KP_MHS_Access_Type_gap', 'KP MHS and Psychosocial Support by Access Type Gap'),\n",
    "        ('process_KP_GBV_CSR_gap', 'KP GBV CSR Gap'),\n",
    "        ('process_KP_Post_GBV_SV_PEP_gap', 'KP Post GBV Sexual Violence Gap'),\n",
    "        ('process_KP_GBV_IVA_gap', 'KP Prev_KP-GBV IVA Gap'),\n",
    "        ('process_KP_GBV_Legal_Support_gap', 'KP Prev_KP-GBV Legal Support Gap'),\n",
    "        ('process_KP_PEP_gap', 'KP Prev_PEP PEP Gap'),\n",
    "        ('process_KP_PrEP_Product_Recieved_MSM_gap', 'KP Prev_KP-PrEP Product Received MSM Gap'),\n",
    "        ('process_KP_PrEP_Product_Recieved_TG_gap', 'KP Prev_KP-PrEP Product Received TG Gap'),\n",
    "        ('process_KP_PrEP_Product_Recieved_SW_gap', 'KP Prev_KP-PrEP Product Received SW Gap'),\n",
    "        ('process_KP_PrEP_Product_Recieved_PWID_gap', 'KP Prev_KP-PrEP Product Received PWID Gap'),\n",
    "        ('process_KP_Condom_Distribution_gap', 'KP Prev_KP-Condom Distribution Gap'),\n",
    "        ('process_KP_Lubricants_Distribution_gap', 'KP Prev_KP-Condom Lubricants Distribution Gap'),\n",
    "        ('process_KP_PrEP_Enrolment_gap', 'KP Prev_PrEP-GP Enrolment Gap'),\n",
    "        ('process_KP_PrEP_Restart_gap', 'KP Prev_PrEP-GP Restart Gap'),\n",
    "        ('process_KP_PrEP_Eligible_gap', 'KP Prev_PrEP-MSF Eligible Gap'),\n",
    "        ('process_KP_PrEP_Received_gap', 'KP Prev_PrEP-MSF Received Gap'),\n",
    "        ('process_KP_PrEP_Retest_Negative_gap', 'KP Prev_PrEP-MSF RR Negative Gap'),\n",
    "        ('process_KP_PrEP_Retest_Positive_gap', 'KP Prev_PrEP-MSF RR Positive Gap'),\n",
    "        ('process_KP_PrEP_Discontinued_gap', 'KP Prev_PrEP-MSF PrEP Discontinued Gap'),\n",
    "        ('process_KP_HTS_Positive_gap', 'KP Prev_HTS HTS and Positive Gap'),\n",
    "        ('process_KP_HTS_3b_Positive_gap', 'KP Prev_HTS 3b (TG) Positive Gap'),\n",
    "        ('process_KP_HTS_3c_Positive_gap', 'KP Prev_HTS 3c (SW) Positive Gap'),\n",
    "        ('process_KP_HTS_3d_Positive_gap', 'KP Prev_HTS 3d (PWID) Positive Gap'),\n",
    "        ('process_KP_HTS_3e_Positive_gap', 'KP Prev_HTS 3e (OVC) Positive Gap'),\n",
    "        ('process_KP_HTS_3f_Positive_gap', 'KP Prev_HTS 3f (Prisons) Positive Gap'),\n",
    "        ('process_KP_HTS_2_Positive_gap', 'KP Prev_HTS 2 (AGYW) Positive Gap')\n",
    "    ]\n",
    "\n",
    "    def on_generate_report_click(b):\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(ui_separator_top)\n",
    "            # Initialize progress bar\n",
    "            total_gaps = len(gap_functions)\n",
    "            progress = widgets.IntProgress(\n",
    "                value=0,\n",
    "                min=0,\n",
    "                max=total_gaps,\n",
    "                bar_style='success',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "                style={'description_width': 'initial'},\n",
    "                layout={'width': '500px'}\n",
    "            )\n",
    "            # Initialize progress label\n",
    "            progress_label = widgets.HTML(\n",
    "                value=f'Preparing report: Processing gap 0 of {total_gaps}'\n",
    "            )\n",
    "            # Display UI header, progress bar, and label\n",
    "            display(progress)\n",
    "            display(progress_label)\n",
    "\n",
    "            # Process each gap function\n",
    "            global idx, func_name, description\n",
    "            for idx, (func_name, description) in enumerate(gap_functions, 1):\n",
    "                clear_output(wait=True)  # Clear previous function output\n",
    "                # Update progress bar and label\n",
    "                progress.value = idx\n",
    "                progress_label.value = f'Processing {description} ({idx}/{total_gaps})'\n",
    "                # Re-display UI elements\n",
    "                print(ui_separator_top)\n",
    "                display(progress)\n",
    "                display(progress_label)\n",
    "                # Execute the gap function\n",
    "                func = globals()[func_name]  # Get function reference\n",
    "                func(display_output=False)\n",
    "                time.sleep(2.5)  # Brief pause for visual smoothness\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            print(ui_separator_top)\n",
    "            display(progress)\n",
    "            display(HTML(f\"✔️ <b>Report generation completed! {idx}/{total_gaps}</b>\"))\n",
    "            file_link = create_report_zip()\n",
    "            if file_link:\n",
    "                display(HTML('<style>.download-link a { color: green; font-size: 10px; }</style>'))\n",
    "                display(file_link)\n",
    "            else:\n",
    "                display(HTML('<b><font color=\"red\">Failed to create ZIP file.</font></b>'))\n",
    "\n",
    "            # Display final separator\n",
    "            print(ui_separator_bottom)\n",
    "\n",
    "    # -- Step 3: Link buttons to their handlers\n",
    "    botton0.on_click(on_botton0_click)\n",
    "    botton1.on_click(on_botton1_click)\n",
    "    botton2.on_click(on_botton2_click)\n",
    "    botton3.on_click(on_botton3_click)\n",
    "    botton4.on_click(on_botton4_click)\n",
    "    botton5.on_click(on_botton5_click)\n",
    "    botton6.on_click(on_botton6_click)\n",
    "    botton7.on_click(on_botton7_click)\n",
    "    botton8.on_click(on_botton8_click)\n",
    "    botton9.on_click(on_botton9_click)\n",
    "    botton10.on_click(on_botton10_click)\n",
    "    botton11.on_click(on_botton11_click)\n",
    "    botton12.on_click(on_botton12_click)\n",
    "    botton13.on_click(on_botton13_click)\n",
    "    botton14.on_click(on_botton14_click)\n",
    "    botton15.on_click(on_botton15_click)\n",
    "    botton16.on_click(on_botton16_click)\n",
    "    botton17.on_click(on_botton17_click)\n",
    "    botton18.on_click(on_botton18_click)\n",
    "    botton19.on_click(on_botton19_click)\n",
    "    botton20.on_click(on_botton20_click)\n",
    "    botton21.on_click(on_botton21_click)\n",
    "    botton22.on_click(on_botton22_click)\n",
    "    botton23.on_click(on_botton23_click)\n",
    "    botton24.on_click(on_botton24_click)\n",
    "    botton25.on_click(on_botton25_click)\n",
    "    botton26.on_click(on_botton26_click)\n",
    "    botton27.on_click(on_botton27_click)\n",
    "    botton28.on_click(on_botton28_click)\n",
    "    botton29.on_click(on_botton29_click)\n",
    "    botton30.on_click(on_botton30_click)\n",
    "    botton31.on_click(on_botton31_click)\n",
    "    botton32.on_click(on_botton32_click)\n",
    "    botton33.on_click(on_botton33_click)\n",
    "    botton34.on_click(on_botton34_click)\n",
    "    botton35.on_click(on_botton35_click)\n",
    "    botton36.on_click(on_botton36_click)\n",
    "    botton37.on_click(on_botton37_click)\n",
    "    botton38.on_click(on_botton38_click)\n",
    "    botton39.on_click(on_botton39_click)\n",
    "    botton40.on_click(on_botton40_click)\n",
    "    botton41.on_click(on_botton41_click)\n",
    "    botton42.on_click(on_botton42_click)\n",
    "    botton43.on_click(on_botton43_click)\n",
    "    botton44.on_click(on_botton44_click)\n",
    "    botton45.on_click(on_botton45_click)\n",
    "    botton46.on_click(on_botton46_click)\n",
    "    botton47.on_click(on_botton47_click)\n",
    "    botton48.on_click(on_botton48_click)\n",
    "    botton49.on_click(on_botton49_click)\n",
    "    botton50.on_click(on_botton50_click)\n",
    "    botton51.on_click(on_botton51_click)\n",
    "    botton52.on_click(on_botton52_click)\n",
    "    botton53.on_click(on_botton53_click)\n",
    "    botton54.on_click(on_botton54_click)\n",
    "    botton55.on_click(on_botton55_click)\n",
    "    botton56.on_click(on_botton56_click)\n",
    "    botton57.on_click(on_botton57_click)\n",
    "    botton58.on_click(on_botton58_click)\n",
    "    botton59.on_click(on_botton59_click)\n",
    "    botton60.on_click(on_botton60_click)\n",
    "    botton61.on_click(on_botton61_click)\n",
    "    botton62.on_click(on_botton62_click)\n",
    "    botton63.on_click(on_botton63_click)\n",
    "    botton64.on_click(on_botton64_click)\n",
    "    botton65.on_click(on_botton65_click)\n",
    "    botton66.on_click(on_botton66_click)\n",
    "    botton67.on_click(on_botton67_click)\n",
    "    botton68.on_click(on_botton68_click)\n",
    "    botton69.on_click(on_botton69_click)\n",
    "    botton70.on_click(on_botton70_click)\n",
    "    generate_report.on_click(on_generate_report_click)\n",
    "    clear_button.on_click(on_clear_button_click)\n",
    "\n",
    "    # -- Step 4: Create group buttons with dropdown arrow, bold text, and larger font\n",
    "    # -- Define a consistent layout for main group buttons\n",
    "    group_button_layout = widgets.Layout(\n",
    "        width='150px',\n",
    "        border='1.5px solid #999'  # Thin visible border\n",
    "    )  # Main buttons width: 150px\n",
    "    group_button_style = {'font_family': 'Calibri', 'font_weight': 'bold', 'font_size': '12px'}\n",
    "\n",
    "    # -- Define a layout for child buttons (sub-buttons) with a smaller width, font size, border, and reduced height\n",
    "    child_button_layout = widgets.Layout(\n",
    "        width='150px',\n",
    "        height='25px',  # Reduced height for child buttons\n",
    "        border='1px solid #999'  # Thin visible border\n",
    "    )\n",
    "    child_button_style = {'font_family': 'Calibri', 'font_size': '10px', 'button_color': '#ffffff'}  # Font size for child buttons\n",
    "    \n",
    "    # Apply the child button layout and style to all child buttons\n",
    "    for btn in [\n",
    "        botton0, botton1, botton2, botton3, botton4, botton5, botton6, botton7, botton8, botton9, botton10, \n",
    "        botton11, botton12, botton13, botton14, botton15, botton16, botton17, botton18, botton19, botton20, \n",
    "        botton21, botton22, botton23, botton24, botton25, botton26, botton27, botton28, botton29, botton30, \n",
    "        botton31, botton32, botton33, botton34, botton35, botton36, botton37, botton38, botton39, botton40, \n",
    "        botton41, botton42, botton43, botton44, botton45, botton46, botton47, botton48, botton49, botton50, \n",
    "        botton51, botton52, botton53, botton54, botton55, botton56, botton57, botton58, botton59, botton60, \n",
    "        botton61, botton62, botton63, botton64, botton65, botton66, botton67, botton68, botton69, botton70,\n",
    "        clear_button, generate_report\n",
    "    ]:\n",
    "        btn.layout = child_button_layout\n",
    "        btn.style = child_button_style\n",
    "\n",
    "    main_button_description = [\n",
    "        'Main Actions', 'Report Rate', 'AGYW Report', 'ART Report', 'HTS Report', \n",
    "        'HIVST Report', 'ICT Report', 'PMTCT Report', 'NSP Report', 'KP Report'\n",
    "    ]                                                 # -- Main button description\n",
    "\n",
    "    # Find the length of the longest description\n",
    "    max_length = len(max(main_button_description, key=len)) \n",
    "\n",
    "    general_button = widgets.Button(\n",
    "        description=f\"{main_button_description[0]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    report_rate_button = widgets.Button(\n",
    "        description=f\"{main_button_description[1]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    agyw_button = widgets.Button(\n",
    "        description=f\"{main_button_description[2]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    art_button = widgets.Button(\n",
    "        description=f\"{main_button_description[3]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    hts_button = widgets.Button(\n",
    "        description=f\"{main_button_description[4]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    hivst_button = widgets.Button(\n",
    "        description=f\"{main_button_description[5]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    ict_button = widgets.Button(\n",
    "        description=f\"{main_button_description[6]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    pmtct_button = widgets.Button(\n",
    "        description=f\"{main_button_description[7]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    nsp_button = widgets.Button(\n",
    "        description=f\"{main_button_description[8]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "    kp_button = widgets.Button(\n",
    "        description=f\"{main_button_description[9]:<{max_length}} ▼\",\n",
    "        layout=group_button_layout,\n",
    "        style=group_button_style\n",
    "    )\n",
    "\n",
    "    # -- Step 5: Define sub-button containers with row breaking for more than 5 buttons\n",
    "    def create_sub_button_rows(buttons, max_per_row=5):\n",
    "        # Split buttons into chunks of max_per_row\n",
    "        button_rows = [buttons[i:i + max_per_row] for i in range(0, len(buttons), max_per_row)]\n",
    "        # Create an HBox for each row with no spacing\n",
    "        return [widgets.HBox(row, layout=widgets.Layout(margin='0px')) for row in button_rows]\n",
    "\n",
    "    # Create sub-button containers with row breaking and a general border\n",
    "    sub_button_container_layout = widgets.Layout(\n",
    "        border='1px solid #999',  # General border around the group of child buttons\n",
    "        padding='1px',  # Small padding inside the border for better appearance\n",
    "    )\n",
    "    general_sub_buttons = widgets.VBox(create_sub_button_rows([botton0, generate_report, clear_button]), layout=sub_button_container_layout)\n",
    "    report_rate_sub_buttons = widgets.VBox(create_sub_button_rows([botton1, botton2, clear_button]), layout=sub_button_container_layout)\n",
    "    agyw_sub_buttons = widgets.VBox(create_sub_button_rows([botton3, botton4, botton5, botton6, clear_button]), layout=sub_button_container_layout)\n",
    "    art_sub_buttons = widgets.VBox(create_sub_button_rows([botton7, botton8, botton9, botton10, botton11, botton12, clear_button]), layout=sub_button_container_layout)\n",
    "    hts_sub_buttons = widgets.VBox(create_sub_button_rows([botton13, botton14, botton15, botton16, botton17, clear_button]), layout=sub_button_container_layout)\n",
    "    hivst_sub_buttons = widgets.VBox(create_sub_button_rows([botton18, botton19, botton20, botton21, botton22, botton23, botton24, clear_button]), layout=sub_button_container_layout)\n",
    "    ict_sub_buttons = widgets.VBox(create_sub_button_rows([botton25, botton26, botton27, clear_button]), layout=sub_button_container_layout)\n",
    "    pmtct_sub_buttons = widgets.VBox(create_sub_button_rows([botton28, botton29, botton30, botton31, botton32, botton33, botton34, \n",
    "                                                             botton35, botton36, botton37, botton38, clear_button]), layout=sub_button_container_layout)\n",
    "    nsp_sub_buttons = widgets.VBox(create_sub_button_rows([botton39, botton40, botton41, botton42, botton43, clear_button]), layout=sub_button_container_layout)\n",
    "    kp_sub_buttons = widgets.VBox(create_sub_button_rows([botton44, botton45, botton46, botton47, botton48, botton49, botton50, botton51, botton52, botton53, \n",
    "                                                          botton54, botton55, botton56, botton57, botton58, botton59, botton60, botton61, botton62, botton63,\n",
    "                                                          botton64, botton65, botton66, botton67, botton68, botton69, botton70, clear_button]), layout=sub_button_container_layout)\n",
    "\n",
    "    # Define custom CSS for background color for main botton area\n",
    "    css_sub_botton = \"\"\"\n",
    "    <style>\n",
    "    .custom-vbox {\n",
    "        background-color: #e8e8e8f6 !important;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(css_sub_botton))\n",
    "    # Apply custom CSS class for background color\n",
    "    for add in [general_sub_buttons, report_rate_sub_buttons, agyw_sub_buttons, art_sub_buttons,\n",
    "                 hts_sub_buttons, hivst_sub_buttons, ict_sub_buttons, pmtct_sub_buttons,\n",
    "                 nsp_sub_buttons, kp_sub_buttons]:\n",
    "        add.add_class('custom-vbox')\n",
    "\n",
    "    # -- Track the currently open group\n",
    "    current_open = [None]\n",
    "    sub_button_area = widgets.VBox([])\n",
    "\n",
    "    # -- Step 6: Define group button handlers to toggle sub-buttons\n",
    "    def update_button_descriptions(closed_button, opened_button):\n",
    "        for btn in [general_button, report_rate_button, agyw_button, art_button, \n",
    "                    hts_button, hivst_button, ict_button, pmtct_button, nsp_button, kp_button]:\n",
    "            if btn != opened_button and btn.description.endswith(\"▲\"):\n",
    "                btn.description = btn.description.replace(\"▲\", \"▼\")\n",
    "        if closed_button and closed_button.description.endswith(\"▲\"):\n",
    "            closed_button.description = closed_button.description.replace(\"▲\", \"▼\")\n",
    "        if opened_button and not opened_button.description.endswith(\"▲\"):\n",
    "            opened_button.description = opened_button.description.replace(\"▼\", \"▲\")\n",
    "\n",
    "    def on_general_button_click(b):\n",
    "        if current_open[0] == general_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(general_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [general_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], general_button)\n",
    "            current_open[0] = general_button\n",
    "\n",
    "    def on_report_rate_button_click(b):\n",
    "        if current_open[0] == report_rate_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(report_rate_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [report_rate_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], report_rate_button)\n",
    "            current_open[0] = report_rate_button\n",
    "\n",
    "    def on_agyw_button_click(b):\n",
    "        if current_open[0] == agyw_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(agyw_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [agyw_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], agyw_button)\n",
    "            current_open[0] = agyw_button\n",
    "\n",
    "    def on_art_button_click(b):\n",
    "        if current_open[0] == art_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(art_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [art_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], art_button)\n",
    "            current_open[0] = art_button\n",
    "    \n",
    "    def on_hts_button_click(b):\n",
    "        if current_open[0] == hts_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(hts_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [hts_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], hts_button)\n",
    "            current_open[0] = hts_button\n",
    "\n",
    "    def on_hivst_button_click(b):\n",
    "        if current_open[0] == hivst_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(hivst_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [hivst_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], hivst_button)\n",
    "            current_open[0] = hivst_button\n",
    "    \n",
    "    def on_ict_button_click(b):\n",
    "        if current_open[0] == ict_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(ict_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [ict_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], ict_button)\n",
    "            current_open[0] = ict_button\n",
    "    \n",
    "    def on_pmtct_button_click(b):\n",
    "        if current_open[0] == pmtct_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(pmtct_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [pmtct_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], pmtct_button)\n",
    "            current_open[0] = pmtct_button\n",
    "    \n",
    "    def on_nsp_button_click(b):\n",
    "        if current_open[0] == nsp_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(nsp_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [nsp_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], nsp_button)\n",
    "            current_open[0] = nsp_button\n",
    "    \n",
    "    def on_kp_button_click(b):\n",
    "        if current_open[0] == kp_button:\n",
    "            sub_button_area.children = []\n",
    "            update_button_descriptions(kp_button, None)\n",
    "            current_open[0] = None\n",
    "        else:\n",
    "            sub_button_area.children = [kp_sub_buttons]\n",
    "            update_button_descriptions(current_open[0], kp_button)\n",
    "            current_open[0] = kp_button\n",
    "\n",
    "    # -- Step 7: Link group buttons to their handlers\n",
    "    general_button.on_click(on_general_button_click)\n",
    "    report_rate_button.on_click(on_report_rate_button_click)\n",
    "    agyw_button.on_click(on_agyw_button_click)\n",
    "    art_button.on_click(on_art_button_click)\n",
    "    hts_button.on_click(on_hts_button_click)\n",
    "    hivst_button.on_click(on_hivst_button_click)\n",
    "    ict_button.on_click(on_ict_button_click)\n",
    "    pmtct_button.on_click(on_pmtct_button_click)\n",
    "    nsp_button.on_click(on_nsp_button_click)\n",
    "    kp_button.on_click(on_kp_button_click)\n",
    "\n",
    "    # -- Step 8: Create a layout for group buttons with a maximum of 5 per row and no spacing between rows\n",
    "    all_group_buttons = [\n",
    "        general_button,\n",
    "        report_rate_button,\n",
    "        agyw_button,\n",
    "        art_button,\n",
    "        hts_button,\n",
    "        hivst_button,\n",
    "        ict_button,\n",
    "        pmtct_button,\n",
    "        nsp_button,\n",
    "        kp_button\n",
    "    ]\n",
    "    # Split the buttons into chunks of 5\n",
    "    max_buttons_per_row = 5\n",
    "    group_button_rows = [\n",
    "        all_group_buttons[i:i + max_buttons_per_row]\n",
    "        for i in range(0, len(all_group_buttons), max_buttons_per_row)\n",
    "    ]\n",
    "    # Create HBox for each row with no margin or padding, and wrap them in a VBox with no spacing\n",
    "    group_buttons_layout = widgets.VBox(\n",
    "        [widgets.HBox(row, layout=widgets.Layout(align_items=\"flex-start\", margin='0px', padding='0px'))\n",
    "         for row in group_button_rows],\n",
    "        layout=widgets.Layout(align_items=\"flex-start\", margin='0px', padding='1px', border='1px solid #999')\n",
    "    )\n",
    "    # Define custom CSS for background color for main botton area\n",
    "    css = \"\"\"\n",
    "    <style>\n",
    "    .custom-vbox {\n",
    "        background-color: #e8e8e8da !important;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\"\n",
    "    display(HTML(css))\n",
    "    # Apply custom CSS class for background color\n",
    "    #group_buttons_layout.add_class('custom-vbox')\n",
    "\n",
    "    # -- Step 9: Create the main layout\n",
    "    output = widgets.Output()\n",
    "    with output:  # Initialize output with ui_separator_clear\n",
    "        print(ui_separator_clear)\n",
    "\n",
    "    layout = widgets.VBox([\n",
    "        group_buttons_layout,\n",
    "        sub_button_area,\n",
    "        output\n",
    "    ], layout=widgets.Layout(\n",
    "        align_items=\"flex-start\",\n",
    "        padding=\"10px\"\n",
    "    ))\n",
    "\n",
    "    # -- Step 10: Display the interface\n",
    "    display(layout)\n",
    "  \n",
    "# -- Ensure this is the last cell in your notebook\n",
    "run_jupyter_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e44ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
